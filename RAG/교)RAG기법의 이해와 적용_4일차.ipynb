{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 RAG기법의 이해와 적용 - 4차시(24.12.03)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CLASS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFPlumberLoader('./data/SPRi AI Brief_11월호_산업동향_F.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs[3: -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 3, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석\\nKEY Contents\\nn 미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고\\n있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과\\n실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\\n£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식\\n기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간\\n∙ AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로\\n법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용\\n∙ 그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며,\\n현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재\\nn 보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수\\n및 차별적 영향과 같은 민권 문제를 초래할 위험 보유\\n∙ 얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별\\n오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재\\n∙ 정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을\\n지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재\\n∙ 법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아\\n공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재\\n£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시\\nn 민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시\\n∙ 국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성\\n평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요\\n∙ 각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로\\n인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요\\n∙ 얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과\\n지원, 업데이트를 제공 필요\\n☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.\\n1\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 4, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표\\nKEY Contents\\nn 미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을\\n지원하기 위한 지침을 발표\\nn 지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI\\n솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구\\n£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시\\nn 미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일\\n‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표\\n∙ 미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일\\n구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획\\n∙ 이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개\\n전략적 목표에 대하여 권고사항을 제시\\nn (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해\\nAI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시\\n∙ 정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호\\n위험을 식별 및 관리하고 법률과 정책 준수를 보장\\n∙ 정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와\\n안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악\\n∙ 성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할\\n수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상\\nn (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서\\n강력한 경쟁을 보장할 것을 요구\\n∙ 계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항\\n개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한\\n계약업체 성과와 정부 기관의 임무 성과를 보장\\nn (연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘\\n공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원\\n∙ 각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에\\n가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려\\n☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in\\nGovernment, 2024.10.03.\\n2\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 5, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\n대한 투명성과 책임성을 보장 필요\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\n3\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 6, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nOECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표\\nKEY Contents\\nn OECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크,\\n정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표\\nn 보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로\\n구현하는 단계별 접근방식을 권고\\n£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련\\nn OECD가 2024년 10월 15일 안전하고 신뢰할 수 있는 AI의 원칙을 실행 가능한 정책으로 전환할\\n수 있도록 지원하는 ‘공공 부문의 AI를 위한 G7 툴킷’ 보고서를 발간\\n∙ OECD는 G7 회원국이 작성한 설문 응답 및 OECD와 UNESCO의 연구를 토대로 공공 부문에서 AI\\n활용 모범사례와 거버넌스 프레임워크, 정책 옵션과 관련된 종합적 지침 제공을 목표로 보고서를 작성\\nn G7과 EU의 AI 도입 추세를 분석한 결과, G7 회원국과 EU는 공공 부문의 AI 도입과 관련된\\n국가 전략 및 정책의 개발과 구현에서 차이가 존재\\n∙ EU·독일·미국·영국·일본은 국가 AI 전략에 공공 부문을 포함했고 프랑스는 국가 AI 전략에서는\\n공공 부문을 구체적으로 다루지 않으나 공공행정 혁신기금(FTAP)을 조성하여 60개 이상의 AI\\n프로젝트에 투자하는 등 별도의 정책을 수립\\n∙ 캐나다는 2025년 봄까지 공공 서비스를 위한 AI 전략을 개발할 계획이며, 이탈리아는 ‘공공\\n부문 디지털화를 위한 3개년 계획(2024~2026)’에 AI를 포함\\n∙ G7 회원국들은 접근방식의 차이에도 인재와 기술 개발, 조달 정책, 협력관계 구축, 윤리적이고\\n신뢰할 수 있으며 인간 중심적인 AI 관행 조성, 데이터 품질 보장 등에서 공통점을 보유\\nn AI 거버넌스 프레임워크 측면에서 G7 회원국 중 미국·캐나다·프랑스와 EU는 여러 기관이 AI를 관리하는\\n분산형 거버넌스 구조를 채택했으며 이탈리아·독일·영국은 단일 기관이 AI를 관리하는 중앙집중형\\n거버넌스를 채택\\nn G7 회원국들은 공공 부문의 운영 효율성 향상, 정책 결정 강화, 공공 서비스 개선, 정부의 투명성과\\n책임성 강화를 위해 AI를 활용하는 한편, 다양한 정책 옵션으로 AI 도입 시의 과제 해결을 모색\\n∙ AI 도입에 필수적인 인프라를 강화하기 위한 데이터 저장과 공유 솔루션 채택, AI에 적합한\\n혁신적이고 유연한 조달 절차의 수립 및 민간 파트너십 육성, 공공 부문의 AI 역량 강화, 데이터\\n거버넌스 프레임워크 구축 등이 대표적인 정책 옵션\\nn 보고서는 공공 부문의 AI 도입 시 각 단계를 신중히 관리하여 위험을 완화할 수 있도록, 문제를\\n명확히 정의하고 아이디어를 구상한 뒤 프로토타입부터 시작해 통제된 환경에서 AI를 시범 도입한\\n후 이를 개선해 본격적으로 구현하는 단계적 접근방식을 강조\\n☞ 출처: OECD, G7 Toolkit for Artificial Intelligence in the Public Sector, 2024.10.15.\\n4\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 7, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시\\nKEY Contents\\nn 세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적\\n균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표\\nn 백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한\\n이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\\n£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요\\nn 세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스\\n프레임워크를 제시한 백서를 발간\\n∙ 백서는 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거\\n활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안\\nn (과거 활용) 기존 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI\\n규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요\\n∙ 생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를\\n고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완\\n∙ 기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제\\n권한을 집중하는 방안의 장단점을 고려\\nn (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는\\n정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적\\n∙ 정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자\\n집단의 고유한 문제에 대응 필요\\n∙ 다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재\\nn (미래 계획) 생성AI 거버넌스에 대한 민첩한 준비와 함께 국제협력을 촉진하는 것으로, 정부는 빠\\n른 기술 발전과 한정된 자원, 글로벌 불확실성을 고려해 미래를 예견한 국가 전략을 개발하고 다음\\n의 활동을 추진\\n∙ 정부 내 AI 역량 향상과 AI 전문가 채용을 위한 투자를 시행하고 AI 전담 기관의 설립 필요성을 신중히 검토\\n∙ 생성AI와 인간 간 상호작용, 생성AI와 여타 기술의 융합, 생성AI 신기능과 관련된 혁신 및 이로 인한\\n새로운 위험을 탐색\\n∙ 기존 규제의 영향 평가 및 미래 AI 발전에 대비한 영향 평가로 규제 민첩성을 유지하며, 일례로\\n광범위한 도입에 앞서 규제 유예제도(샌드박스)를 시범 운영\\n∙ 지식과 인프라 공유와 AI 안전성 연구, AI 표준의 일관성 확보를 위한 국제협력 추진\\n☞ 출처: World Economic Forum, Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation, 2024.10.08.\\n5\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 8, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중\\nKEY Contents\\nn CB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며,\\nAI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도\\n비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\n£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상\\nn 글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처\\n현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석\\n∙ AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며,\\n3분기에도 역대 두 번째로 높은 비중을 기록\\n∙ 오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe\\nSuperintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록\\n∙ CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국\\n기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록\\nn 기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이\\nAI 기업인 것으로 확인\\n∙ 범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI\\n서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득\\nn AI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은\\n설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해\\n2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성\\n∙ 대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고\\n있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는\\n2024년 9월 AI 스타트업 2곳을 인수\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에\\n부응하지 못하고 실패하게 될 것으로 예상\\n∙ CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을\\n겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망\\n☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.\\n6\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 9, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개\\nKEY Contents\\nn 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는\\n‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁\\n동영상 AI 모델보다 더 높은 점수를 기록\\n£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개\\nn 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타\\n무비 젠(Meta Movie Gen)’을 공개\\n∙ 메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을\\n반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과\\n같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침\\nn 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원\\n∙ (동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대\\n16초 길이 동영상 생성을 지원\\n∙ (개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을\\n반영한 개인화 동영상을 제작 가능\\n∙ (동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과\\n같은 광범위한 수정도 지원\\n∙ (오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로\\n최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성\\n£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를\\n비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록\\n∙ 메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win\\nRate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가\\n* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해\\n승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미\\n<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.\\n7\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 10, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개\\nKEY Contents\\nn 메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량\\n모델을 포함하는 라마 3.2 시리즈를 공개\\nn 비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서\\n앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\n£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능\\nn 메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라마 3.2’를 공개\\n∙ 라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억\\n개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성\\n∙ 2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지\\n추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상\\nn 라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지\\n안의 물체 식별과 같은 이미지 추론을 지원\\n∙ 라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록\\n내용을 전달하는 문장을 생성 가능\\n∙ 이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드\\n3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서\\n57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가\\nn 라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어\\n텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화\\n∙ 모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서\\n구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수\\n∙ 일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점)\\n및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2\\n2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가\\nn 메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록\\n지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개\\n∙ 개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고\\n간소화된 방식으로 라마 모델을 구축 가능\\n* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터\\n☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.\\n8\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 11, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개\\nKEY Contents\\nn 앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를\\n능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성\\nn 몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단\\n폐쇄형 모델을 능가하는 점수를 기록\\n£몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가\\nn 미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈\\n소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개\\n∙ 몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의\\n전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중\\nE-1B 모델은 온디바이스 실행 가능\\n∙ 몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된\\n환경에서도 사용 가능한 것이 장점\\n∙ 몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를\\n구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이\\n필요한 웹 에이전트나 로봇 개발에도 유리\\n∙ AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고\\n연구와 상업적 목적의 활용을 허용\\nn AI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가\\n* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정\\n∙ 몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점),\\n‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로\\nGPT-4o(1079점)에 이어 2위\\n∙ 전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로\\n각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준\\n<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.\\n9\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 12, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개\\nKEY Contents\\nn 미스트랄AI가 네트워크 연결 없이 온디바이스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를\\n미스트랄 3B와 미스트랄 8B 버전으로 공개\\nn 벤치마크 평가에서 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마 및 라마와\\n비교해 대부분 벤치마크에서 더 높은 평가를 획득\\n£미스트랄 AI, 네트워크 연결이 필요 없는 경량 모델 ‘레 미니스트로’ 출시\\nn 프랑스의 대표 AI 스타트업 미스트랄AI(Mistral AI)가 2024년 10월 16일 네트워크 연결 없이\\n작동하는 온디바이스용 AI 모델 ‘레 미니스트로(Les Ministraux)’를 발표\\n∙ ‘미스트랄 3B’와 ‘미스트랄 8B’ 버전으로 공개된 이 모델은 경량 모델이면서도 영어책 50쪽 분량에\\n해당하는 12만 8천 개 토큰의 컨텍스트 창을 지원\\n∙ 미스트랄AI는 레 미니스트로가 번역과 스마트 어시스턴트, 분석, 자율 로봇 같은 중요 애플리케이션에\\n대하여 네트워크 연결 없이 개인정보보호가 가능한 온디바이스 추론을 원하는 고객 수요에 맞게\\n지연시간이 짧고 효율적인 솔루션을 제공한다고 강조\\n∙ 미스트랄AI는 8B 버전만 연구용으로 다운로드를 허용했으며 향후 두 모델을 클라우드 플랫폼을 통해\\n제공할 계획으로, 사용 비용은 100만 입출력 토큰 당 8B 버전은 10센트, 3B 버전은 4센트로 책정\\n£레 미니스트로, 오픈소스 모델 ‘젬마’ 및 ‘라마’ 대비 대부분 벤치마크에서 우수한 평가\\nn 벤치마크 평가 결과, 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마(Gemma)와 라마\\n(Llama)보다 대부분 벤치마크에서 더 높은 평가를 획득\\n∙ MMLU* 평가에서 미스트랄 3B는 60.9점을 얻어 구글의 ‘젬마 2 2B’(52.4점)와 메타의 ‘라마 3.2\\n3B’(56.2점)를 앞섰고, 미스트랄 8B는 65.0점으로 ‘라마 3.1 8B’(64.7점)와 1년 전 출시된 자체\\n모델 ‘미스트랄 7B’(62.5점)를 능가\\n* 다양한 주제에 대한 모델의 광범위한 지식과 추론 능력을 평가하는 벤치마크\\n∙ 미스트랄 8B는 코딩 능력을 평가하는 HumanEval pass@1*에서만 34.8점으로 ‘라마 3.1\\n8B’(37.8점)보다 소폭 낮은 점수를 기록\\n* AI 모델이 한 번의 시도로 정확한 코드를 생성할 수 있는 능력을 평가하는 벤치마크\\n<미스트랄 3B/7B와 경쟁 모델의 벤치마크 평가 비교>\\n☞ 출처: Mistral AI, Un Ministral, des Ministraux-Introducing the world’s best edge models, 2024.10.16.\\n10\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 13, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개\\nKEY Contents\\nn 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI\\n메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정\\nn 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발\\n중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획\\n£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현\\nn 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의\\nAI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표\\n∙ 사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지\\n않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는\\n‘가장 나다운 AI’를 의미\\n∙ 카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,\\nAI 메이트 서비스 ‘카나나’ 출시 계획도 공개\\nn 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를\\n지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현\\n∙ 개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화\\n경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록\\n메시지로 전송\\n∙ 카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서\\n함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공\\n∙ 카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해\\n완성도를 높여갈 계획\\nn 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나\\n에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의\\n주요 서비스에 적용할 계획\\nn 카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조\\n∙ Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서,\\n기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수\\n있는 리스크에 선제적 대응 추구\\n☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.\\n11\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상\\nKEY Contents\\nn 2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는\\n방법을 개발한 존 홉필드와 제프리 힌턴이 수상\\nn 2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI\\n모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상\\n£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상\\nn 스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤\\n교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의\\n토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여\\n∙ 홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을\\n찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발\\n∙ 힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은\\n통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴\\n유형을 활용해 새로운 예제를 생성 가능\\n∙ 힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을\\n이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세\\n£노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상\\nn 데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글\\n딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를\\n활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상\\n∙ 베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며,\\n2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계\\n* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수\\n∙ 허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델\\n‘알파폴드(AlphaFold) 2’를 2020년 발표하고 오픈소스로 공개\\n∙ 2억 개에 달하는 단백질 구조를 예측한 알파폴드 2는 과거에는 몇 년이 걸리거나 불가능하던 단백질\\n구조 예측을 몇 분 만에 완료할 수 있으며, 2024년 10월까지 190개국 200만 명 이상에 의해 사용\\n∙ 노벨위원회에 따르면 단백질의 구조 예측과 새로운 단백질의 설계는 특정 질병이나 항생제 내성의\\n발생원인 이해 및 새로운 의약품이나 나노소재 개발 등으로 인류에게 막대한 이익을 가져올 전망\\n☞ 출처: The Nobel Prize, They used physics to find patterns in information, 2024.10.08.\\nThe Nobel Prize, They have revealed proteins’ secrets through computing and artificial intelligence, 2024.10.09.\\n12\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 15, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표\\nKEY Contents\\nn 미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI\\nR&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표\\nn 국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구\\n우선순위, 주요 이해관계자별 권장 사항을 제시\\n£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시\\nn 미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고\\n신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌\\nAI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표\\n∙ 국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운\\n방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고,\\nAI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시\\nn 국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시\\n∙ (사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의\\n설계와 배포에 관한 연구를 수행 우선\\n∙ (포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에\\n대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화\\n∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI\\n애플리케이션을 우선 개발\\n∙ (AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는\\nAI 시스템 개발을 위해 더 많은 기술 발전 필요\\n∙ (글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고\\n노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립\\nn 국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구\\n의제의 목표 달성을 위한 권장 사항을 제시\\n∙ (연구 기금 제공자) 투명성을 증진하고 국제 AI 연구 협력을 지원하는 기금을 요청하며 다양한 지역에\\n서 연구 인프라 접근성을 증진하고 민관협력을 추진\\n∙ (연구 생태계 허브) 연구 재현성을 장려하고, AI 연구 가이드라인 관련 협력과 조정을 강화하며, 민간\\n분야에서 중시하는 연구 주제 이외의 연구를 지원\\n∙ (연구팀) 다학제적 팀을 우선 편성하고 지역 연구자들과 협력하며, 사회기술적 방법론과 연구 설계를\\n채택하고 위험 평가 절차를 통합\\n☞ 출처: U.S. Department of State, Global AI Research Agenda, 2024.09.23.\\n13\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 16, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간\\nKEY Contents\\nn 일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한\\n평가 관점 가이드’를 발표\\nn 가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해\\n효과적 조치를 취했을 때의 기대 목표를 제시\\n£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시\\nn 일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성\\n평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간\\n∙ 가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을\\n제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립\\n<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점>\\n평가 관점 관련 AI 안전성 요소 기대 목표\\n유해 정보의 출력 통제 인간중심, 안전성, 공정성 Ÿ LLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능\\n허위 정보와 Ÿ LLM 시스템의 출력에 대한 사실 검증 메커니즘 구축\\n인간중심, 안전성, 투명성\\n조작 방지 Ÿ LLM 시스템의 출력에 의한 사용자 결정의 조작 방지\\nŸ LLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한\\n공정성과 포용성 인간중심, 공정성, 투명성 차별 부재\\nŸ LLM 시스템의 출력을 모든 최종 사용자가 이해 가능\\n고위험 사용 및 Ÿ LLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익\\n인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ LLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호\\nŸ LLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한\\n보안 보안\\n기밀정보의 유출 방지\\nŸ LLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적\\n설명 가능성 투명성\\n으로 합리적인 범위에서 확인 가능\\nŸ LLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치\\n견고성 안전성, 투명성\\n않은 입력에 대해 안정적 출력을 제공\\nŸ LLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이\\n데이터 품질 안전성, 공정성, 투명성\\n적절히 관리되는 상태\\nŸ LLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서 시스템 사용\\n검증 가능성 투명성\\n시점까지 제공되는 상태\\nn AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포,\\n사용 단계에서 적절한 간격으로 시행될 필요\\n∙ AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며,\\n평가는 한 차례가 아니라 반복적으로 실시\\n☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.\\n14\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 17, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표\\nKEY Contents\\nn 구글 딥마인드가 강화학습 방식으로 반도체 칩 레이아웃을 설계하여 사람이 몇 주에서 몇 달이\\n걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성하는 AI 모델 ‘알파칩’을 공개\\nn 구글은 2020년 처음 알파칩에 관한 연구 논문을 발표한 뒤, 자체 AI 칩 TPU 개발 시\\n알파칩을 활용해 칩 성능을 개선하고 개발 주기를 단축\\n£알파칩, 구글의 자체 AI 칩 TPU의 레이아웃 설계에도 기여\\nn 구글 딥마인드가 2024년 9월 26일 반도체 칩의 레이아웃을 설계할 수 있는 AI 모델 ‘알파칩\\n(AlphaChip)’을 공개\\n∙ 2020년 연구 프로젝트로 시작된 알파칩은 강화학습 방식을 사용하여 반도체 칩 레이아웃을 설계하며,\\n사람이 완료하는데 몇 주에서 몇 달이 걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성 가능\\nn 구글은 2020년 알파칩에 대한 연구 논문을 처음 발표했으며, 자체 AI 칩 TPU(Tensor Processing\\nUnit) 개발 시 알파칩을 활용해 칩 레이아웃을 설계\\n∙ TPU는 제미나이(Gemini)뿐 아니라 이마젠(Imagen), 비오(Veo) 등의 이미지 및 동영상 생성 모델과\\n같은 구글 AI 시스템의 핵심 요소를 형성\\n∙ 알파칩은 최신 6세대 TPU를 포함한 새로운 세대마다 칩 레이아웃 설계를 개선해 설계주기를\\n단축하고 더 높은 성능의 칩 생산에 기여\\nn 알파칩은 바둑에 특화된 알파고(AlphaGo) 및 바둑, 체스, 쇼기(일본 장기)를 마스터한 알파제로\\n(AlphaZero)와 비슷하게 칩 레이아웃 설계를 게임처럼 접근\\n∙ 알파칩은 모든 부품을 배치할 때까지 한 번에 하나의 회로 부품을 배치하고 최종 레이아웃의 품질에 따라\\n보상을 받게 되며, 상호 연결된 부품 간 관계를 학습하고 칩 전체로 확장해 레이아웃을 개선\\nn 구글은 자체 AI 칩 TPU뿐 아니라 영국 반도체 기업 ARM과 협력해 개발한 데이터센터용 CPU인\\n액시온(Axion) 프로세서도 알파칩으로 레이아웃을 생성했으며, 타사에도 알파칩을 제공\\n∙ 대만의 반도체 기업 미디어텍(MediaTek)은 삼성 스마트폰에 사용되는 ‘다이멘시티 플래그십(Dimensity\\nFlagship) 5G’와 같은 첨단 칩 개발에 알파칩을 활용해 개발을 가속화하고 칩 성능을 개선\\nn 구글 딥마인드는 현재 알파칩의 차기 버전을 개발 중으로, 향후 알파칩이 칩 설계주기의 전 단계를\\n최적화하고 스마트폰, 의료 장비, 농업 센서 등에 사용되는 맞춤형 하드웨어의 칩 설계에 혁신을\\n가져올 것으로 기대\\n☞ 출처: Google Deepmind, How AlphaChip transformed computer chip design, 2024.09.26.\\n15\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 18, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조\\nKEY Contents\\nn 이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머\\n아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적\\nn 고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용\\n절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장\\n£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요\\nn 이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면\\n트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장\\n* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망\\n** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미\\n∙ 트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성\\n측면에서는 한계를 내포\\n∙ 트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI\\n에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아\\n처리 과정에서 지연이 발생\\nn 고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더\\n효율적이고 저렴하게 만들 수 있다고 강조\\n∙ 카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)*\\n메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화\\n* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘\\n∙ 미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월\\n‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세\\n∙ AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를\\n활용해 기반모델을 개발\\nn 고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은\\n이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적\\n∙ AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는\\nLLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요\\n∙ 최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는\\n플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱\\n확산될 것으로 예상\\n☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.\\n16\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 19, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사\\nKEY Contents\\nn MIT 산업성과센터가 설문조사를 통해 근로자 관점의 자동화 기술의 영향을 조사한 결과,\\n근로자들은 직장 내 안전, 임금, 업무 자율성 등에서 자동화를 긍정적으로 평가\\nn 복잡한 문제 해결이 필요한 작업을 수행하는 근로자 및 자신의 직무에 만족하는 근로자일수록\\n자동화의 영향에 긍정적인 것으로 확인\\n£근로자들, 직장 내 안전, 임금, 업무 자율성 등에서 자동화의 영향에 긍정적\\nn MIT 산업성과센터(IPC)는 2024년 9월 30일 9개국* 9천 명 이상의 근로자에 대한 설문조사를\\n바탕으로 근로자 관점에서 자동화 기술을 평가한 연구 결과를 공개\\n* 독일, 미국, 스페인, 영국, 이탈리아, 일본, 폴란드, 프랑스, 호주\\n∙ 연구진은 설문조사를 통해 업무 환경, 직장에서 사용되는 자동화 기술(로봇 및 AI 등), 업무와 기술에\\n대한 태도, 기술이 업무에 미치는 영향을 조사\\nn 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가\\n긍정적 영향을 미칠 것이란 응답이 우세\\n∙ 자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적\\n응답은 12.5%에 불과\\n∙ 자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에\\n미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답\\nn 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며\\n미국 근로자들이 가장 비관적 태도를 보유\\n∙ 9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다\\n우세(임금: –0.6%, 직업 안정성: -4.6%)*\\n* 긍정적 응답에서 부정적 응답 비율을 뺀 수치\\nn 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직 근로자가\\n자동화에 더 긍정적이며, 직장 내 처우도 자동화에 대한 근로자의 인식에 영향을 발휘\\n∙ 고용주가 근로자를 적절히 대우하고 안전에 투자하는 직장에서 일하는 근로자는 직장 내 자동화의\\n영향에 긍정적이며, 직무 만족도와 신뢰도도 자동화에 대한 긍정적 인식에 영향을 미치는 요인으로 확인\\nn 연구진은 조사 결과를 바탕으로 직장 내 원활한 자동화 기술 도입을 위해 직무 설계를 통해 근로자가\\n복잡한 문제를 해결할 수 있는 역할을 만들 것을 권고\\n∙ 근로자들은 신기술 사용과 관련된 보너스가 제공되면 자동화에 더 긍정적인 것으로 나타나, 생산성\\n향상을 위한 자동화 기술 사용에 금전적 보상을 제공하는 방안도 고려 필요\\n☞ 출처: MIT IPC, Automation from the Worker’s Perspective, 2024.09.30.\\n17\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 20, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려\\nKEY Contents\\nn 다이스에 따르면, AI 전문가의 73%는 2025년 이직을 계획 중이며, 58%는 2024년 중 현재보다\\n더 나은 일자리를 찾을 자신이 있다고 응답해 여타 기술 전문가 대비 직업 전망을 낙관\\nn AI 전문가들은 여타 기술 전문가 대비 AI 도구 사용에도 적극적이며, 업무에 생성AI가 상당한\\n영향을 미친다는 응답도 36%로 여타 기술 전문가(22%) 대비 높은 수치를 기록\\n£AI 전문가들, 일반적인 기술 전문가보다 직업 전망에 낙관적\\nn 미국 기술직 채용 플랫폼 다이스(Dice)의 조사에 따르면, AI 기술 전문가는 일반적인 기술 전문가\\n대비 기술 산업의 미래와 자기 경력에 대하여 낙관적\\n∙ 이번 조사는 520명의 미국 정규직 기술 전문가와 390명의 인사 전문가의 응답을 토대로 기술 분야의\\n일자리 시장 환경을 분석\\n∙ 2024년 동안 주요 빅테크가 기술직에 대한 정리해고를 단행하고 기술직 채용도 2021~2022년 대비\\n대폭 감소하는 등 일자리 시장의 침체에도 2024년 기술과 사업의 핵심 요소로 부상한 AI 분야의\\n전문가들은 직업 전망을 낙관\\nn AI 전문가의 73%는 2025년에 이직을 계획 중이며, 58%는 2024년 중 현재보다 더 나은 새로운 일자리를\\n찾을 자신이 있다고 응답\\n∙ 일반적인 기술 전문가의 경우 65%가 2025년 중 이직을 계획 중이며, 2024년 더 나은 신규 일자리를\\n찾을 수 있다고 자신하는 비율은 36%에 불과\\n∙ AI 전문가는 빅테크를 선호하는 비율이 29%로 일반적인 기술 전문가(18%) 대비 더 높게 나타났으며,\\n이는 예산 규모가 더 크고 중요한 AI 프로젝트에 관심이 있거나 빅테크의 채용 가능성에 자신 있기\\n때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가\\n가치 있다고 느끼는 전문가일수록 현재 역할에 만족할 가능성도 증대할 것으로 추론\\n∙ AI 전문가의 51%는 자신의 프로젝트가 기업에 전략적 가치가 있다고 답했으나, 36%는 투자자나\\n이사회, 외부 관계자에게 기업이 AI로 뭔가를 하고 있음을 보여주기 위한 목적이라고 응답\\nn AI 전문가들은 AI 도구 사용에도 적극적이지만, 일반적인 기술 전문가들은 업무에서 AI 도구 사용을\\n주저하는 편으로, AI 전문가들은 일주일에 1회 이상 AI를 사용하는 비율이 49%에 달했으나, 여타\\n기술 전문가들은 25%에 불과\\nn 생성AI가 미치는 영향에 대해서 AI 전문가 사이에서는 상당한 영향을 미친다는 응답이 36%, 약간의 영향을\\n미친다는 응답이 56%, 영향이 없다는 응답은 8%를 기록했으나, 여타 기술 전문가들은 22%가 상당한 영향,\\n53%는 약간의 영향, 26%는 영향이 없다고 응답\\n☞ 출처: Dice, 3 Key Lessons about the AI Tech Talent Market, 2024.09.05.\\n18\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 21, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요\\nKEY Contents\\nn 가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및\\nAI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망\\nn 기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한\\n투자를 강화할 필요\\n£생성AI로 소프트웨어 엔지니어링에서 데이터과학과 AI/ML 역량의 중요성 증대\\nn 시장조사기관 가트너(Gartner)에 따르면 2027년까지 생성AI로 인해 소프트웨어 엔지니어링\\n인력의 80%가 역량 향상이 필요할 전망\\n∙ AI로 인해 인간 엔지니어에 대한 수요가 감소하거나 심지어 AI가 인간을 대체할 것이라는 예상과\\n달리, 가트너는 AI가 향후 소프트웨어 엔지니어의 역할을 변화시키더라도 인간의 전문성과 창의성은\\n여전히 중요하다고 강조\\nn 가트너에 따르면 생성AI는 소프트웨어 엔지니어의 역할에 단기, 중기, 장기적으로 영향을 미칠 전망\\n∙ 단기적으로는 AI가 기존 개발자의 작업 패턴과 업무를 보완하며 소폭의 생산성 향상 효과를 가져오며,\\nAI의 생산성 향상 효과는 성숙한 엔지니어링 관행을 갖춘 기업의 상급 개발자에게 집중될 전망\\n∙ 중기적으로는 AI 에이전트를 통해 더 많은 업무가 자동화되어 개발자의 작업 패턴의 변화가 예상되며,\\n이는 코드 대부분이 인간이 아닌 AI로 생성되는 AI 네이티브 소프트웨어 엔지니어링의 출현을 의미해\\n자연어 프롬프트 엔지니어링과 검색 증강 생성(RAG)* 기술이 엔지니어링의 필수 역량이 될 전망\\n* 외부 데이터를 활용하여 LLM의 출력 정확성을 향상하는 기술\\n∙ 장기적으로는 기업 내 AI 기반 소프트웨어 수요가 증가하면서 이를 충족하기 위해 소프트웨어\\n엔지니어링, 데이터 과학, AI/ML(머신러닝) 분야의 고유한 기술을 갖춘 훨씬 숙련된 AI 엔지니어가\\n부상할 전망\\n£AI 엔지니어를 지원하기 위해 기업의 AI 개발자 플랫폼 투자 필요\\nn 가트너가 2023년 4분기에 미국과 영국 기업 300개를 대상으로 실시한 설문조사에 따르면 소프트웨어\\n엔지니어링 책임자의 56%가 AI/ML 엔지니어를 2024년 가장 수요가 많은 직업으로 평가\\n∙ 기업들은 AI 엔지니어를 지원하기 위해 AI 개발자 플랫폼에 투자해야 하며, AI 개발자 플랫폼은\\n기업이 AI 역량을 더욱 효율적으로 구축하고 AI를 기업 솔루션에 대규모로 통합하는 데 도움이 될 전망\\n∙ 기업들은 AI 개발자 플랫폼 투자를 통해 소프트웨어 엔지니어링팀의 역량을 강화하고 지속적인 AI\\n통합과 개발을 추진하는 도구와 프로세스를 채택 필요\\n☞ 출처: Gartner, Gartner Says Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027,\\n2024.10.03.\\n19\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 22, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박\\nKEY Contents\\nn 인디드가 2,800개 이상의 직무 기술에 대한 생성AI의 수행 능력을 분석해 인간을 대체할\\n가능성을 평가한 결과, 생성AI로 대체될 가능성이 “매우 높은” 것으로 평가된 기술은 전무\\nn 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이며, 물리적 작업\\n수행이 필요한 직무 기술에서는 인간 근로자를 대체할 가능성이 희박\\n£생성AI, 문제 해결 역량 및 물리적 작업 수행 역량의 부족으로 인간 근로자 대체에 한계\\nn 미국의 채용 플랫폼 인디드(Indeed) 산하 연구소 하이어링랩(Hiring Lab)이 2024년 9월 25일\\n발표한 연구 결과에 따르면 생성AI가 인간 근로자를 대체할 가능성은 희박\\n∙ 인디드 하이어링랩은 오픈AI의 GPT-4o로 2,800개 이상의 고유한 직무 기술에 대한 생성AI의 수행\\n능력을 분석해 생성AI가 인간을 대체할 가능성을 평가\\n∙ 연구진은 오픈AI의 GPT-4o가 △기술과 관련된 이론적 지식의 제공 역량 △기술을 사용한 문제 해결 역량\\n△기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행\\n∙ 다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은\\n2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로\\n평가됐으며, “매우 높음”으로 평가된 기술은 전무\\nn 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결\\n능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가\\n∙ 생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제\\n해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는\\n“매우 높음”이라고 평가*\\n* 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely, 5점)\\n∙ 생성AI는 물리적 작업을 수행할 몸체가 없어 실제 작업 수행이 필요한 직무 기술에서는 인간 근로자를\\n대체할 가능성이 제한적\\n∙ 일례로 생성AI는 디지털 기술 비중이 큰 소프트웨어 개발 직종의 구인 공고에서 통상 제시되는 직무\\n기술의 71%에 대하여 인간을 대체할 가능성이 “보통” 또는 “높음”으로 평가했으나, 간호사 직종의\\n구인 공고에 제시되는 기술의 약 32.9%만 생성AI로 대체될 가능성이 “보통” 또는 “높음”으로 평가\\nn 인디드는 현재 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이라고 강조\\n∙ 생성AI는 직원 생산성을 극대화하여 노동 시장의 경색을 완화할 수 있으며, 물리적 작업 수행이 필요한\\n직업에서도 근로자가 핵심 업무에 집중할 수 있도록 지원 가능\\n∙ 그러나 생성AI는 논리적 오류나 사실과 다른 내용 또는 편향이나 차별과 같은 비윤리적 응답을 출력할\\n가능성도 있으므로 인간의 신중한 검토 필요\\n☞ 출처: Indeed Hiring Lab, AI at Work: Why GenAI Is More Likely To Support Workers Than Replace Them, 2024.09.25.\\n20\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 23, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 신경정보처리시스템재단은 인공지능과 머신러닝 분야의 연구 성과\\n교환을 촉진하는 것을 목적으로 하는 비영리 법인으로 매년 학제간\\n학술대회(NeurIPS)를 주최\\n- 이번 제38회 연례학술대회는 AI 연구자를 위한 실험 설계,\\nNeurIPS\\nLLM을 위한 메타 생성 알고리즘, 정렬에 대한 학제 간 통찰력\\n2024\\n등을 다룰 예정\\n기간 장소 홈페이지\\n2024.12.10~15 캐나다 밴쿠버 https://neurips.cc/\\n- GenAI Summit Maroc 2024는 인공지능과 데이터 분석에\\n초점을 맞춘 최고의 이벤트로, 250명 이상의 업계 리더, 정책\\nGenAI\\n입안자, 전문가가 모여 AI 발전을 탐구\\nSummit\\n- 이번 행사에는 오픈소스 AI, AI 주도 사이버 보안, 우수한\\nMaroc\\n의사결정을 위한 생성AI와 예측 AI 결합 등을 다룰 예정\\n2024\\n기간 장소 홈페이지\\n2024.12.10~11 모로코 https://genaimaroc.com/\\n- AI Summit Seoul 행사는 2018년 개최를 시작으로 금년도는\\n7회 행사로 개최\\n- 이번 행사는 AI와 산업의 융합에 초점을 두고 다양한 글로벌\\n기업과 기관, 학계 전문가 등 전문가들이 한자리에 모여 AI\\nAI Summit\\n및 산업 트렌드 등에 대한 주제 발표 및 워크샵 진행\\nSeoul 2024\\n기간 장소 홈페이지\\n2024.12.10~11 서울(코엑스 그랜드볼룸) https://aisummit.co.kr/\\n21\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    doc.metadata['filename'] = doc.metadata['source'] # source의 값을 filename이라는 키에 대입해서 새로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 3, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석\\nKEY Contents\\nn 미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고\\n있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과\\n실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\\n£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식\\n기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간\\n∙ AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로\\n법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용\\n∙ 그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며,\\n현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재\\nn 보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수\\n및 차별적 영향과 같은 민권 문제를 초래할 위험 보유\\n∙ 얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별\\n오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재\\n∙ 정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을\\n지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재\\n∙ 법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아\\n공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재\\n£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시\\nn 민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시\\n∙ 국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성\\n평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요\\n∙ 각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로\\n인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요\\n∙ 얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과\\n지원, 업데이트를 제공 필요\\n☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.\\n1\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 4, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표\\nKEY Contents\\nn 미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을\\n지원하기 위한 지침을 발표\\nn 지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI\\n솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구\\n£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시\\nn 미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일\\n‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표\\n∙ 미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일\\n구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획\\n∙ 이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개\\n전략적 목표에 대하여 권고사항을 제시\\nn (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해\\nAI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시\\n∙ 정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호\\n위험을 식별 및 관리하고 법률과 정책 준수를 보장\\n∙ 정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와\\n안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악\\n∙ 성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할\\n수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상\\nn (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서\\n강력한 경쟁을 보장할 것을 요구\\n∙ 계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항\\n개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한\\n계약업체 성과와 정부 기관의 임무 성과를 보장\\nn (연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘\\n공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원\\n∙ 각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에\\n가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려\\n☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in\\nGovernment, 2024.10.03.\\n2\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 5, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\n대한 투명성과 책임성을 보장 필요\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\n3\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 6, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nOECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표\\nKEY Contents\\nn OECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크,\\n정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표\\nn 보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로\\n구현하는 단계별 접근방식을 권고\\n£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련\\nn OECD가 2024년 10월 15일 안전하고 신뢰할 수 있는 AI의 원칙을 실행 가능한 정책으로 전환할\\n수 있도록 지원하는 ‘공공 부문의 AI를 위한 G7 툴킷’ 보고서를 발간\\n∙ OECD는 G7 회원국이 작성한 설문 응답 및 OECD와 UNESCO의 연구를 토대로 공공 부문에서 AI\\n활용 모범사례와 거버넌스 프레임워크, 정책 옵션과 관련된 종합적 지침 제공을 목표로 보고서를 작성\\nn G7과 EU의 AI 도입 추세를 분석한 결과, G7 회원국과 EU는 공공 부문의 AI 도입과 관련된\\n국가 전략 및 정책의 개발과 구현에서 차이가 존재\\n∙ EU·독일·미국·영국·일본은 국가 AI 전략에 공공 부문을 포함했고 프랑스는 국가 AI 전략에서는\\n공공 부문을 구체적으로 다루지 않으나 공공행정 혁신기금(FTAP)을 조성하여 60개 이상의 AI\\n프로젝트에 투자하는 등 별도의 정책을 수립\\n∙ 캐나다는 2025년 봄까지 공공 서비스를 위한 AI 전략을 개발할 계획이며, 이탈리아는 ‘공공\\n부문 디지털화를 위한 3개년 계획(2024~2026)’에 AI를 포함\\n∙ G7 회원국들은 접근방식의 차이에도 인재와 기술 개발, 조달 정책, 협력관계 구축, 윤리적이고\\n신뢰할 수 있으며 인간 중심적인 AI 관행 조성, 데이터 품질 보장 등에서 공통점을 보유\\nn AI 거버넌스 프레임워크 측면에서 G7 회원국 중 미국·캐나다·프랑스와 EU는 여러 기관이 AI를 관리하는\\n분산형 거버넌스 구조를 채택했으며 이탈리아·독일·영국은 단일 기관이 AI를 관리하는 중앙집중형\\n거버넌스를 채택\\nn G7 회원국들은 공공 부문의 운영 효율성 향상, 정책 결정 강화, 공공 서비스 개선, 정부의 투명성과\\n책임성 강화를 위해 AI를 활용하는 한편, 다양한 정책 옵션으로 AI 도입 시의 과제 해결을 모색\\n∙ AI 도입에 필수적인 인프라를 강화하기 위한 데이터 저장과 공유 솔루션 채택, AI에 적합한\\n혁신적이고 유연한 조달 절차의 수립 및 민간 파트너십 육성, 공공 부문의 AI 역량 강화, 데이터\\n거버넌스 프레임워크 구축 등이 대표적인 정책 옵션\\nn 보고서는 공공 부문의 AI 도입 시 각 단계를 신중히 관리하여 위험을 완화할 수 있도록, 문제를\\n명확히 정의하고 아이디어를 구상한 뒤 프로토타입부터 시작해 통제된 환경에서 AI를 시범 도입한\\n후 이를 개선해 본격적으로 구현하는 단계적 접근방식을 강조\\n☞ 출처: OECD, G7 Toolkit for Artificial Intelligence in the Public Sector, 2024.10.15.\\n4\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 7, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시\\nKEY Contents\\nn 세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적\\n균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표\\nn 백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한\\n이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\\n£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요\\nn 세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스\\n프레임워크를 제시한 백서를 발간\\n∙ 백서는 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거\\n활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안\\nn (과거 활용) 기존 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI\\n규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요\\n∙ 생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를\\n고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완\\n∙ 기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제\\n권한을 집중하는 방안의 장단점을 고려\\nn (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는\\n정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적\\n∙ 정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자\\n집단의 고유한 문제에 대응 필요\\n∙ 다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재\\nn (미래 계획) 생성AI 거버넌스에 대한 민첩한 준비와 함께 국제협력을 촉진하는 것으로, 정부는 빠\\n른 기술 발전과 한정된 자원, 글로벌 불확실성을 고려해 미래를 예견한 국가 전략을 개발하고 다음\\n의 활동을 추진\\n∙ 정부 내 AI 역량 향상과 AI 전문가 채용을 위한 투자를 시행하고 AI 전담 기관의 설립 필요성을 신중히 검토\\n∙ 생성AI와 인간 간 상호작용, 생성AI와 여타 기술의 융합, 생성AI 신기능과 관련된 혁신 및 이로 인한\\n새로운 위험을 탐색\\n∙ 기존 규제의 영향 평가 및 미래 AI 발전에 대비한 영향 평가로 규제 민첩성을 유지하며, 일례로\\n광범위한 도입에 앞서 규제 유예제도(샌드박스)를 시범 운영\\n∙ 지식과 인프라 공유와 AI 안전성 연구, AI 표준의 일관성 확보를 위한 국제협력 추진\\n☞ 출처: World Economic Forum, Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation, 2024.10.08.\\n5\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 8, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중\\nKEY Contents\\nn CB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며,\\nAI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도\\n비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\n£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상\\nn 글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처\\n현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석\\n∙ AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며,\\n3분기에도 역대 두 번째로 높은 비중을 기록\\n∙ 오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe\\nSuperintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록\\n∙ CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국\\n기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록\\nn 기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이\\nAI 기업인 것으로 확인\\n∙ 범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI\\n서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득\\nn AI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은\\n설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해\\n2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성\\n∙ 대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고\\n있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는\\n2024년 9월 AI 스타트업 2곳을 인수\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에\\n부응하지 못하고 실패하게 될 것으로 예상\\n∙ CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을\\n겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망\\n☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.\\n6\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 9, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개\\nKEY Contents\\nn 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는\\n‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁\\n동영상 AI 모델보다 더 높은 점수를 기록\\n£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개\\nn 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타\\n무비 젠(Meta Movie Gen)’을 공개\\n∙ 메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을\\n반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과\\n같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침\\nn 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원\\n∙ (동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대\\n16초 길이 동영상 생성을 지원\\n∙ (개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을\\n반영한 개인화 동영상을 제작 가능\\n∙ (동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과\\n같은 광범위한 수정도 지원\\n∙ (오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로\\n최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성\\n£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를\\n비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록\\n∙ 메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win\\nRate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가\\n* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해\\n승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미\\n<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.\\n7\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 10, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개\\nKEY Contents\\nn 메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량\\n모델을 포함하는 라마 3.2 시리즈를 공개\\nn 비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서\\n앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\n£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능\\nn 메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라마 3.2’를 공개\\n∙ 라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억\\n개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성\\n∙ 2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지\\n추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상\\nn 라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지\\n안의 물체 식별과 같은 이미지 추론을 지원\\n∙ 라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록\\n내용을 전달하는 문장을 생성 가능\\n∙ 이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드\\n3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서\\n57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가\\nn 라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어\\n텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화\\n∙ 모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서\\n구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수\\n∙ 일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점)\\n및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2\\n2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가\\nn 메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록\\n지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개\\n∙ 개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고\\n간소화된 방식으로 라마 모델을 구축 가능\\n* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터\\n☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.\\n8\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 11, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개\\nKEY Contents\\nn 앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를\\n능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성\\nn 몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단\\n폐쇄형 모델을 능가하는 점수를 기록\\n£몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가\\nn 미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈\\n소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개\\n∙ 몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의\\n전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중\\nE-1B 모델은 온디바이스 실행 가능\\n∙ 몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된\\n환경에서도 사용 가능한 것이 장점\\n∙ 몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를\\n구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이\\n필요한 웹 에이전트나 로봇 개발에도 유리\\n∙ AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고\\n연구와 상업적 목적의 활용을 허용\\nn AI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가\\n* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정\\n∙ 몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점),\\n‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로\\nGPT-4o(1079점)에 이어 2위\\n∙ 전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로\\n각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준\\n<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.\\n9\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 12, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개\\nKEY Contents\\nn 미스트랄AI가 네트워크 연결 없이 온디바이스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를\\n미스트랄 3B와 미스트랄 8B 버전으로 공개\\nn 벤치마크 평가에서 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마 및 라마와\\n비교해 대부분 벤치마크에서 더 높은 평가를 획득\\n£미스트랄 AI, 네트워크 연결이 필요 없는 경량 모델 ‘레 미니스트로’ 출시\\nn 프랑스의 대표 AI 스타트업 미스트랄AI(Mistral AI)가 2024년 10월 16일 네트워크 연결 없이\\n작동하는 온디바이스용 AI 모델 ‘레 미니스트로(Les Ministraux)’를 발표\\n∙ ‘미스트랄 3B’와 ‘미스트랄 8B’ 버전으로 공개된 이 모델은 경량 모델이면서도 영어책 50쪽 분량에\\n해당하는 12만 8천 개 토큰의 컨텍스트 창을 지원\\n∙ 미스트랄AI는 레 미니스트로가 번역과 스마트 어시스턴트, 분석, 자율 로봇 같은 중요 애플리케이션에\\n대하여 네트워크 연결 없이 개인정보보호가 가능한 온디바이스 추론을 원하는 고객 수요에 맞게\\n지연시간이 짧고 효율적인 솔루션을 제공한다고 강조\\n∙ 미스트랄AI는 8B 버전만 연구용으로 다운로드를 허용했으며 향후 두 모델을 클라우드 플랫폼을 통해\\n제공할 계획으로, 사용 비용은 100만 입출력 토큰 당 8B 버전은 10센트, 3B 버전은 4센트로 책정\\n£레 미니스트로, 오픈소스 모델 ‘젬마’ 및 ‘라마’ 대비 대부분 벤치마크에서 우수한 평가\\nn 벤치마크 평가 결과, 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마(Gemma)와 라마\\n(Llama)보다 대부분 벤치마크에서 더 높은 평가를 획득\\n∙ MMLU* 평가에서 미스트랄 3B는 60.9점을 얻어 구글의 ‘젬마 2 2B’(52.4점)와 메타의 ‘라마 3.2\\n3B’(56.2점)를 앞섰고, 미스트랄 8B는 65.0점으로 ‘라마 3.1 8B’(64.7점)와 1년 전 출시된 자체\\n모델 ‘미스트랄 7B’(62.5점)를 능가\\n* 다양한 주제에 대한 모델의 광범위한 지식과 추론 능력을 평가하는 벤치마크\\n∙ 미스트랄 8B는 코딩 능력을 평가하는 HumanEval pass@1*에서만 34.8점으로 ‘라마 3.1\\n8B’(37.8점)보다 소폭 낮은 점수를 기록\\n* AI 모델이 한 번의 시도로 정확한 코드를 생성할 수 있는 능력을 평가하는 벤치마크\\n<미스트랄 3B/7B와 경쟁 모델의 벤치마크 평가 비교>\\n☞ 출처: Mistral AI, Un Ministral, des Ministraux-Introducing the world’s best edge models, 2024.10.16.\\n10\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 13, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개\\nKEY Contents\\nn 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI\\n메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정\\nn 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발\\n중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획\\n£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현\\nn 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의\\nAI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표\\n∙ 사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지\\n않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는\\n‘가장 나다운 AI’를 의미\\n∙ 카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,\\nAI 메이트 서비스 ‘카나나’ 출시 계획도 공개\\nn 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를\\n지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현\\n∙ 개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화\\n경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록\\n메시지로 전송\\n∙ 카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서\\n함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공\\n∙ 카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해\\n완성도를 높여갈 계획\\nn 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나\\n에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의\\n주요 서비스에 적용할 계획\\nn 카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조\\n∙ Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서,\\n기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수\\n있는 리스크에 선제적 대응 추구\\n☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.\\n11\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상\\nKEY Contents\\nn 2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는\\n방법을 개발한 존 홉필드와 제프리 힌턴이 수상\\nn 2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI\\n모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상\\n£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상\\nn 스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤\\n교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의\\n토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여\\n∙ 홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을\\n찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발\\n∙ 힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은\\n통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴\\n유형을 활용해 새로운 예제를 생성 가능\\n∙ 힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을\\n이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세\\n£노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상\\nn 데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글\\n딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를\\n활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상\\n∙ 베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며,\\n2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계\\n* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수\\n∙ 허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델\\n‘알파폴드(AlphaFold) 2’를 2020년 발표하고 오픈소스로 공개\\n∙ 2억 개에 달하는 단백질 구조를 예측한 알파폴드 2는 과거에는 몇 년이 걸리거나 불가능하던 단백질\\n구조 예측을 몇 분 만에 완료할 수 있으며, 2024년 10월까지 190개국 200만 명 이상에 의해 사용\\n∙ 노벨위원회에 따르면 단백질의 구조 예측과 새로운 단백질의 설계는 특정 질병이나 항생제 내성의\\n발생원인 이해 및 새로운 의약품이나 나노소재 개발 등으로 인류에게 막대한 이익을 가져올 전망\\n☞ 출처: The Nobel Prize, They used physics to find patterns in information, 2024.10.08.\\nThe Nobel Prize, They have revealed proteins’ secrets through computing and artificial intelligence, 2024.10.09.\\n12\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 15, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표\\nKEY Contents\\nn 미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI\\nR&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표\\nn 국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구\\n우선순위, 주요 이해관계자별 권장 사항을 제시\\n£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시\\nn 미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고\\n신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌\\nAI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표\\n∙ 국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운\\n방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고,\\nAI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시\\nn 국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시\\n∙ (사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의\\n설계와 배포에 관한 연구를 수행 우선\\n∙ (포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에\\n대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화\\n∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI\\n애플리케이션을 우선 개발\\n∙ (AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는\\nAI 시스템 개발을 위해 더 많은 기술 발전 필요\\n∙ (글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고\\n노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립\\nn 국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구\\n의제의 목표 달성을 위한 권장 사항을 제시\\n∙ (연구 기금 제공자) 투명성을 증진하고 국제 AI 연구 협력을 지원하는 기금을 요청하며 다양한 지역에\\n서 연구 인프라 접근성을 증진하고 민관협력을 추진\\n∙ (연구 생태계 허브) 연구 재현성을 장려하고, AI 연구 가이드라인 관련 협력과 조정을 강화하며, 민간\\n분야에서 중시하는 연구 주제 이외의 연구를 지원\\n∙ (연구팀) 다학제적 팀을 우선 편성하고 지역 연구자들과 협력하며, 사회기술적 방법론과 연구 설계를\\n채택하고 위험 평가 절차를 통합\\n☞ 출처: U.S. Department of State, Global AI Research Agenda, 2024.09.23.\\n13\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 16, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간\\nKEY Contents\\nn 일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한\\n평가 관점 가이드’를 발표\\nn 가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해\\n효과적 조치를 취했을 때의 기대 목표를 제시\\n£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시\\nn 일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성\\n평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간\\n∙ 가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을\\n제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립\\n<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점>\\n평가 관점 관련 AI 안전성 요소 기대 목표\\n유해 정보의 출력 통제 인간중심, 안전성, 공정성 Ÿ LLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능\\n허위 정보와 Ÿ LLM 시스템의 출력에 대한 사실 검증 메커니즘 구축\\n인간중심, 안전성, 투명성\\n조작 방지 Ÿ LLM 시스템의 출력에 의한 사용자 결정의 조작 방지\\nŸ LLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한\\n공정성과 포용성 인간중심, 공정성, 투명성 차별 부재\\nŸ LLM 시스템의 출력을 모든 최종 사용자가 이해 가능\\n고위험 사용 및 Ÿ LLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익\\n인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ LLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호\\nŸ LLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한\\n보안 보안\\n기밀정보의 유출 방지\\nŸ LLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적\\n설명 가능성 투명성\\n으로 합리적인 범위에서 확인 가능\\nŸ LLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치\\n견고성 안전성, 투명성\\n않은 입력에 대해 안정적 출력을 제공\\nŸ LLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이\\n데이터 품질 안전성, 공정성, 투명성\\n적절히 관리되는 상태\\nŸ LLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서 시스템 사용\\n검증 가능성 투명성\\n시점까지 제공되는 상태\\nn AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포,\\n사용 단계에서 적절한 간격으로 시행될 필요\\n∙ AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며,\\n평가는 한 차례가 아니라 반복적으로 실시\\n☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.\\n14\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 17, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표\\nKEY Contents\\nn 구글 딥마인드가 강화학습 방식으로 반도체 칩 레이아웃을 설계하여 사람이 몇 주에서 몇 달이\\n걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성하는 AI 모델 ‘알파칩’을 공개\\nn 구글은 2020년 처음 알파칩에 관한 연구 논문을 발표한 뒤, 자체 AI 칩 TPU 개발 시\\n알파칩을 활용해 칩 성능을 개선하고 개발 주기를 단축\\n£알파칩, 구글의 자체 AI 칩 TPU의 레이아웃 설계에도 기여\\nn 구글 딥마인드가 2024년 9월 26일 반도체 칩의 레이아웃을 설계할 수 있는 AI 모델 ‘알파칩\\n(AlphaChip)’을 공개\\n∙ 2020년 연구 프로젝트로 시작된 알파칩은 강화학습 방식을 사용하여 반도체 칩 레이아웃을 설계하며,\\n사람이 완료하는데 몇 주에서 몇 달이 걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성 가능\\nn 구글은 2020년 알파칩에 대한 연구 논문을 처음 발표했으며, 자체 AI 칩 TPU(Tensor Processing\\nUnit) 개발 시 알파칩을 활용해 칩 레이아웃을 설계\\n∙ TPU는 제미나이(Gemini)뿐 아니라 이마젠(Imagen), 비오(Veo) 등의 이미지 및 동영상 생성 모델과\\n같은 구글 AI 시스템의 핵심 요소를 형성\\n∙ 알파칩은 최신 6세대 TPU를 포함한 새로운 세대마다 칩 레이아웃 설계를 개선해 설계주기를\\n단축하고 더 높은 성능의 칩 생산에 기여\\nn 알파칩은 바둑에 특화된 알파고(AlphaGo) 및 바둑, 체스, 쇼기(일본 장기)를 마스터한 알파제로\\n(AlphaZero)와 비슷하게 칩 레이아웃 설계를 게임처럼 접근\\n∙ 알파칩은 모든 부품을 배치할 때까지 한 번에 하나의 회로 부품을 배치하고 최종 레이아웃의 품질에 따라\\n보상을 받게 되며, 상호 연결된 부품 간 관계를 학습하고 칩 전체로 확장해 레이아웃을 개선\\nn 구글은 자체 AI 칩 TPU뿐 아니라 영국 반도체 기업 ARM과 협력해 개발한 데이터센터용 CPU인\\n액시온(Axion) 프로세서도 알파칩으로 레이아웃을 생성했으며, 타사에도 알파칩을 제공\\n∙ 대만의 반도체 기업 미디어텍(MediaTek)은 삼성 스마트폰에 사용되는 ‘다이멘시티 플래그십(Dimensity\\nFlagship) 5G’와 같은 첨단 칩 개발에 알파칩을 활용해 개발을 가속화하고 칩 성능을 개선\\nn 구글 딥마인드는 현재 알파칩의 차기 버전을 개발 중으로, 향후 알파칩이 칩 설계주기의 전 단계를\\n최적화하고 스마트폰, 의료 장비, 농업 센서 등에 사용되는 맞춤형 하드웨어의 칩 설계에 혁신을\\n가져올 것으로 기대\\n☞ 출처: Google Deepmind, How AlphaChip transformed computer chip design, 2024.09.26.\\n15\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 18, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조\\nKEY Contents\\nn 이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머\\n아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적\\nn 고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용\\n절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장\\n£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요\\nn 이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면\\n트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장\\n* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망\\n** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미\\n∙ 트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성\\n측면에서는 한계를 내포\\n∙ 트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI\\n에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아\\n처리 과정에서 지연이 발생\\nn 고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더\\n효율적이고 저렴하게 만들 수 있다고 강조\\n∙ 카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)*\\n메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화\\n* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘\\n∙ 미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월\\n‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세\\n∙ AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를\\n활용해 기반모델을 개발\\nn 고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은\\n이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적\\n∙ AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는\\nLLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요\\n∙ 최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는\\n플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱\\n확산될 것으로 예상\\n☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.\\n16\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 19, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사\\nKEY Contents\\nn MIT 산업성과센터가 설문조사를 통해 근로자 관점의 자동화 기술의 영향을 조사한 결과,\\n근로자들은 직장 내 안전, 임금, 업무 자율성 등에서 자동화를 긍정적으로 평가\\nn 복잡한 문제 해결이 필요한 작업을 수행하는 근로자 및 자신의 직무에 만족하는 근로자일수록\\n자동화의 영향에 긍정적인 것으로 확인\\n£근로자들, 직장 내 안전, 임금, 업무 자율성 등에서 자동화의 영향에 긍정적\\nn MIT 산업성과센터(IPC)는 2024년 9월 30일 9개국* 9천 명 이상의 근로자에 대한 설문조사를\\n바탕으로 근로자 관점에서 자동화 기술을 평가한 연구 결과를 공개\\n* 독일, 미국, 스페인, 영국, 이탈리아, 일본, 폴란드, 프랑스, 호주\\n∙ 연구진은 설문조사를 통해 업무 환경, 직장에서 사용되는 자동화 기술(로봇 및 AI 등), 업무와 기술에\\n대한 태도, 기술이 업무에 미치는 영향을 조사\\nn 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가\\n긍정적 영향을 미칠 것이란 응답이 우세\\n∙ 자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적\\n응답은 12.5%에 불과\\n∙ 자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에\\n미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답\\nn 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며\\n미국 근로자들이 가장 비관적 태도를 보유\\n∙ 9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다\\n우세(임금: –0.6%, 직업 안정성: -4.6%)*\\n* 긍정적 응답에서 부정적 응답 비율을 뺀 수치\\nn 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직 근로자가\\n자동화에 더 긍정적이며, 직장 내 처우도 자동화에 대한 근로자의 인식에 영향을 발휘\\n∙ 고용주가 근로자를 적절히 대우하고 안전에 투자하는 직장에서 일하는 근로자는 직장 내 자동화의\\n영향에 긍정적이며, 직무 만족도와 신뢰도도 자동화에 대한 긍정적 인식에 영향을 미치는 요인으로 확인\\nn 연구진은 조사 결과를 바탕으로 직장 내 원활한 자동화 기술 도입을 위해 직무 설계를 통해 근로자가\\n복잡한 문제를 해결할 수 있는 역할을 만들 것을 권고\\n∙ 근로자들은 신기술 사용과 관련된 보너스가 제공되면 자동화에 더 긍정적인 것으로 나타나, 생산성\\n향상을 위한 자동화 기술 사용에 금전적 보상을 제공하는 방안도 고려 필요\\n☞ 출처: MIT IPC, Automation from the Worker’s Perspective, 2024.09.30.\\n17\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 20, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려\\nKEY Contents\\nn 다이스에 따르면, AI 전문가의 73%는 2025년 이직을 계획 중이며, 58%는 2024년 중 현재보다\\n더 나은 일자리를 찾을 자신이 있다고 응답해 여타 기술 전문가 대비 직업 전망을 낙관\\nn AI 전문가들은 여타 기술 전문가 대비 AI 도구 사용에도 적극적이며, 업무에 생성AI가 상당한\\n영향을 미친다는 응답도 36%로 여타 기술 전문가(22%) 대비 높은 수치를 기록\\n£AI 전문가들, 일반적인 기술 전문가보다 직업 전망에 낙관적\\nn 미국 기술직 채용 플랫폼 다이스(Dice)의 조사에 따르면, AI 기술 전문가는 일반적인 기술 전문가\\n대비 기술 산업의 미래와 자기 경력에 대하여 낙관적\\n∙ 이번 조사는 520명의 미국 정규직 기술 전문가와 390명의 인사 전문가의 응답을 토대로 기술 분야의\\n일자리 시장 환경을 분석\\n∙ 2024년 동안 주요 빅테크가 기술직에 대한 정리해고를 단행하고 기술직 채용도 2021~2022년 대비\\n대폭 감소하는 등 일자리 시장의 침체에도 2024년 기술과 사업의 핵심 요소로 부상한 AI 분야의\\n전문가들은 직업 전망을 낙관\\nn AI 전문가의 73%는 2025년에 이직을 계획 중이며, 58%는 2024년 중 현재보다 더 나은 새로운 일자리를\\n찾을 자신이 있다고 응답\\n∙ 일반적인 기술 전문가의 경우 65%가 2025년 중 이직을 계획 중이며, 2024년 더 나은 신규 일자리를\\n찾을 수 있다고 자신하는 비율은 36%에 불과\\n∙ AI 전문가는 빅테크를 선호하는 비율이 29%로 일반적인 기술 전문가(18%) 대비 더 높게 나타났으며,\\n이는 예산 규모가 더 크고 중요한 AI 프로젝트에 관심이 있거나 빅테크의 채용 가능성에 자신 있기\\n때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가\\n가치 있다고 느끼는 전문가일수록 현재 역할에 만족할 가능성도 증대할 것으로 추론\\n∙ AI 전문가의 51%는 자신의 프로젝트가 기업에 전략적 가치가 있다고 답했으나, 36%는 투자자나\\n이사회, 외부 관계자에게 기업이 AI로 뭔가를 하고 있음을 보여주기 위한 목적이라고 응답\\nn AI 전문가들은 AI 도구 사용에도 적극적이지만, 일반적인 기술 전문가들은 업무에서 AI 도구 사용을\\n주저하는 편으로, AI 전문가들은 일주일에 1회 이상 AI를 사용하는 비율이 49%에 달했으나, 여타\\n기술 전문가들은 25%에 불과\\nn 생성AI가 미치는 영향에 대해서 AI 전문가 사이에서는 상당한 영향을 미친다는 응답이 36%, 약간의 영향을\\n미친다는 응답이 56%, 영향이 없다는 응답은 8%를 기록했으나, 여타 기술 전문가들은 22%가 상당한 영향,\\n53%는 약간의 영향, 26%는 영향이 없다고 응답\\n☞ 출처: Dice, 3 Key Lessons about the AI Tech Talent Market, 2024.09.05.\\n18\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 21, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요\\nKEY Contents\\nn 가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및\\nAI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망\\nn 기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한\\n투자를 강화할 필요\\n£생성AI로 소프트웨어 엔지니어링에서 데이터과학과 AI/ML 역량의 중요성 증대\\nn 시장조사기관 가트너(Gartner)에 따르면 2027년까지 생성AI로 인해 소프트웨어 엔지니어링\\n인력의 80%가 역량 향상이 필요할 전망\\n∙ AI로 인해 인간 엔지니어에 대한 수요가 감소하거나 심지어 AI가 인간을 대체할 것이라는 예상과\\n달리, 가트너는 AI가 향후 소프트웨어 엔지니어의 역할을 변화시키더라도 인간의 전문성과 창의성은\\n여전히 중요하다고 강조\\nn 가트너에 따르면 생성AI는 소프트웨어 엔지니어의 역할에 단기, 중기, 장기적으로 영향을 미칠 전망\\n∙ 단기적으로는 AI가 기존 개발자의 작업 패턴과 업무를 보완하며 소폭의 생산성 향상 효과를 가져오며,\\nAI의 생산성 향상 효과는 성숙한 엔지니어링 관행을 갖춘 기업의 상급 개발자에게 집중될 전망\\n∙ 중기적으로는 AI 에이전트를 통해 더 많은 업무가 자동화되어 개발자의 작업 패턴의 변화가 예상되며,\\n이는 코드 대부분이 인간이 아닌 AI로 생성되는 AI 네이티브 소프트웨어 엔지니어링의 출현을 의미해\\n자연어 프롬프트 엔지니어링과 검색 증강 생성(RAG)* 기술이 엔지니어링의 필수 역량이 될 전망\\n* 외부 데이터를 활용하여 LLM의 출력 정확성을 향상하는 기술\\n∙ 장기적으로는 기업 내 AI 기반 소프트웨어 수요가 증가하면서 이를 충족하기 위해 소프트웨어\\n엔지니어링, 데이터 과학, AI/ML(머신러닝) 분야의 고유한 기술을 갖춘 훨씬 숙련된 AI 엔지니어가\\n부상할 전망\\n£AI 엔지니어를 지원하기 위해 기업의 AI 개발자 플랫폼 투자 필요\\nn 가트너가 2023년 4분기에 미국과 영국 기업 300개를 대상으로 실시한 설문조사에 따르면 소프트웨어\\n엔지니어링 책임자의 56%가 AI/ML 엔지니어를 2024년 가장 수요가 많은 직업으로 평가\\n∙ 기업들은 AI 엔지니어를 지원하기 위해 AI 개발자 플랫폼에 투자해야 하며, AI 개발자 플랫폼은\\n기업이 AI 역량을 더욱 효율적으로 구축하고 AI를 기업 솔루션에 대규모로 통합하는 데 도움이 될 전망\\n∙ 기업들은 AI 개발자 플랫폼 투자를 통해 소프트웨어 엔지니어링팀의 역량을 강화하고 지속적인 AI\\n통합과 개발을 추진하는 도구와 프로세스를 채택 필요\\n☞ 출처: Gartner, Gartner Says Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027,\\n2024.10.03.\\n19\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 22, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박\\nKEY Contents\\nn 인디드가 2,800개 이상의 직무 기술에 대한 생성AI의 수행 능력을 분석해 인간을 대체할\\n가능성을 평가한 결과, 생성AI로 대체될 가능성이 “매우 높은” 것으로 평가된 기술은 전무\\nn 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이며, 물리적 작업\\n수행이 필요한 직무 기술에서는 인간 근로자를 대체할 가능성이 희박\\n£생성AI, 문제 해결 역량 및 물리적 작업 수행 역량의 부족으로 인간 근로자 대체에 한계\\nn 미국의 채용 플랫폼 인디드(Indeed) 산하 연구소 하이어링랩(Hiring Lab)이 2024년 9월 25일\\n발표한 연구 결과에 따르면 생성AI가 인간 근로자를 대체할 가능성은 희박\\n∙ 인디드 하이어링랩은 오픈AI의 GPT-4o로 2,800개 이상의 고유한 직무 기술에 대한 생성AI의 수행\\n능력을 분석해 생성AI가 인간을 대체할 가능성을 평가\\n∙ 연구진은 오픈AI의 GPT-4o가 △기술과 관련된 이론적 지식의 제공 역량 △기술을 사용한 문제 해결 역량\\n△기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행\\n∙ 다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은\\n2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로\\n평가됐으며, “매우 높음”으로 평가된 기술은 전무\\nn 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결\\n능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가\\n∙ 생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제\\n해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는\\n“매우 높음”이라고 평가*\\n* 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely, 5점)\\n∙ 생성AI는 물리적 작업을 수행할 몸체가 없어 실제 작업 수행이 필요한 직무 기술에서는 인간 근로자를\\n대체할 가능성이 제한적\\n∙ 일례로 생성AI는 디지털 기술 비중이 큰 소프트웨어 개발 직종의 구인 공고에서 통상 제시되는 직무\\n기술의 71%에 대하여 인간을 대체할 가능성이 “보통” 또는 “높음”으로 평가했으나, 간호사 직종의\\n구인 공고에 제시되는 기술의 약 32.9%만 생성AI로 대체될 가능성이 “보통” 또는 “높음”으로 평가\\nn 인디드는 현재 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이라고 강조\\n∙ 생성AI는 직원 생산성을 극대화하여 노동 시장의 경색을 완화할 수 있으며, 물리적 작업 수행이 필요한\\n직업에서도 근로자가 핵심 업무에 집중할 수 있도록 지원 가능\\n∙ 그러나 생성AI는 논리적 오류나 사실과 다른 내용 또는 편향이나 차별과 같은 비윤리적 응답을 출력할\\n가능성도 있으므로 인간의 신중한 검토 필요\\n☞ 출처: Indeed Hiring Lab, AI at Work: Why GenAI Is More Likely To Support Workers Than Replace Them, 2024.09.25.\\n20\\n'),\n",
       " Document(metadata={'source': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': './data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 23, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': './data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 신경정보처리시스템재단은 인공지능과 머신러닝 분야의 연구 성과\\n교환을 촉진하는 것을 목적으로 하는 비영리 법인으로 매년 학제간\\n학술대회(NeurIPS)를 주최\\n- 이번 제38회 연례학술대회는 AI 연구자를 위한 실험 설계,\\nNeurIPS\\nLLM을 위한 메타 생성 알고리즘, 정렬에 대한 학제 간 통찰력\\n2024\\n등을 다룰 예정\\n기간 장소 홈페이지\\n2024.12.10~15 캐나다 밴쿠버 https://neurips.cc/\\n- GenAI Summit Maroc 2024는 인공지능과 데이터 분석에\\n초점을 맞춘 최고의 이벤트로, 250명 이상의 업계 리더, 정책\\nGenAI\\n입안자, 전문가가 모여 AI 발전을 탐구\\nSummit\\n- 이번 행사에는 오픈소스 AI, AI 주도 사이버 보안, 우수한\\nMaroc\\n의사결정을 위한 생성AI와 예측 AI 결합 등을 다룰 예정\\n2024\\n기간 장소 홈페이지\\n2024.12.10~11 모로코 https://genaimaroc.com/\\n- AI Summit Seoul 행사는 2018년 개최를 시작으로 금년도는\\n7회 행사로 개최\\n- 이번 행사는 AI와 산업의 융합에 초점을 두고 다양한 글로벌\\n기업과 기관, 학계 전문가 등 전문가들이 한자리에 모여 AI\\nAI Summit\\n및 산업 트렌드 등에 대한 주제 발표 및 워크샵 진행\\nSeoul 2024\\n기간 장소 홈페이지\\n2024.12.10~11 서울(코엑스 그랜드볼룸) https://aisummit.co.kr/\\n21\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs # filename 들어갔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변의 충실성, 질문과 답변의 관련성 평가\n",
    "# !pip install -q ragas==0.1.19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor\n",
    "from ragas.testset.docstore import InMemoryDocumentStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기\n",
    "generator_llm = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비평기 (생성기와 비평기는 같은 모델을 쓰는게 좋음)\n",
    "critic_llm = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할기 설정\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구문 추출기 생성을 위한 모델 호출(RAGAS와의 호환을 위한 Wrapper)\n",
    "# 키워드 중심으로 \n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model = 'gpt-4o'))\n",
    "# 토큰수 에러나면 모델 바꿔서 사용!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구문 추출기 : 문서 핵심 정보 식별 및 추출 역할\n",
    "Keyphrase_extractor = KeyphraseExtractor(llm = langchain_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델도 RAGAS와의 호환을 위해 Wrapper 적용\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstore 만들기\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter = splitter,\n",
    "    embeddings = ragas_embeddings,\n",
    "    extractor = Keyphrase_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기 만들기 (생성을 하면서 평가를 함)\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm, # 생성기\n",
    "    critic_llm, # 판별기\n",
    "    ragas_embeddings, # 임베딩 모델\n",
    "    docstore=docstore # 문서 저장소\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형 분포 결정\n",
    "dirstributions = {simple : 0.4, reasoning : 0.2, multi_context : 0.2, conditional : 0.2}\n",
    "# simple : 간단한 질문\n",
    "# reasoning : 추론을 요구하는 질문\n",
    "# multi_context : 여러 맥락을 고려하는 질문\n",
    "# conditional : 조건부 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s]              [ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Molmo-72B', 'Benchmark scores', 'GPT-4o', 'MolmoE-1B', 'Allen Institute for AI']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How does GPT-4o compare to other models in terms of benchmark average scores and human preference ratings?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 전문가', '기업에서의 역할', 'AI 도구 사용', 'AI의 영향', '기술 전문가']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"\\uae30\\uc5c5\\uc5d0\\uc11c\\uc758 \\uc5ed\\ud560\" (Role in the company)\n",
      "\n",
      "Question: \"\\uae30\\uc5c5\\uc5d0\\uc11c AI \\uc804\\ubb38\\uac00\\ub4e4\\uc758 \\uc5ed\\ud560\\uc740 \\uc5b4\\ub5bb\\uac8c \\ud45c\\ud604\\ub418\\ub098\\uc694?\"  \n",
      "(How is the role of AI experts expressed in companies?)\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 시장의 경쟁 촉진', '정부 데이터와 지식재산권 보호', '공급업체 시장에서 강력한 경쟁', 'AI 기술환경의 위험관리', 'AI 전문지식 확보']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How does the guidance aim to ensure strong competition in the AI market?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '상호작용 계산', 'Codestral 맘바 7B', 'AI21 아키텍처', 'AI 에이전트 상용화']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 시장의 경쟁 촉진', '정부 데이터와 지식재산권 보호', '공급업체 시장에서 강력한 경쟁', 'AI 기술환경의 위험관리', 'AI 전문지식 확보']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"AI 기술환경의 위험관리를 위해 어떤 전략적 조달이 지원되고 있나요?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data collection standardization', 'AI model development', 'Data privacy and human rights', 'EU AI law', 'High-risk AI systems']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for a comparison of GPT-4o with other models based on benchmark average scores and human preference ratings. It is clear in specifying the model of interest (GPT-4o) and the criteria for comparison (benchmark average scores and human preference ratings), making the intent clear. However, the question does not specify which benchmarks or human preference ratings are being referred to, which could lead to ambiguity. To improve clarity and answerability, the question could specify the particular benchmarks or studies being referenced, or provide more context about the human preference ratings.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the implications of the EU AI law on the use of AI in public spaces and high-risk AI systems?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '상호작용 계산', 'Codestral 맘바 7B', 'AI21 아키텍처', 'AI 에이전트 상용화']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the significance of the release of Codestral 맘바 7B by 미스트랄 in July 2024?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the guidance's aim to ensure strong competition in the AI market. While it is clear in its intent to understand the objectives of the guidance, it lacks independence because it does not specify which guidance is being referred to. Without knowing the specific guidance document or context, it is difficult to provide a precise answer. To improve clarity and answerability, the question should specify the guidance document or context it refers to, such as a particular policy, regulation, or set of guidelines related to AI market competition.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the implications of the EU AI law on the use of AI in public spaces and high-risk AI systems. It is clear in its intent, seeking information on the effects or consequences of the EU AI law in specific contexts (public spaces and high-risk AI systems). The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge about the EU AI law and its provisions.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the conditions necessary for AI agents to be commercialized, written in Korean. It is clear in its intent, seeking specific information about the requirements or conditions for AI commercialization. The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided. However, to enhance clarity, it could specify the type of AI agents or the industry context if relevant.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The EU AI law prohibits the use of specific applications like real-time biometric identification in public spaces and imposes strict supervision on high-risk AI systems. However, it considers the particularities of law enforcement activities and sets certain exceptions.', 'verdict': 1}\n",
      "Generating:  10%|█         | 1/10 [00:52<07:56, 52.94s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는 LLM의 신뢰성을 높여야 한다.', 'verdict': 1}\n",
      "Generating:  20%|██        | 2/10 [00:59<03:27, 25.90s/it][ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['MIT 산업성과센터', '자동화 기술 영향', '근로자 안전과 임금', '설문조사 결과', '국가별 차이']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of the release of 'Codestral 맘바 7B' by '미스트랄' in July 2024. While it specifies the subject (Codestral 맘바 7B) and the event (its release), the question is unclear due to the use of non-standard characters, which may not be recognizable or interpretable by all readers. Additionally, the question assumes knowledge of what 'Codestral 맘바 7B' and '미스트랄' refer to, without providing context or explanation. To improve clarity and answerability, the question could include a brief description of what 'Codestral 맘바 7B' is, who '미스트랄' is, and why the release is significant, or specify the aspects of significance being inquired about (e.g., technological impact, market influence).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How does the perception of automation technology among workers vary by country?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the variation in perception of automation technology among workers across different countries. It is clear in its intent to understand differences in perception based on geographical location, making it specific and independent. However, the question could be improved by specifying the aspects of perception it is interested in (e.g., job security, efficiency, adaptability) or the countries of interest if applicable. Overall, the question is understandable and answerable with the provided details.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: How does the perception of automation technology among workers vary by country?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question seeks to understand how workers' perceptions of automation technology vary by country, specifically when job security concerns are prioritized. It is clear in its intent to compare perceptions across different countries and focuses on the aspect of job security. However, the question could be improved by specifying the type of automation technology or the sectors of interest, as perceptions might differ significantly depending on these factors. Additionally, it could benefit from defining what is meant by 'prioritized' in terms of job security concerns, such as whether it refers to survey data, studies, or specific metrics. Overall, the question is mostly clear but could be more precise in its scope.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: How does workers' perception of automation tech differ by country if job security concerns are prioritized?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about strategic measures supported for risk management in the AI technology environment. It is clear in its intent, seeking information on strategies or policies in place for managing risks associated with AI technology. The question is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"AI 기술환경의 위험관리를 위해 어떤 전략적 조달이 지원되고 있나요?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the general perception of automation technology among workers by country, while the second question specifically considers views on automation technology with an emphasis on job security. This introduces a different depth and focus in the inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context indicates that there is a variation in views on automation technology by country, particularly with regard to job security. In the United States, responses were more negative regarding the impact of automation on job security compared to other countries, with a negative response rate of -0.6% for income and -4.6% for job stability.', 'verdict': 1}\n",
      "Generating:  30%|███       | 3/10 [01:28<03:08, 26.97s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about how the role of AI experts is expressed in companies. It is clear in its intent, seeking information on the expression or manifestation of AI experts' roles within a corporate setting. The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided. However, to enhance specificity, the question could specify particular aspects of the role (e.g., responsibilities, impact on decision-making, integration into teams) or types of companies (e.g., tech companies, startups) if that is of interest.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How does the OMB guidance issued on October 3, 2024, aim to ensure strong competition in the AI market?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'AI 전문가들은 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가 가치 있다고 느끼는 전문가일수록 현재 역할에 만족할 가능성도 증대할 것으로 추론', 'verdict': 1}\n",
      "Generating:  40%|████      | 4/10 [01:39<02:05, 20.96s/it][ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: How do strategic collaborations between government agencies and private sectors ensure effective AI risk management while fostering competitive innovation in the tech market?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the objectives of the OMB guidance issued on October 3, 2024, specifically regarding its aim to ensure strong competition in the AI market. It is clear in specifying the document of interest (OMB guidance) and the date of issuance, as well as the specific aspect of interest (ensuring strong competition in the AI market). However, the question assumes the existence of a specific guidance document issued on a future date (October 3, 2024), which may not be accessible or verifiable at this time. To improve clarity and answerability, the question could be reframed to inquire about general strategies or principles that OMB might employ to promote competition in the AI market, without relying on a specific, potentially non-existent document.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Molmo-72B', 'Benchmark scores', 'GPT-4o', 'MolmoE-1B', 'Allen Institute for AI']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the average scores of GPT-4o in the benchmark and human preference ratings compared to other models?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the average scores of GPT-4o in a benchmark and human preference ratings, comparing it to other models. While it specifies the model of interest (GPT-4o) and the type of comparison (benchmark scores and human preference ratings), it lacks clarity on which specific benchmark is being referred to and does not provide context or criteria for the human preference ratings. To improve clarity and answerability, the question could specify the benchmark in question and provide more details on the human preference ratings, such as the criteria used for evaluation or the context in which these ratings were gathered.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking about the role of strategic collaborations between government agencies and private sectors in managing AI risks and promoting innovation in the tech market. It specifies the focus on AI risk management and competitive innovation, making it understandable and answerable for someone with knowledge in AI policy and industry dynamics. The question does not rely on external references or unspecified contexts, thus meeting the criteria for independence and clarity.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How do gov-private partnerships balance AI risk mgmt and tech innovation?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AlphaChip', 'Google Brain', 'AI model', 'Chip layout design', 'Tensor Processing Unit (TPU)']\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about strategic support for AI risk management, while the second question focuses on balancing AI risk management with technological innovation through government-private partnerships. They differ in scope and focus.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What role does Google Brain play in the development and design of AI models like AlphaChip?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of Google Brain in the development and design of AI models, specifically mentioning 'AlphaChip'. It is clear in its intent to understand the contribution or involvement of Google Brain in this context. However, the question assumes knowledge of 'AlphaChip', which may not be widely recognized or understood without additional context. To improve clarity and answerability, the question could provide a brief description of what 'AlphaChip' is or specify the aspects of development and design it is interested in (e.g., research, engineering, innovation).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the average scores of GPT-4o in the specified benchmark and human preference ratings, and how do these scores compare to other models like Molmo-72B and Jemina 1.5 Pro?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the average scores of GPT-4o in a 'specified benchmark' and human preference ratings, and seeks a comparison with other models like Molmo-72B and Jemina 1.5 Pro. While it specifies the models of interest, it refers to a 'specified benchmark' without providing details or context about what this benchmark entails. This makes the question unclear for those who do not have access to the specific benchmark information. To improve clarity and answerability, the question should include a description or name of the benchmark being referred to, or be framed in a way that does not rely on unspecified external information.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Nobel Prize in Physics and Chemistry 2024', 'Artificial Intelligence research', 'John Hopfield and Geoffrey Hinton', 'Hopfield Network and Boltzmann Machine', 'David Baker and Demis Hassabis']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What contributions have David Baker and Demis Hassabis made to the development of new protein structures and AI models?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the contributions of David Baker and Demis Hassabis to the development of new protein structures and AI models. It is clear in its intent, specifying the individuals of interest and the areas of contribution (protein structures and AI models). The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge about the work of these individuals.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'David Baker and Demis Hassabis have contributed to the development of new protein structures and AI models.', 'verdict': 1}\n",
      "Generating:  50%|█████     | 5/10 [02:35<02:46, 33.37s/it][ragas.testset.evolutions.INFO] rewritten question: \"How does GPT-4o compare to other models in terms of benchmark average scores and human preference ratings as reported by the Allen Institute for AI?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for a comparison of GPT-4o with other models based on benchmark average scores and human preference ratings as reported by the Allen Institute for AI. It specifies the model of interest (GPT-4o) and the criteria for comparison (benchmark scores and human ratings), making the intent clear. However, it assumes access to specific reports or data from the Allen Institute for AI without providing this information within the question. To improve clarity and answerability, the question could include a brief summary of the relevant findings or specify the particular report or study from the Allen Institute for AI being referenced.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AlphaChip', 'Google Brain', 'AI model', 'Chip layout design', 'Tensor Processing Unit (TPU)']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the role of AlphaChip in improving chip layout design and production cycles?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 전문가', '직업 전망', '기술 산업', '미래 계획', '기술 전문가 대비']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"\\uc9c1\\uc5c5 \\uc804\\ub9dd\\uc5d0 \\ub300\\ud55c AI \\uc804\\ubb38\\uac00\\uc758 \\uc751\\ub2f5\\uc740 \\uc5b4\\ub5a4 \\ud615\\ud0dc\\ub85c \\ub098\\ud0c0\\ub0a8\\ub2c8\\uae4c?\" (What form does the response of AI experts take regarding career prospects?)\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of AlphaChip in enhancing chip layout design and production cycles. It is clear in its intent, seeking information on the specific contributions or functions of AlphaChip in these areas. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge about AlphaChip and its applications in chip design and production.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What is the role of AlphaChip in improving chip layout design and production cycles?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the form of responses given by AI experts concerning career prospects. It is clear in its intent, seeking information on the nature or type of responses from AI experts. However, the question could be interpreted in multiple ways, such as whether it refers to the content of the responses, the medium through which they are delivered, or the general sentiment. To improve clarity, the question could specify whether it is asking about the content, medium, or sentiment of the responses, or provide more context on what aspect of 'form' is of interest.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how AlphaChip's AI model improves chip layout in a manner similar to AlphaGo's game strategy. It is clear in its intent, seeking a comparison between the methodologies or strategies used by AlphaChip's AI model and AlphaGo. However, the question assumes familiarity with both AlphaChip's AI model and AlphaGo's strategy without providing context or details about these systems. To improve clarity and answerability, the question could benefit from a brief description of AlphaChip's AI model and AlphaGo's strategy, or specify the aspects of the strategy being compared (e.g., decision-making processes, optimization techniques).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"In what way do AI experts express their views on career prospects, specifically regarding the content, medium, or sentiment of their responses?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about how AI experts express their views on career prospects, focusing on the content, medium, or sentiment of their responses. It is clear in its intent to understand the manner of expression (content, medium, sentiment) and the specific topic (career prospects). However, the question could be improved by specifying the context or scope, such as whether it refers to a particular study, survey, or platform where these views are expressed. Without such context, the question remains somewhat broad, as AI experts could express their views in numerous ways across various platforms.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI21 CEO Ori Goshen', 'AI Transformer architecture', \"AI21's AI startup\", 'Efficient AI integration', 'Mamba and Jamba alternatives']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How can efficient AI integration be achieved according to Ori Goshen, CEO of AI21?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about achieving efficient AI integration according to Ori Goshen, CEO of AI21. It specifies the topic (efficient AI integration) and the source of information (Ori Goshen, CEO of AI21), making the intent clear. However, it assumes prior knowledge of Ori Goshen's statements or writings on this topic, which are not provided within the question. To improve clarity and answerability, the question could include a brief summary or key points of Ori Goshen's views on AI integration, or specify where these views can be found.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are Ori Goshen's recommendations for achieving efficient AI integration, as discussed in the AI21 CEO's statements?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for Ori Goshen's recommendations on efficient AI integration as discussed in the AI21 CEO's statements. It specifies the person of interest (Ori Goshen) and the topic (efficient AI integration), making the intent clear. However, it assumes access to or familiarity with the specific statements made by the AI21 CEO, which are not provided within the question. To improve clarity and answerability, the question could include a brief summary or key points of the CEO's statements, or alternatively, frame the question in a way that does not rely on specific, unpublished statements.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Meta Movie Gen', 'AI-enabled era', 'Content creators', \"Runway's Gen 3\", 'Sora AI model']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the significance of Meta Movie Gen in the context of AI-enabled content creation?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of 'Meta Movie Gen' in the context of AI-enabled content creation. It is clear in its intent to understand the importance or impact of this specific tool or concept within a defined area (AI-enabled content creation). However, the question assumes familiarity with 'Meta Movie Gen' without providing any description or context about what it is or does. To improve clarity and answerability, the question could include a brief explanation of what 'Meta Movie Gen' is, or specify the aspects of AI-enabled content creation it relates to (e.g., efficiency, creativity, automation).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Meta Movie Gen, a tool for generating personalized video content, in enhancing AI-enabled content creation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of Meta Movie Gen, a tool for generating personalized video content, in the context of enhancing AI-enabled content creation. It is clear in specifying the tool of interest (Meta Movie Gen) and the broader context (AI-enabled content creation), making the intent of the question understandable. However, the question could be improved by specifying what aspects of AI-enabled content creation are being enhanced (e.g., efficiency, creativity, user engagement) to provide a more focused inquiry. Overall, the question is sufficiently clear and independent for someone with domain knowledge to provide an answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What is the significance of Meta Movie Gen, a tool for generating personalized video content, in enhancing AI-enabled content creation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking about the potential impact of integrating Meta Movie Gen with Instagram by 2025 on AI-driven personalized video content creation. It specifies the entities involved (Meta Movie Gen and Instagram) and the timeframe (by 2025), making it specific and independent. The question does not rely on external references or unspecified contexts, allowing for a direct and relevant response based on domain knowledge about AI, video content creation, and social media platforms.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"If Meta Movie Gen integrates with Instagram by 2025, how might it transform AI-driven personalized video content creation?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the overall significance of Meta Movie Gen in AI-enabled content creation, while the second question specifically addresses its impact on AI video content creation through a particular integration. They differ in scope and specific requirements.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Meta Movie Gen plans to integrate with platforms like Instagram in 2025, which could enhance AI video content creation by providing a unified platform for distribution and potentially improving the capabilities of AI tools through feedback and platform-specific optimizations.', 'verdict': 1}\n",
      "Generating:  60%|██████    | 6/10 [05:01<04:47, 71.86s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context discusses government-private partnerships in the context of AI risk management and technological innovation. It mentions the formation of collaborative teams including public officials and experts in AI governance, personal information protection, and cybersecurity to support strategic governance. Each government agency is encouraged to form consultative meetings to effectively support responsible AI governance and, during cooperation, to consider the most appropriate AI investment classification and prioritization, AI deployment volume development, and AI model utilization case selection and verification.', 'verdict': 1}\n",
      "Generating:  70%|███████   | 7/10 [05:08<02:31, 50.44s/it][ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of the release of Codestral Mamba 7B by Mystra AI in July 2024, in terms of its technological impact and market influence?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of the release of Codestral Mamba 7B by Mystra AI in July 2024, focusing on its technological impact and market influence. It is clear in specifying the subject (Codestral Mamba 7B by Mystra AI) and the aspects of interest (technological impact and market influence). However, the question assumes knowledge of the release event and its context, which may not be available to all readers. To improve clarity and answerability, the question could provide a brief description of what Codestral Mamba 7B is or its key features, or specify the aspects of technological impact and market influence it refers to (e.g., innovation, adoption rate, competitive advantage).', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['생성AI', '소프트웨어 엔지니어링', '데이터 과학', 'AI/ML 역량', 'AI 개발자 플랫폼']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How can companies strengthen their investment in AI developer platforms to promote AI integration within their organizations?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking how companies can enhance their investment in AI developer platforms to facilitate AI integration within their organizations. It specifies the focus on investment strategies and the goal of promoting AI integration, making it understandable and answerable without requiring additional context. The question is broad enough to allow for a variety of strategies and approaches, but it remains specific in its focus on AI developer platforms and organizational integration.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: How can companies strengthen their investment in AI developer platforms to promote AI integration within their organizations?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the investment focus that aids AI developer platforms in organizations to enhance AI integration. It is clear in its intent, seeking information on investment strategies or areas that could support AI developer platforms. However, the question could be improved by specifying what aspects of AI integration or developer platforms it refers to, such as infrastructure, tools, training, or collaboration. This would help narrow down the scope and provide a more targeted answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: To enhance AI integration, what investment focus aids AI developer platforms in organizations?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question is specific about companies strengthening their investment in AI developer platforms to promote AI integration, while the second question is more general and lacks specific constraints and depth regarding the role of investment in boosting AI platforms.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Investment can boost AI platforms in organizations by supporting AI engineering, integrating AI within the company, and strengthening the AI developer platform. This involves enhancing the productivity of existing developers, automating more tasks, and focusing on the development of AI-native software engineering.', 'verdict': 1}\n",
      "Generating:  80%|████████  | 8/10 [05:48<01:34, 47.36s/it][ragas.testset.evolutions.INFO] rewritten question: \"In what ways does AlphaChip's AI model optimize chip layout using strategies similar to AlphaGo's decision-making and optimization techniques in game strategy?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how AlphaChip's AI model optimizes chip layout using strategies similar to AlphaGo's decision-making and optimization techniques in game strategy. It is clear in its intent, specifying the focus on optimization techniques and drawing a parallel to AlphaGo's methods. However, it assumes familiarity with both AlphaChip's AI model and AlphaGo's techniques without providing context or details about these strategies. To improve clarity and answerability, the question could benefit from a brief description of the specific decision-making and optimization techniques used by AlphaGo that are relevant to the comparison, or a more detailed explanation of AlphaChip's AI model's approach.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '상호작용 계산', 'Codestral 맘바 7B', 'AI21 아키텍처', 'AI 에이전트 상용화']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: AI21 아키텍처는 어떤 방식으로 AI 에이전트의 신뢰성을 높이기 위해 사용되나요?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the methods used by AI21 Akita to enhance the reliability of AI agents. It is clear in its intent, seeking specific information about the techniques or approaches employed by AI21 Akita. The question is self-contained and does not rely on external references or context, making it understandable and answerable with sufficient domain knowledge about AI21 Akita's practices.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: AI21 아키텍처는 어떤 방식으로 AI 에이전트의 신뢰성을 높이기 위해 사용되나요?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how AI21's Akita enhances the reliability of large language models (LLMs) through data prioritization. It is clear in specifying the subject (AI21's Akita) and the aspect of interest (enhancing LLM reliability through data prioritization). The intent is to understand the mechanism or approach used by Akita to achieve this enhancement. The question is specific and does not rely on external references or context, making it understandable and answerable with sufficient domain knowledge.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"How does AI21's Akita enhance LLM reliability through data prioritization?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the methods used by AI21 Akita to enhance AI reliability, while the second question specifically inquires about how Akita improves LLM reliability through data prioritization. The second question is more specific, indicating a difference in depth and breadth.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  90%|█████████ | 9/10 [06:35<00:47, 47.12s/it][ragas.testset.evolutions.INFO] rewritten question: \"What role does Google Brain play in the research and engineering of AI models, specifically in the development and design of AlphaChip, an AI model designed for efficient chip layout and performance improvement?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the specific role of Google Brain in the research and engineering of AI models, with a focus on the development and design of AlphaChip. It specifies the area of interest (AI models, AlphaChip) and the aspect of Google Brain's involvement, making it understandable and answerable without needing additional context. The question is self-contained and does not rely on external references, meeting the criteria for independence and clear intent.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What role does Google Brain play in the research and engineering of AI models, specifically in the development and design of AlphaChip, an AI model designed for efficient chip layout and performance improvement?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: How does the integration of AI safety principles by Google Brain influence the design and efficiency of AlphaChip in chip layout optimization?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the influence of AI safety principles integrated by Google Brain on the design and efficiency of AlphaChip in the context of chip layout optimization. It specifies the entities involved (Google Brain, AlphaChip) and the aspect of interest (design and efficiency in chip layout optimization), making it understandable and answerable for someone with domain knowledge. However, it assumes familiarity with AlphaChip and its context within Google Brain's projects. To improve clarity for a broader audience, the question could briefly describe what AlphaChip is or its role in chip layout optimization.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does AI safety by Google Brain affect AlphaChip's design and efficiency?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"The first question focuses on the role of Google Brain in the research and engineering of AI models, specifically AlphaChip, while the second question is about AI safety's impact on AlphaChip's design and efficiency. They differ in both constraints and depth of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating: 100%|██████████| 10/10 [07:09<00:00, 42.91s/it]\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents = docs, # 문서 데이터를 전달\n",
    "    test_size = 10, # 테스트 데이터 크기\n",
    "    distributions=dirstributions,\n",
    "    with_debugging_logs = True, # 로그 활성화\n",
    "    raise_exceptions=False # 예외가 발생해도 계속 진행, 예외 발생 시 문서가 처리 되지 않거나 문서에 기록됨\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the implications of the EU AI law on ...</td>\n",
       "      <td>[무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규...</td>\n",
       "      <td>The EU AI law prohibits the use of specific ap...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What contributions have David Baker and Demis ...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학...</td>\n",
       "      <td>David Baker and Demis Hassabis have contribute...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?</td>\n",
       "      <td>[메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...</td>\n",
       "      <td>AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\uae30\\uc5c5\\uc5d0\\uc11c\\uc758 \\uc5ed\\ud560\" (...</td>\n",
       "      <td>[때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇...</td>\n",
       "      <td>AI 전문가들은 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can investment boost AI platforms in orgs?</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...</td>\n",
       "      <td>Investment can boost AI platforms in organizat...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does Akita boost LLM reliability via data ...</td>\n",
       "      <td>[메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do gov-private partnerships balance AI ris...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의...</td>\n",
       "      <td>The context discusses government-private partn...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does AI safety by Google Brain affect Alph...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드,...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How could Meta Movie Gen's 2025 Instagram inte...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 ...</td>\n",
       "      <td>Meta Movie Gen plans to integrate with platfor...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do views on automation tech vary by countr...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과...</td>\n",
       "      <td>The context indicates that there is a variatio...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': './data/SPRi AI Brief_11월호_산업동향_F....</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the implications of the EU AI law on ...   \n",
       "1  What contributions have David Baker and Demis ...   \n",
       "2                    AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?   \n",
       "3  \\uae30\\uc5c5\\uc5d0\\uc11c\\uc758 \\uc5ed\\ud560\" (...   \n",
       "4     How can investment boost AI platforms in orgs?   \n",
       "5  How does Akita boost LLM reliability via data ...   \n",
       "6  How do gov-private partnerships balance AI ris...   \n",
       "7  How does AI safety by Google Brain affect Alph...   \n",
       "8  How could Meta Movie Gen's 2025 Instagram inte...   \n",
       "9  How do views on automation tech vary by countr...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규...   \n",
       "1  [SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학...   \n",
       "2  [메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...   \n",
       "3  [때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇...   \n",
       "4  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...   \n",
       "5  [메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...   \n",
       "6  [SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의...   \n",
       "7  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드,...   \n",
       "8  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 ...   \n",
       "9  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The EU AI law prohibits the use of specific ap...         simple   \n",
       "1  David Baker and Demis Hassabis have contribute...         simple   \n",
       "2  AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답...         simple   \n",
       "3  AI 전문가들은 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가...         simple   \n",
       "4  Investment can boost AI platforms in organizat...      reasoning   \n",
       "5  The answer to given question is not present in...      reasoning   \n",
       "6  The context discusses government-private partn...  multi_context   \n",
       "7  The answer to given question is not present in...  multi_context   \n",
       "8  Meta Movie Gen plans to integrate with platfor...    conditional   \n",
       "9  The context indicates that there is a variatio...    conditional   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "1  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "2  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "3  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "4  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "5  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "6  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "7  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "8  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  \n",
       "9  [{'source': './data/SPRi AI Brief_11월호_산업동향_F....          True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = testset.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에러 발생으로 데이터 출력 안됐을 경우 사용!!(파일을 불러와서 확인!!)\n",
    "\n",
    "# test_df.to_csv('data/ragas_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('data/ragas_dataset.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contexts'][0]\n",
    "type(test_dataset[0]['contexts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# def convert_to_list(example):\n",
    "#     contexts = ast.literal_eval(example['contexts'])\n",
    "#     return{'contexts' : contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 668.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# test_dataset = test_dataset.map(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset[0]['contexts'] # 밖의 \"\"가 사라짐\n",
    "# type(test_dataset[0]['contexts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader('data/SPRi AI Brief_11월호_산업동향_F.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "split_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents = split_documents, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    '''너는 주어진 질문에 대답하는 AI야. 다음 검색된 context를 사용해서 question에 대답해줘.\n",
    "    답을 모르면, '알 수 없습니다'라고 대답해\n",
    "    \n",
    "    # Context : {context}\n",
    "    # Question : {question}\n",
    "    # Answer : \n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-3.5-turbo', temperature=0) # 토큰수 부족으로 다른 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {'context' : retriever, 'question' : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset = []\n",
    "for question in test_dataset['question']:\n",
    "    batch_dataset.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the implications of the EU AI law on the use of AI in public spaces and high-risk AI systems?',\n",
       " 'What contributions have David Baker and Demis Hassabis made to the development of new protein structures and AI models?',\n",
       " 'AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알 수 없습니다.',\n",
       " 'David Baker and Demis Hassabis have made contributions to the development of new protein structures and AI models by developing the AlphaFold 2 AI model in 2020, which is capable of predicting protein structures for millions of proteins in just a few minutes. This has revolutionized the field of protein structure prediction and has the potential to lead to a better understanding of disease mechanisms, antibiotic resistance, and the development of new drugs and nanomaterials.',\n",
       " '알 수 없습니다.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'answer' in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(['answer']).add_column('answer', answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column('answer',answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done', 'answer'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy,faithfulness,context_recall,context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]Exception raised in Job[39]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2173. Please try again in 651ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   2%|▎         | 1/40 [01:30<58:31, 90.05s/it]Exception raised in Job[33]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   5%|▌         | 2/40 [01:47<29:55, 47.26s/it]Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2220. Please try again in 666ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   8%|▊         | 3/40 [01:48<16:01, 25.99s/it]Exception raised in Job[32]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  10%|█         | 4/40 [01:58<11:59, 19.99s/it]Exception raised in Job[14]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  12%|█▎        | 5/40 [02:23<12:42, 21.79s/it]Exception raised in Job[20]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1853. Please try again in 555ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  15%|█▌        | 6/40 [02:24<08:20, 14.71s/it]Exception raised in Job[16]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2274. Please try again in 682ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  18%|█▊        | 7/40 [02:25<05:30, 10.00s/it]Exception raised in Job[10]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  20%|██        | 8/40 [02:26<03:52,  7.26s/it]Exception raised in Job[8]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1939. Please try again in 581ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  22%|██▎       | 9/40 [02:27<02:42,  5.23s/it]Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 708. Please try again in 212ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  25%|██▌       | 10/40 [02:36<03:12,  6.41s/it]Exception raised in Job[12]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199317, Requested 1867. Please try again in 355ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  28%|██▊       | 11/40 [02:41<02:52,  5.96s/it]Exception raised in Job[38]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199006, Requested 1663. Please try again in 200ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Exception raised in Job[28]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199651, Requested 2115. Please try again in 529ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  32%|███▎      | 13/40 [02:44<01:48,  4.01s/it]Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198821, Requested 2226. Please try again in 314ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  35%|███▌      | 14/40 [02:56<02:37,  6.06s/it]Exception raised in Job[9]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  38%|███▊      | 15/40 [02:58<02:01,  4.86s/it]Exception raised in Job[23]: TimeoutError()\n",
      "Evaluating:  40%|████      | 16/40 [03:00<01:34,  3.94s/it]Exception raised in Job[5]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199274, Requested 933. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  42%|████▎     | 17/40 [03:35<04:56, 12.87s/it]Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199663, Requested 1230. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  45%|████▌     | 18/40 [03:49<04:50, 13.23s/it]Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  48%|████▊     | 19/40 [03:54<03:43, 10.66s/it]Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  50%|█████     | 20/40 [04:06<03:40, 11.01s/it]Exception raised in Job[34]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199884, Requested 1652. Please try again in 460ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  52%|█████▎    | 21/40 [04:10<02:49,  8.93s/it]Exception raised in Job[17]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 875. Please try again in 262ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  55%|█████▌    | 22/40 [04:17<02:33,  8.55s/it]Exception raised in Job[21]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 697. Please try again in 209ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  57%|█████▊    | 23/40 [04:18<01:44,  6.13s/it]Exception raised in Job[11]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  60%|██████    | 24/40 [04:31<02:14,  8.39s/it]Exception raised in Job[31]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199872, Requested 2062. Please try again in 580ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  62%|██████▎   | 25/40 [04:33<01:36,  6.42s/it]Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  65%|██████▌   | 26/40 [04:46<01:55,  8.27s/it]Exception raised in Job[27]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2262. Please try again in 678ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  68%|██████▊   | 27/40 [04:47<01:21,  6.26s/it]Exception raised in Job[0]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1833. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  70%|███████   | 28/40 [05:02<01:46,  8.88s/it]Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  72%|███████▎  | 29/40 [05:23<02:16, 12.45s/it]Exception raised in Job[29]: TimeoutError()\n",
      "Evaluating:  75%|███████▌  | 30/40 [05:23<01:27,  8.79s/it]Exception raised in Job[4]: TimeoutError()\n",
      "Evaluating:  78%|███████▊  | 31/40 [05:41<01:42, 11.38s/it]Exception raised in Job[15]: TimeoutError()\n",
      "Evaluating:  80%|████████  | 32/40 [06:00<01:48, 13.59s/it]Exception raised in Job[18]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  82%|████████▎ | 33/40 [06:06<01:20, 11.48s/it]Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  85%|████████▌ | 34/40 [06:24<01:20, 13.39s/it]Exception raised in Job[22]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  88%|████████▊ | 35/40 [06:37<01:07, 13.41s/it]Exception raised in Job[6]: TimeoutError()\n",
      "Evaluating:  90%|█████████ | 36/40 [06:49<00:51, 12.99s/it]Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199262, Requested 2865. Please try again in 638ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  92%|█████████▎| 37/40 [06:50<00:28,  9.42s/it]Exception raised in Job[3]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198340, Requested 1780. Please try again in 36ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  95%|█████████▌| 38/40 [06:51<00:13,  6.84s/it]Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 197552, Requested 3498. Please try again in 315ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  98%|█████████▊| 39/40 [06:52<00:05,  5.07s/it]Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating: 100%|██████████| 40/40 [07:08<00:00, 10.72s/it]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    dataset = test_dataset,\n",
    "    metrics = [\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision\n",
    "    ]\n",
    ")\n",
    "# context_recall : 모델이 문맥에서 중요한 정보를 잘 회상, 재현 했는가\n",
    "# faithfulness : 모델의 답변이 문맥에 기반해서 사실적인가(factual)\n",
    "# answer_relevancy : 전체 질문에 대해 모델의 답변이 질문과 얼마나 관련성이 있는가\n",
    "# context_precision : 모델이 문맥에서 필요한 정보를 정확히 활용했는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|context_precision (문맥 정밀도)|faithfulness (신뢰성)|answer_relevancy (답변 적합성)|context_recall (문맥 재현율)|\n",
    "|---|---|---|---|\n",
    "|답변에 사용된 문맥이 정확했는지|답변이 문맥에 기반해 사실적(factual)인지|답변이 질문과 관련성이 있는지|답변이 문맥에서 얼마나 많은 정보를 활용했는지|\n",
    "|1.0: 답변에 사용된 정보가 문맥에서 매우 정확하게 활용됨|1.0: 답변이 문맥과 매우 정확하게 일치|1.0: 답변이 질문과 매우 높은 관련성을 가짐|1.0: 답변이 문맥의 모든 중요한 정보를 잘 회상|\n",
    "|0.0: 답변이 문맥과 무관하거나, 부정확한 정보를 활용|0.0: 답변이 문맥에 기반하지 않고, 사실과 다를 가능성이 큼|0.0: 답변이 질문과 관련이 없거나, 부정확|0.0: 답변이 문맥을 활용하지 못함|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the implications of the EU AI law on ...</td>\n",
       "      <td>[무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규...</td>\n",
       "      <td>알 수 없습니다.</td>\n",
       "      <td>The EU AI law prohibits the use of specific ap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What contributions have David Baker and Demis ...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학...</td>\n",
       "      <td>David Baker and Demis Hassabis have made contr...</td>\n",
       "      <td>David Baker and Demis Hassabis have contribute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?</td>\n",
       "      <td>[메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...</td>\n",
       "      <td>알 수 없습니다.</td>\n",
       "      <td>AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\uae30\\uc5c5\\uc5d0\\uc11c\\uc758 \\uc5ed\\ud560\" (...</td>\n",
       "      <td>[때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇...</td>\n",
       "      <td>AI 전문가의 역할은 기업에서 전략적 가치를 제공하고 있다고 인식되고 있습니다. 일...</td>\n",
       "      <td>AI 전문가들은 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can investment boost AI platforms in orgs?</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...</td>\n",
       "      <td>Investment can boost AI platforms in organizat...</td>\n",
       "      <td>Investment can boost AI platforms in organizat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the implications of the EU AI law on ...   \n",
       "1  What contributions have David Baker and Demis ...   \n",
       "2                    AI 에이전트가 상용화되기 위해 필요한 조건은 무엇인가?   \n",
       "3  \\uae30\\uc5c5\\uc5d0\\uc11c\\uc758 \\uc5ed\\ud560\" (...   \n",
       "4     How can investment boost AI platforms in orgs?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규...   \n",
       "1  [SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학...   \n",
       "2  [메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...   \n",
       "3  [때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇...   \n",
       "4  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                          알 수 없습니다.   \n",
       "1  David Baker and Demis Hassabis have made contr...   \n",
       "2                                          알 수 없습니다.   \n",
       "3  AI 전문가의 역할은 기업에서 전략적 가치를 제공하고 있다고 인식되고 있습니다. 일...   \n",
       "4  Investment can boost AI platforms in organizat...   \n",
       "\n",
       "                                        ground_truth  context_recall  \\\n",
       "0  The EU AI law prohibits the use of specific ap...             NaN   \n",
       "1  David Baker and Demis Hassabis have contribute...             NaN   \n",
       "2  AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답...             NaN   \n",
       "3  AI 전문가들은 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가...             NaN   \n",
       "4  Investment can boost AI platforms in organizat...             NaN   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_precision  \n",
       "0           NaN               NaN                NaN  \n",
       "1           NaN               NaN                NaN  \n",
       "2           NaN               NaN                NaN  \n",
       "3           NaN               NaN                NaN  \n",
       "4           NaN               NaN                NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_recall  faithfulness  answer_relevancy  context_precision\n",
       "0             NaN           NaN               NaN                NaN\n",
       "1             NaN           NaN               NaN                NaN\n",
       "2             NaN           NaN               NaN                NaN\n",
       "3             NaN           NaN               NaN                NaN\n",
       "4             NaN           NaN               NaN                NaN\n",
       "5             NaN           NaN               NaN                NaN\n",
       "6             NaN           NaN               NaN                NaN\n",
       "7             NaN           NaN               NaN                NaN\n",
       "8             NaN           NaN               NaN                NaN\n",
       "9             NaN           NaN               NaN                NaN"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[:, 'context_recall':'context_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.15.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.22.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
      "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.6/8.6 MB 67.1 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 29.3 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.9/6.9 MB 105.4 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading narwhals-1.15.1-py3-none-any.whl (232 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.0-cp311-cp311-win_amd64.whl (231 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, rpds-py, narwhals, mdurl, blinker, referencing, pydeck, markdown-it-py, gitdb, rich, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 gitdb-4.0.11 gitpython-3.1.43 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.15.1 pydeck-0.9.1 referencing-0.35.1 rich-13.9.4 rpds-py-0.22.0 smmap-5.0.1 streamlit-1.40.2 toml-0.10.2 watchdog-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
