{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.0/10.0 MB 78.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 46.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis') # 감정 분석하는 파이프 라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998656511306763}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('I love you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9991129040718079}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('I hate you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\") # 별점을 메겨준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.7805582284927368}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('We are so happy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '3 stars', 'score': 0.24557183682918549}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('이 영화 지루하고 재미없어'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '1 star', 'score': 0.38107573986053467}]\n"
     ]
    }
   ],
   "source": [
    "print(classifier('진짜 싫어'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model = 'bert-base-uncased', top_k = 2) # top_k =2 : 상위 2개만 보여줌\n",
    "# 마스크라는 빈칸에 적절한 단어를 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0378149189054966,\n",
       "  'token': 2767,\n",
       "  'token_str': 'friend',\n",
       "  'sequence': \"hello, i ' m a friend.\"},\n",
       " {'score': 0.030563192442059517,\n",
       "  'token': 4393,\n",
       "  'token_str': 'vampire',\n",
       "  'sequence': \"hello, i ' m a vampire.\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a [MASK].\") # mask 는 대문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2619807720184326,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': 'i am a role model.'},\n",
       " {'score': 0.12169697135686874,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': 'i am a fashion model.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"I am a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "text_generator = pipeline('text-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'When the Titanic crashed, I didn\\'t remember what had happened to my brother,\" says the actress. \"I would try not to look in on my brother.\\n\\n\"We\\'d walk along to find him. And we\\'re not sure who he'}]\n"
     ]
    }
   ],
   "source": [
    "print(text_generator('When the Titanic crashed, I', max_length = 50, do_sample=True)) # do_sample=True : 뒤에 나올 단어들을 확률로 선택 (예측 불가능)\n",
    "# do_sample : 가능성 높은 토큰만 선택을 할 것인지(False), 확률에 따라 랜덤으로 토큰을 선택할 것인지(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
