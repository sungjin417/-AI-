{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 자연어처리 기초 - 1차시(24.11.08)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 텍스트 전처리\n",
    "1. 정규화 : 대소문자 통일, 용어 통일, 특수문자 제거, 정규표현식\n",
    "2. 어간추출 / 표제어추출 : 단어에서 접사 제거하여 기본 형태 찾아내기, 사전에 기반하여 단어를 원형으로 변환하기\n",
    "3. 불용어 제거 : 불용어 목록 정의하고 필터링\n",
    "4. 토큰화 : 의미를 갖는 최소한의 단위로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today is an exciting friday'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is an exciting Friday'\n",
    "lower_text = text.lower() # 대문자를 소문자로 변환\n",
    "lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE WEEKEND IS SHORT, ONLY TWO DAYS LONG.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'The weekend is short, only two days long.'\n",
    "upper_text = text2.upper() # 소문자를 대문자로 변환\n",
    "upper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스마트폰은 스마트폰, 스마트폰 이라고도 할 수 있어요'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text3 = '스마트폰은 핸드폰, 휴대폰 이라고도 할 수 있어요'\n",
    "nomalized = re.sub(r'(핸드폰|휴대폰)', '스마트폰', text3)\n",
    "nomalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|구성 요소|설명|예시|\n",
    "|---|---|---|\n",
    "|특수 문자|특정 패턴에 매칭하는 메타 문자|\n",
    "|.\t|임의의 한 문자와 매칭 (줄 바꿈 제외)|\ta.b → \"a와 b 사이에 아무 문자\"|\n",
    "|*\t|앞에 있는 문자가 0번 이상 반복됨|\tab* → \"a + 0개 이상의 b\"|\n",
    "|+\t|앞에 있는 문자가 1번 이상 반복됨|\tab+ → \"a + 1개 이상의 b\"|\n",
    "|?\t|앞에 있는 문자가 0번 또는 1번 나타남|\tab? → \"a + 0개 또는 1개의 b\"|\n",
    "|문자 클래스\t|대괄호 안의 문자 중 하나와 매칭\t|\n",
    "|[abc]\t|\"a\", \"b\", \"c\" 중 하나와 매칭\t|[abc] → \"a, b, 또는 c\"|\n",
    "|[a-z]\t|소문자 알파벳 a부터 z까지의 문자 중 하나와 매칭\t|[a-z] → \"모든 소문자\"|\n",
    "|이스케이프 시퀀스\t|특정 문자 그룹과 매칭\t|\n",
    "|\\d|\t숫자 (0-9)와 매칭\t|\\d+ → \"1개 이상의 숫자\"|\n",
    "|\\s\t|공백 문자 (스페이스, 탭 등)와 매칭|\t\\s+ → \"1개 이상의 공백\"|\n",
    "|\\w\t|알파벳, 숫자, 밑줄(_)과 매칭\t|\\w+ → \"1개 이상의 단어 문자\"|\n",
    "|그룹화\t|패턴을 그룹으로 묶어 매칭 및 캡처\t|\n",
    "|()\t|괄호 안의 패턴을 그룹화하여 캡처 가능\t|(\\d{3})-(\\d{4}) → 전화번호 패턴|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요 오늘 점심은 무엇을 먹을까요 김수빈 Python AI'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4 = \"안녕하세요!!! 오늘 점심은 무엇을 먹을까요? @김수빈 #Python #AI\"\n",
    "nomalized2 = re.sub(r'[^가-힣a-zA-Z0_9\\s]','',text4)\n",
    "nomalized2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문의는  으로 보내주세요. 더 많은 정보는 https://chatgpt.com/ 에서 확인하세요.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5 = \"문의는 soocong@chunjae.co.kr 으로 보내주세요. 더 많은 정보는 https://chatgpt.com/ 에서 확인하세요.\"\n",
    "without_email = re.sub(r'\\S+@+\\S+', '', text5)\n",
    "without_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'문의는  으로 보내주세요. 더 많은 정보는  에서 확인하세요.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_url = re.sub(r'http[s]?://\\S+', '', without_email)\n",
    "without_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RMARKET\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "word = ['running', 'jumps', 'studies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'jump', 'studi']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = []\n",
    "for wor in word:\n",
    "    stems.append(stemmer.stem(wor)) # 어간 추출\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = ['running', 'jumps', 'studies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'jump', 'study']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = []\n",
    "for word in words:\n",
    "    lemma = lemmatizer.lemmatize(word,pos='v') # POS= : 옵션 (동사, 명사, 부사로 설정 가능)\n",
    "    lemmas.append(lemma)\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "text = '달리고 있는 사람들을 보았다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['달리', '고', '있다', '사람', '들', '을', '보다']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = okt.morphs(text, stem=True)\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('달리', 'Noun'),\n",
       " ('고', 'Josa'),\n",
       " ('있는', 'Adjective'),\n",
       " ('사람', 'Noun'),\n",
       " ('들', 'Suffix'),\n",
       " ('을', 'Josa'),\n",
       " ('보았다', 'Verb')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = []\n",
    "for word, tag in okt.pos(text):\n",
    "    lemmas.append((word, tag))\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RMARKET\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 문장에서 라는 단어를 로 처리합니다'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= '이 문장에서 불용어라는 단어를 불용어로 처리합니다'\n",
    "text.replace('불용어', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['This', 'is', 'a', 'simple', 'example']\n",
    "filtered = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simple', 'example']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word.lower() not in stop_words:\n",
    "        filtered.append(word)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '불용어 예시를 실행해 봅니다.'\n",
    "stop_words = {'불','를'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['불', '용어', '예시', '를', '실행', '해', '봅니다', '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = okt.morphs(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['용어', '예시', '실행', '해', '봅니다', '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ko = []\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filtered_ko.append(word)\n",
    "filtered_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 토큰화 (영어)\n",
    "1. word_tokenize\n",
    "2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RMARKET\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download() # 설치에 시간이 거리므로 설치하면 주석처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"It's difficult to create English sentence examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = word_tokeni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 토큰화 (한국어)\n",
    "1. okt\n",
    "2. hannanum\n",
    "3. kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt, Hannanum, Kkma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt() \n",
    "hannanum = Hannanum() \n",
    "kkma = Kkma() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"아버지가방에들어가신다.\" \n",
    "text2 = \"저기저뜀틀이내가뛸뜀틀인가내가안뛸뜀틀인가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okt 형태소 추출 : ['아버지', '가방', '에', '들어가신다', '.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hannanum 형태소 추출 : ['아버지가방에들어가', '이', '시ㄴ다', '.']\n",
      "kkma 형태소 추출 : ['아버지', '가방', '에', '들어가', '시', 'ㄴ다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(f'okt 형태소 추출 : {okt.morphs(text)}')\n",
    "print(f'hannanum 형태소 추출 : {hannanum.morphs(text)}')\n",
    "print(f'kkma 형태소 추출 : {kkma.morphs(text)}') # 시간비용이 더 드는 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okt 형태소 추출 : ['저', '기', '저', '뜀틀', '이내', '가', '뛸', '뜀틀', '인가', '내', '가안', '뛸', '뜀틀', '인가']\n",
      "hannanum 형태소 추출 : ['저기저뜀틀이내가뛸뜀틀인가내가안뛸뜀틀', '인가']\n",
      "kkma 형태소 추출 : ['저', '기저', '뜀틀', '이내', '가', '뛰', 'ㄹ', '뜀틀', '이', 'ㄴ가', '내가', '안', '뛰', 'ㄹ', '뜀틀', '이', 'ㄴ가']\n"
     ]
    }
   ],
   "source": [
    "print(f'okt 형태소 추출 : {okt.morphs(text2)}')\n",
    "print(f'hannanum 형태소 추출 : {hannanum.morphs(text2)}')\n",
    "print(f'kkma 형태소 추출 : {kkma.morphs(text2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okt 명사 추출 : ['아버지', '가방']\n",
      "hannanum 명사 추출 : ['아버지가방에들어가']\n",
      "kkma 명사 추출 : ['아버지', '아버지가방', '가방']\n"
     ]
    }
   ],
   "source": [
    "print(f'okt 명사 추출 : {okt.nouns(text)}')\n",
    "print(f'hannanum 명사 추출 : {hannanum.nouns(text)}')\n",
    "print(f'kkma 명사 추출 : {kkma.nouns(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okt 명사 추출 : ['뜀틀', '이내', '뜀틀', '가안', '뜀틀']\n",
      "hannanum 명사 추출 : ['저기저뜀틀이내가뛸뜀틀인가내가안뛸뜀틀']\n",
      "kkma 명사 추출 : ['뜀틀', '내가', '뜀틀이내', '기저', '이내']\n"
     ]
    }
   ],
   "source": [
    "print(f'okt 명사 추출 : {okt.nouns(text2)}')\n",
    "print(f'hannanum 명사 추출 : {hannanum.nouns(text2)}')\n",
    "print(f'kkma 명사 추출 : {kkma.nouns(text2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab\n",
    "- 형태소분석기 성능 중 가장 빠르고 성능이 좋은 편으로 유명한 한국어 자연어 처리 모델\n",
    "- mecab-ko-dic : https://github.com/Pusnow/mecab-ko-dic-msvc/releases/tag/mecab-ko-dic-2.1.1-20180720-msvc\n",
    "- mecab-ko-msvc :https://github.com/Pusnow/mecab-ko-msvc/releases/tag/release-0.9.2-msvc-3\n",
    "- https://github.com/Pusnow/mecab-python-msvc/releases\n",
    "- C드라이브 바로 아래에 mecab이라는 폴더 생성 후 mecab-ko-dic, mecab-ko-msvc 파일 언패킹\n",
    "- 비트에 맞는 python wheel 설치 후 anaconda3 > envs > 가상환경 > Lib > site-packages 폴더로 이동\n",
    "- python version 3.9인 가상환경 실행 (Anaconda Prompt)\n",
    "- 실행 후 wheel을 설치한 경로로 이동하여 pip install mecab-python3 실행\n",
    "- `커널 restart 후 코드 실행`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국어', '자연어', '처리']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "m = Mecab(dicpath = 'C:/mecab/mecab-ko-dic')\n",
    "m.nouns('한국어자연어처리')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"아버지가방에들어가신다.\" \n",
    "text2 = \"저기저뜀틀이내가뛸뜀틀인가내가안뛸뜀틀인가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['저기',\n",
       " '저',\n",
       " '뜀틀',\n",
       " '이',\n",
       " '내',\n",
       " '가',\n",
       " '뛸',\n",
       " '뜀틀',\n",
       " '인가',\n",
       " '내',\n",
       " '가',\n",
       " '안',\n",
       " '뛸',\n",
       " '뜀틀',\n",
       " '인가']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.morphs(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 텍스트 벡터화\n",
    "1. Bag-of-Words\n",
    "2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    okt = Okt()\n",
    "    text = text.replace('.', '') # 문장의 . 을 처리\n",
    "    tokens = okt.morphs(text)\n",
    "    word_dict = {}\n",
    "    bow = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in word_dict:\n",
    "            word_dict[token] = len(word_dict) # 인덱스 부여\n",
    "            bow.append(1)\n",
    "        else:\n",
    "            index = word_dict[token]\n",
    "            bow[index] += 1\n",
    "    return word_dict, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = '반복되는 단어는 단어 개수 만큼 추가 됩니다..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 1, 1, 1, 1]\n",
      "{'반복': 0, '되는': 1, '단어': 2, '는': 3, '개수': 4, '만큼': 5, '추가': 6, '됩니다': 7}\n"
     ]
    }
   ],
   "source": [
    "word_dict, bow = bag_of_words(doc)\n",
    "print(bow)\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "{'그룹': 0, '에스': 1, '파': 2, '카리나': 3, '가': 4, '미모': 5, '를': 6, '뽐냈다': 7, '는': 8, '7일': 9, '자신': 10, '의': 11, '인스타그램': 12, '에': 13, '\"': 14, '우울할': 15, '땐': 16, '이': 17, '포즈': 18, '해봐': 19, '라는': 20, '글': 21, '과': 22, '사진': 23, '을': 24, '게재': 25, '했다': 26}\n"
     ]
    }
   ],
   "source": [
    "doc = '그룹 에스파 카리나가 미모를 뽐냈다. 카리나는 7일 자신의 인스타그램에 \"우울할 땐 이포즈를 해봐\"라는 글과 사진을 게재했다.'\n",
    "word_dict, bow = bag_of_words(doc)\n",
    "print(bow)\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터화된 문장 : [[1 1 1 1 1]]\n",
      "단어 사전 : {'반복되는': 3, '단어는': 2, '단어': 1, '개수만큼': 0, '추가됩니다': 4}\n"
     ]
    }
   ],
   "source": [
    "corpus = ['반복되는 단어는 단어 개수만큼 추가됩니다.']\n",
    "vector = CountVectorizer()\n",
    "print(f'벡터화된 문장 : {vector.fit_transform(corpus).toarray()}')\n",
    "print(f'단어 사전 : {vector.vocabulary_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.fit_transform(corpus).toarray() # .toarray() : 숫자 형태로 볼려면 붙여야함 (메모리의 문제??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터화된 문장 : [[1 1 1 1]]\n",
      "단어 사전 : {'bow': 0, 'works': 3, 'same': 2, 'english': 1}\n"
     ]
    }
   ],
   "source": [
    "text = ['BOW works the same for English.']\n",
    "vect = CountVectorizer(stop_words=['the', 'for'])\n",
    "print(f'벡터화된 문장 : {vect.fit_transform(text).toarray()}')\n",
    "print(f'단어 사전 : {vect.vocabulary_}') # vocabulary_ 속성은 텍스트 데이터의 고유 단어를 인덱스로 매핑하는 단어 사전입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터화된 문장 : [[1 1 1]]\n",
      "단어 사전 : {'bow': 0, 'works': 2, 'english': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "print(f'벡터화된 문장 : {vect.fit_transform(text).toarray()}')\n",
    "print(f'단어 사전 : {vect.vocabulary_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "# DTM : 문서 단어 행렬 (Document Term Matrix)\n",
    "\n",
    "docs = [\n",
    "  '원숭이 엉덩이는 빨개',\n",
    "  '빨간건 사과',\n",
    "  '사과는 맛있어',\n",
    "  '맛있으면 바나나'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['맛있어', '맛있으면', '바나나', '빨간건', '빨개', '사과', '사과는', '엉덩이는', '원숭이']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "for doc in docs:\n",
    "    words = doc.split() # 단어단위로 분리(공백)\n",
    "    for w in words:\n",
    "        if w not in vocab:\n",
    "            vocab.append(w)\n",
    "vocab.sort()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "N = len(docs)\n",
    "print(N)\n",
    "def tf(t, d):\n",
    "    return d.count(t)\n",
    "# TF : 특정 문서 d에서 특정 단어 t의 등장 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 집합에서 얼마나 흔.하.지 않은지\n",
    "# df : 문서의 빈도\n",
    "# docs : 문장의 집합\n",
    "# doc : 한 문장씩 반환\n",
    "# t : 단어\n",
    "# N : 문장의 집합안의 문장의 수\n",
    "\n",
    "def idf(t):\n",
    "    df = 0 # 문서의빈도를 저장(t 가 등장하는 문서의 개수)\n",
    "    for doc in docs:\n",
    "        df += t in doc # True(1), False(0)로 반환 됨\n",
    "    return log((N/df+1)) # df + 1로 나누는 것은 0으로 나누는 오류를 방지하기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(t, d): \n",
    "    return tf(t,d) *idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛있어</th>\n",
       "      <th>맛있으면</th>\n",
       "      <th>바나나</th>\n",
       "      <th>빨간건</th>\n",
       "      <th>빨개</th>\n",
       "      <th>사과</th>\n",
       "      <th>사과는</th>\n",
       "      <th>엉덩이는</th>\n",
       "      <th>원숭이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   맛있어  맛있으면  바나나  빨간건  빨개  사과  사과는  엉덩이는  원숭이\n",
       "0    0     0    0    0   1   0    0     1    1\n",
       "1    0     0    0    1   0   1    0     0    0\n",
       "2    1     0    0    0   0   1    1     0    0\n",
       "3    0     1    1    0   0   0    0     0    0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result[-1].append(tf(t,d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns= vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['원숭이 엉덩이는 빨개', '빨간건 사과', '사과는 맛있어', '맛있으면 바나나']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = []\n",
    "for i in range(len(vocab)):\n",
    "    t = vocab[i]\n",
    "    result2.append(idf(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>맛있어</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>맛있으면</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>빨간건</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>빨개</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과는</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>엉덩이는</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>원숭이</th>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           IDF\n",
       "맛있어   1.609438\n",
       "맛있으면  1.609438\n",
       "바나나   1.609438\n",
       "빨간건   1.609438\n",
       "빨개    1.609438\n",
       "사과    1.098612\n",
       "사과는   1.609438\n",
       "엉덩이는  1.609438\n",
       "원숭이   1.609438"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_ = pd.DataFrame(result2, index=vocab, columns=['IDF'])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = []\n",
    "for i in range(N):\n",
    "    result3.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result3[-1].append(tfidf(t, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛있어</th>\n",
       "      <th>맛있으면</th>\n",
       "      <th>바나나</th>\n",
       "      <th>빨간건</th>\n",
       "      <th>빨개</th>\n",
       "      <th>사과</th>\n",
       "      <th>사과는</th>\n",
       "      <th>엉덩이는</th>\n",
       "      <th>원숭이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        맛있어      맛있으면       바나나  ...       사과는      엉덩이는       원숭이\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  1.609438  1.609438\n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
       "2  1.609438  0.000000  0.000000  ...  1.609438  0.000000  0.000000\n",
       "3  0.000000  1.609438  1.609438  ...  0.000000  0.000000  0.000000\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ = pd.DataFrame(result3, columns=vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런을 통한 TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 사실 이거 쓰면 짱빨리됨ㅎㅎ\n",
    "\n",
    "docs = [\n",
    "  '원숭이 엉덩이는 빨개',\n",
    "  '빨간건 사과',\n",
    "  '사과는 맛있어',\n",
    "  '맛있으면 바나나'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'원숭이': 8, '엉덩이는': 7, '빨개': 4, '빨간건': 3, '사과': 5, '사과는': 6, '맛있어': 0, '맛있으면': 1, '바나나': 2}\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer()\n",
    "vector.fit_transform(docs).toarray()\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 텍스트 임베딩 (Word2Vec)\n",
    "1. CBOW\n",
    "2. Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 지우기 pip uninstall numpy\n",
    "# 넘파이 재설치하기 pip install numpy==1.24.4\n",
    "# gensim 설치하기 pip install gensim==3.4.0\n",
    "# scipy 지우기 pip uninstall scipy\n",
    "# scipy 설치하기 pip install scipy==1.9.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    ['the', 'cat', 'is', 'on', 'the', 'mat'],\n",
    "    ['dogs', 'are', 'in', 'the', 'garden'],\n",
    "    ['we', 'love', 'playing', 'with', 'our', 'pets']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다 설치하고 업데이트!!!\n",
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('with', 0.17826786637306213),\n",
       " ('pets', 0.16072483360767365),\n",
       " ('garden', 0.10560770332813263),\n",
       " ('on', 0.09215974807739258),\n",
       " ('is', 0.027008360251784325),\n",
       " ('we', 0.00773055013269186),\n",
       " ('the', -0.037719566375017166),\n",
       " ('are', -0.045522745698690414),\n",
       " ('dogs', -0.04649786278605461),\n",
       " ('mat', -0.05902623012661934)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg = 0) # vector_size=100 : 오류나면 그냥 size로 수정(버전의 차이!!)\n",
    "# print(f'CBOW모델을 통함 cat과 가장 유사한 단어 : {cbow_model.wv.most_similar('cat')}')\n",
    "cbow_model.wv.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('with', 0.17826786637306213),\n",
       " ('pets', 0.16072483360767365),\n",
       " ('garden', 0.10560770332813263),\n",
       " ('on', 0.09215974807739258),\n",
       " ('is', 0.027008360251784325),\n",
       " ('we', 0.00773055013269186),\n",
       " ('the', -0.037719566375017166),\n",
       " ('are', -0.045522745698690414),\n",
       " ('dogs', -0.04649786278605461),\n",
       " ('mat', -0.05902623012661934)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg = 1) # 대부분 cbow를 사용\n",
    "skip_gram_model.wv.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.57735027, 0.57735027],\n",
       "       [0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.70710678, 0.        , 0.        , 0.        ],\n",
       "       [0.70710678, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.70710678, 0.        , 0.        ],\n",
       "       [0.        , 0.70710678, 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(docs)\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>맛있어</th>\n",
       "      <th>맛있으면</th>\n",
       "      <th>바나나</th>\n",
       "      <th>빨간건</th>\n",
       "      <th>빨개</th>\n",
       "      <th>사과</th>\n",
       "      <th>사과는</th>\n",
       "      <th>엉덩이는</th>\n",
       "      <th>원숭이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        맛있어      맛있으면       바나나       빨간건  ...        사과       사과는     엉덩이는      원숭이\n",
       "0  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.57735  0.57735\n",
       "1  0.000000  0.000000  0.000000  0.707107  ...  0.707107  0.000000  0.00000  0.00000\n",
       "2  0.707107  0.000000  0.000000  0.000000  ...  0.000000  0.707107  0.00000  0.00000\n",
       "3  0.000000  0.707107  0.707107  0.000000  ...  0.000000  0.000000  0.00000  0.00000\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 🌼마무리 문제\n",
    "\n",
    "아래 문제들을 풀어보세요!\n",
    "\n",
    "Q1. 음식점 리뷰 데이터를 다운로드받고 불러오세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Collecting requests (from kagglehub)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kagglehub) (4.67.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kagglehub)\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.3-py3-none-any.whl (42 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests, kagglehub\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 kagglehub-0.3.3 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (2.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (4.67.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from requests->kaggle) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\test_env\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105797 sha256=60dbcaeec838f5da0d60af260d6b0576e2c29af3367a7eb740c3be571595936f\n",
      "  Stored in directory: c:\\users\\rmarket\\appdata\\local\\pip\\cache\\wheels\\2b\\af\\a9\\70bffa2773af622d2ebea9c8d407720b86e67bd40c465bf837\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, python-slugify, bleach, kaggle\n",
      "Successfully installed bleach-6.2.0 kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\test_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ninetyninenewton/kr3-korean-restaurant-reviews-with-ratings?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142M/142M [00:04<00:00, 31.2MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설치 파일 경로: C:\\Users\\RMARKET\\.cache\\kagglehub\\datasets\\ninetyninenewton\\kr3-korean-restaurant-reviews-with-ratings\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# 캐글에서 데이터 다운로드\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"ninetyninenewton/kr3-korean-restaurant-reviews-with-ratings\")\n",
    "\n",
    "print(\"설치 파일 경로:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124388</th>\n",
       "      <td>1</td>\n",
       "      <td>삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633594</th>\n",
       "      <td>2</td>\n",
       "      <td>가볼만해요 맛있더라고요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393430</th>\n",
       "      <td>0</td>\n",
       "      <td>새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547587</th>\n",
       "      <td>1</td>\n",
       "      <td>사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125026</th>\n",
       "      <td>1</td>\n",
       "      <td>밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216066</th>\n",
       "      <td>1</td>\n",
       "      <td>음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166832</th>\n",
       "      <td>1</td>\n",
       "      <td>건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369894</th>\n",
       "      <td>1</td>\n",
       "      <td>600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179061</th>\n",
       "      <td>0</td>\n",
       "      <td>양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323012</th>\n",
       "      <td>1</td>\n",
       "      <td>깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                             Review\n",
       "124388       1  삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...\n",
       "633594       2                                       가볼만해요 맛있더라고요\n",
       "393430       0  새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...\n",
       "547587       1  사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...\n",
       "125026       1            밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다\n",
       "...        ...                                                ...\n",
       "216066       1  음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...\n",
       "166832       1  건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...\n",
       "369894       1  600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...\n",
       "179061       0  양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...\n",
       "323012       1                      깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다운받은 경로에 접근하여 csv로 읽어오기\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/RMARKET/.cache/kagglehub/datasets/ninetyninenewton/kr3-korean-restaurant-reviews-with-ratings/versions/1/kr3.tsv', sep='\\t', encoding='utf-8')\n",
    "restaurants = df.sample(n=1000, random_state=42)\n",
    "# 데이터가 너무 커요~ 랜덤으로 1000개정도만 가져와봅시다 (csv가 크면 tsv)\n",
    "restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 리뷰의 길이와 평점 사이의 관계를 분석해보세요\n",
    "\n",
    "1. 각 리뷰의 문자 수나 단어 수를 계산해보세요.\n",
    "2. 평점에 따른 리뷰의 평균 길이를 계산하여, 평점이 높은 리뷰와 평점이 낮은 리뷰의 길이 차이를 비교해보고 시각화해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 124388 to 323012\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Rating  1000 non-null   int64 \n",
      " 1   Review  1000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.59309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating\n",
       "count  1000.00000\n",
       "mean      1.18600\n",
       "std       0.59309\n",
       "min       0.00000\n",
       "25%       1.00000\n",
       "50%       1.00000\n",
       "75%       2.00000\n",
       "max       2.00000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.info()\n",
    "restaurants.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124388</th>\n",
       "      <td>1</td>\n",
       "      <td>삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633594</th>\n",
       "      <td>2</td>\n",
       "      <td>가볼만해요 맛있더라고요</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393430</th>\n",
       "      <td>0</td>\n",
       "      <td>새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547587</th>\n",
       "      <td>1</td>\n",
       "      <td>사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125026</th>\n",
       "      <td>1</td>\n",
       "      <td>밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216066</th>\n",
       "      <td>1</td>\n",
       "      <td>음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166832</th>\n",
       "      <td>1</td>\n",
       "      <td>건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369894</th>\n",
       "      <td>1</td>\n",
       "      <td>600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179061</th>\n",
       "      <td>0</td>\n",
       "      <td>양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323012</th>\n",
       "      <td>1</td>\n",
       "      <td>깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                             Review  char_count\n",
       "124388       1  삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...          36\n",
       "633594       2                                       가볼만해요 맛있더라고요          11\n",
       "393430       0  새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...         274\n",
       "547587       1  사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...          55\n",
       "125026       1            밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다          28\n",
       "...        ...                                                ...         ...\n",
       "216066       1  음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...          62\n",
       "166832       1  건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...          36\n",
       "369894       1  600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...         891\n",
       "179061       0  양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...          44\n",
       "323012       1                      깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴          23\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants['char_count'] = restaurants['Review'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124388</th>\n",
       "      <td>1</td>\n",
       "      <td>삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633594</th>\n",
       "      <td>2</td>\n",
       "      <td>가볼만해요 맛있더라고요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393430</th>\n",
       "      <td>0</td>\n",
       "      <td>새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547587</th>\n",
       "      <td>1</td>\n",
       "      <td>사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125026</th>\n",
       "      <td>1</td>\n",
       "      <td>밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216066</th>\n",
       "      <td>1</td>\n",
       "      <td>음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166832</th>\n",
       "      <td>1</td>\n",
       "      <td>건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369894</th>\n",
       "      <td>1</td>\n",
       "      <td>600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179061</th>\n",
       "      <td>0</td>\n",
       "      <td>양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323012</th>\n",
       "      <td>1</td>\n",
       "      <td>깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                             Review\n",
       "124388       1  삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...\n",
       "633594       2                                       가볼만해요 맛있더라고요\n",
       "393430       0  새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...\n",
       "547587       1  사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...\n",
       "125026       1            밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다\n",
       "...        ...                                                ...\n",
       "216066       1  음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...\n",
       "166832       1  건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...\n",
       "369894       1  600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...\n",
       "179061       0  양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...\n",
       "323012       1                      깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restaurants['Review']\n",
    "res_char = restaurants.copy()\n",
    "res_word = restaurants.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = []\n",
    "for char in res_char['Review']:\n",
    "    char_list.append(len(char.replace(\" \", \"\")))\n",
    "res_char['char'] = char_list    \n",
    "res_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124388</th>\n",
       "      <td>1</td>\n",
       "      <td>삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633594</th>\n",
       "      <td>2</td>\n",
       "      <td>가볼만해요 맛있더라고요</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393430</th>\n",
       "      <td>0</td>\n",
       "      <td>새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547587</th>\n",
       "      <td>1</td>\n",
       "      <td>사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125026</th>\n",
       "      <td>1</td>\n",
       "      <td>밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216066</th>\n",
       "      <td>1</td>\n",
       "      <td>음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166832</th>\n",
       "      <td>1</td>\n",
       "      <td>건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369894</th>\n",
       "      <td>1</td>\n",
       "      <td>600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179061</th>\n",
       "      <td>0</td>\n",
       "      <td>양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323012</th>\n",
       "      <td>1</td>\n",
       "      <td>깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rating                                             Review  word\n",
       "124388       1  삼겹만 먹다가 목살 먹었어요 냉면에   역시 저기압일 땐 고기 앞으로 가야쥬 잘 먹...    13\n",
       "633594       2                                       가볼만해요 맛있더라고요     2\n",
       "393430       0  새로 생겨서 가봤는데 생각보다는 별로였네요  라테 종류는 맛있었는데 아메리카노는 산...    84\n",
       "547587       1  사람들이 너무 많아서 주변 분위기가 너무 시끄러웠다.. 이야기를 하기 위해서는 목청...    16\n",
       "125026       1            밑에 뚜아앙 정신 차려라 세종에서 이 정도면 서비스 맛 다 좋은 편이다    12\n",
       "...        ...                                                ...   ...\n",
       "216066       1  음료와 디저트가 좀 비싸고 카페 가는 길이 좀 힘들긴 해요 그래도 그게 잊힐 만큼 ...    23\n",
       "166832       1  건강빵에 눈을 뜬 곳  건강빵도 맛있다는 걸 알게 됐어요   다른 빵보다 건강빵 등...    14\n",
       "369894       1  600번째 리뷰는 늦었지만 화이트데이 기념으로 방문한 테이블 포포! Popo가 아니...   280\n",
       "179061       0  양도 별로고 맛도 없고 원수 친구가 간다 해도 말릴 거 같아요. 그리고 컵이 약간 ...    18\n",
       "323012       1                      깔끔하고 어른들이 좋아하실만한 맛 외국인들도 많이 옴     7\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = []\n",
    "for word in res_word['Review']:\n",
    "    words = word.split()\n",
    "    word_list.append(len(words))\n",
    "res_word['word'] = word_list\n",
    "res_word.iloc[0,1]       \n",
    "res_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어의 평균 : Rating\n",
      "0    33.050000\n",
      "1    37.197068\n",
      "2    26.129371\n",
      "Name: word, dtype: float64, \n",
      "문장길이의 평균 : Rating\n",
      "0     96.190000\n",
      "1    111.385993\n",
      "2     77.898601\n",
      "Name: char, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 평점에 따른 길이이이이\n",
    "\n",
    "word = res_word.groupby('Rating')['word'].mean()\n",
    "char = res_char.groupby('Rating')['char'].mean()\n",
    "print(f'단어의 평균 : {word}, \\n문장길이의 평균 : {char}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 평점에 따라 리뷰에서 자주 등장하는 단어를 분석해보세요\n",
    "\n",
    "1. 리뷰데이터를 전처리하고 자유로운 방법으로 토큰화를 수행해보세요\n",
    "2. 토큰화된 단어들의 빈도수를 계산하고 가장 많이 등장한 단어들을 bar그래프로 시각화해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
