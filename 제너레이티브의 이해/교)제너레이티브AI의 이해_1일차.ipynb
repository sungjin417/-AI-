{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 제너레이티브AI의 이해 - 1차시(24.11.18)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VAE(Variational Auto Encoder)\n",
    "- 모델이 숫자 이미지를 압축하고, 복원하는 과정(인코더-디코더)\n",
    "- 인코더 : 입력 이미지를 잠재공간으로 매핑\n",
    "- 디코더 : 잠재 공간에서 샘플을 받아 이미지 복원\n",
    "- 가상환경 실행 후 - pip install opencv-python로 설치!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow를 활용한 celeb데이터셋에 VAE 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\RMARKET\\.cache\\kagglehub\\datasets\\yunting0123\\img-align-celeba\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yunting0123/img-align-celeba\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "image_dir = \"C:/Users/RMARKET/.cache/kagglehub/datasets/yunting0123/img-align-celeba/versions/1/t/celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'030000.png'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filenames = os.listdir(image_dir)[-1]\n",
    "img_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이미지 불러오고 전처리 하는 함수 만들기\n",
    "def load_preprocess_images(image_dir, img_size = (128, 128), num_images = 10000):\n",
    "    # 경로, 이미지 크기, 최대 로드할 이미지 개수\n",
    "    images = []\n",
    "    # 전처리 된 이미지를 추가할 리스트\n",
    "    img_filenames = os.listdir(image_dir)[:num_images]\n",
    "    for filename in img_filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        # 이미지 파일의 전체 경로를 image_dir(파일 경로) + filename(파일 이름)으로 만들어 주기\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0 # 이미지 정규화\n",
    "            # 정규화 과정\n",
    "            # rgb [204, 76, 128] -> [0.8, 0.3, 0.5]\n",
    "            images.append(img)\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.78823529, 0.88627451, 0.94901961],\n",
       "         [0.84705882, 0.92156863, 0.96862745],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.79607843, 0.89411765, 0.95294118],\n",
       "         [0.85098039, 0.92156863, 0.97254902],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.81960784, 0.90588235, 0.96078431],\n",
       "         [0.85490196, 0.9254902 , 0.97647059],\n",
       "         [0.8745098 , 0.93333333, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23529412, 0.40392157, 0.6745098 ],\n",
       "         [0.22745098, 0.39215686, 0.6627451 ],\n",
       "         [0.21176471, 0.37254902, 0.63921569],\n",
       "         ...,\n",
       "         [0.0627451 , 0.16078431, 0.40784314],\n",
       "         [0.0627451 , 0.16078431, 0.40392157],\n",
       "         [0.0627451 , 0.16078431, 0.40392157]],\n",
       "\n",
       "        [[0.2       , 0.36078431, 0.63921569],\n",
       "         [0.20784314, 0.37254902, 0.64705882],\n",
       "         [0.22745098, 0.39215686, 0.67058824],\n",
       "         ...,\n",
       "         [0.07843137, 0.18039216, 0.43921569],\n",
       "         [0.0745098 , 0.18039216, 0.43529412],\n",
       "         [0.0745098 , 0.18039216, 0.43529412]],\n",
       "\n",
       "        [[0.18039216, 0.34117647, 0.61960784],\n",
       "         [0.19607843, 0.36078431, 0.63921569],\n",
       "         [0.23137255, 0.4       , 0.68235294],\n",
       "         ...,\n",
       "         [0.08627451, 0.18823529, 0.45490196],\n",
       "         [0.08235294, 0.18823529, 0.45098039],\n",
       "         [0.08235294, 0.18823529, 0.45098039]]],\n",
       "\n",
       "\n",
       "       [[[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30196078, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30588235, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28627451, 0.29803922],\n",
       "         [0.28627451, 0.30588235, 0.31764706],\n",
       "         [0.29411765, 0.31764706, 0.32941176]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784314, 0.78431373, 0.77647059],\n",
       "         [0.81176471, 0.79215686, 0.78431373],\n",
       "         [0.82745098, 0.80392157, 0.8       ],\n",
       "         ...,\n",
       "         [0.4       , 0.41960784, 0.53333333],\n",
       "         [0.45882353, 0.47058824, 0.55686275],\n",
       "         [0.48627451, 0.49803922, 0.57254902]],\n",
       "\n",
       "        [[0.85882353, 0.83529412, 0.83529412],\n",
       "         [0.85490196, 0.83529412, 0.83529412],\n",
       "         [0.85098039, 0.83137255, 0.83137255],\n",
       "         ...,\n",
       "         [0.38039216, 0.40784314, 0.52941176],\n",
       "         [0.43137255, 0.45098039, 0.54901961],\n",
       "         [0.45882353, 0.47058824, 0.56078431]],\n",
       "\n",
       "        [[0.88235294, 0.8627451 , 0.86666667],\n",
       "         [0.8745098 , 0.85490196, 0.85882353],\n",
       "         [0.8627451 , 0.84313725, 0.84705882],\n",
       "         ...,\n",
       "         [0.37254902, 0.4       , 0.5254902 ],\n",
       "         [0.41960784, 0.43921569, 0.54509804],\n",
       "         [0.44313725, 0.45882353, 0.55294118]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22352941, 0.34117647, 0.51764706],\n",
       "         [0.21960784, 0.34509804, 0.5254902 ],\n",
       "         [0.21568627, 0.36078431, 0.54117647],\n",
       "         ...,\n",
       "         [0.25098039, 0.23921569, 0.23921569],\n",
       "         [0.25490196, 0.24313725, 0.24705882],\n",
       "         [0.25882353, 0.24705882, 0.25098039]],\n",
       "\n",
       "        [[0.22745098, 0.32156863, 0.48235294],\n",
       "         [0.22352941, 0.3254902 , 0.49019608],\n",
       "         [0.21568627, 0.34509804, 0.51372549],\n",
       "         ...,\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725],\n",
       "         [0.25098039, 0.24313725, 0.24705882]],\n",
       "\n",
       "        [[0.22745098, 0.30980392, 0.4627451 ],\n",
       "         [0.22352941, 0.31764706, 0.4745098 ],\n",
       "         [0.21960784, 0.3372549 , 0.49803922],\n",
       "         ...,\n",
       "         [0.23921569, 0.23137255, 0.23529412],\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.71372549, 0.69411765, 0.69803922],\n",
       "         [0.71764706, 0.69803922, 0.70196078],\n",
       "         [0.72941176, 0.70980392, 0.71372549],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.70588235, 0.68627451, 0.69019608],\n",
       "         [0.70980392, 0.69019608, 0.69411765],\n",
       "         [0.72156863, 0.70196078, 0.70588235],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.68627451, 0.66666667, 0.67058824],\n",
       "         [0.69019608, 0.67058824, 0.6745098 ],\n",
       "         [0.70588235, 0.68627451, 0.69019608],\n",
       "         ...,\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         ...,\n",
       "         [0.87058824, 0.8627451 , 0.87843137],\n",
       "         [0.8745098 , 0.86666667, 0.87843137],\n",
       "         [0.87843137, 0.86666667, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.87058824, 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.86666667, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.8745098 , 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.87058824, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]]],\n",
       "\n",
       "\n",
       "       [[[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.92156863, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.9372549 , 0.94117647],\n",
       "         [0.90196078, 0.9254902 , 0.92941176],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54117647, 0.49803922, 0.44313725]],\n",
       "\n",
       "        [[0.93333333, 0.94901961, 0.94901961],\n",
       "         [0.9254902 , 0.94117647, 0.94509804],\n",
       "         [0.91372549, 0.92941176, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]],\n",
       "\n",
       "        [[0.9372549 , 0.95294118, 0.95294118],\n",
       "         [0.92941176, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.93333333, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]]],\n",
       "\n",
       "\n",
       "       [[[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.83529412, 0.83921569, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.81568627, 0.81960784, 0.81960784],\n",
       "         ...,\n",
       "         [0.2       , 0.26666667, 0.38039216],\n",
       "         [0.19607843, 0.26666667, 0.38039216],\n",
       "         [0.19215686, 0.26666667, 0.38431373]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         ...,\n",
       "         [0.17647059, 0.23529412, 0.35294118],\n",
       "         [0.17647059, 0.23921569, 0.36078431],\n",
       "         [0.18039216, 0.24313725, 0.36470588]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82745098, 0.82352941],\n",
       "         ...,\n",
       "         [0.16470588, 0.21960784, 0.3372549 ],\n",
       "         [0.16862745, 0.22745098, 0.34901961],\n",
       "         [0.17254902, 0.23137255, 0.35294118]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = load_preprocess_images(image_dir)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 샘플링 함수 정의\n",
    "# 잠재공간에서 새로운 샘플을 생성하기 위해 데이터포이트들을 샘플링하는 과정\n",
    "# 각 데이터포인터들의 평균값과 로그 분산을 출력하는 함수\n",
    "def sampling(z_mean, z_log_var):\n",
    "    # 모델이 새로운 데이터포인트(z)를 생성할 수 있음\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    # 딥러닝프레임워크는 데이터 입력시 자동으로 배치 크기를 감지\n",
    "    # 0번째 자리의 값이 batch 사이즈이므로 batch라는 이름의 변수로 저장한 것\n",
    "\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # 잠재공간의 차원값\n",
    "\n",
    "    epsilon = tf.random.normal(shape = (batch, dim))\n",
    "    # 배치사이즈와 차원의 shape을 갖는 표준정규분포의 무작위값 생성\n",
    "\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "# tf.exp(0.5 z_log_var) -> 로그 분산을 표준편차로 변환하는 과정, 로그분산에 0.5를 곱하고 지수함수를 적용 -> 표준편차를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 인코더 정의\n",
    "latent_dim = 200\n",
    "# 잠재공간의 차원\n",
    "# 간단한 데이터나 테스트목적 : 2 ~ 10 정도\n",
    "# 복잡한 이미지나 고차원 : 100 ~ 200 사용\n",
    "\n",
    "encoder_input = keras.layers.Input(shape = (128, 128, 3), name='encoder_input') # shape = (가로, 세로, 차원(컬러(rgb)))\n",
    "# 128x128 사이즈의 컬러 이미지를 인풋으로 넣을 것임을 명시적으로 지정한 것\n",
    "x = keras.layers.Conv2D(32, (3,3), strides = 2, activation = 'relu', padding = 'same')(encoder_input) # padding = 'same' : 가장자리에 패딩이 들어가기 위해(입력과 출력값이 같게 하기 위해)\n",
    "# Conv2D : 공간적인 패턴 학습 가능\n",
    "# 32개 필터, (3,3)커널, 슬라이딩 간격 2\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2D(128,  (3,3), strides = 2, activation= 'relu', padding='same')(x)\n",
    "# 텐서 : 딥러닝 적인 연산이 가능하다\n",
    "# x.sahpe = (batch_size, height, width, channels)\n",
    "shape_before_flattening = x.shape[1:]\n",
    "# x를 1차원 벡터로 변환하기 전 정보 저장\n",
    "\n",
    "# 1차원 벡터로 변환 : Conv2D는 이미지의 공간적인 구조를 학습할 수 있으나 결정을 내릴 순 없음\n",
    "# 결정을 내릴 수 있는 Dense층을 쌓아주기 위해 1차원 벡터로 변환(flatten, 평탄화)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "# 인코더의 마지막 단계\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(x)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(x)\n",
    "# 두 레이어는 동일한 입력 x를 받지만, 손실함수와 역전파 과정에 의해 다른 출력을 학습\n",
    "\n",
    "z = sampling(z_mean, z_log_var)\n",
    "# 무작위 벡터값 생성\n",
    "\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "# 모델은 3개의 출력을 반환한다\n",
    "# z_mean : 인코더가 학습한 잠재 공간의 평균 벡터\n",
    "# z_log_var : 인코더가 학습한 로그 분산 벡터\n",
    "# z : 평균과 분산을 사용해 샘플링된 잠재 공간의 벡터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 디코더 정의\n",
    "decoder_input = keras.layers.Input(shape = (latent_dim,), name='decoder_input')\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "# Dense 레이어로 잠재공간의 벡터를 디코더 출력에 맞게 변환\n",
    "# prod : 이 형태의 모든 차원을 곱해 1차원 값으로 변환\n",
    "# (16,16,128) -> 16x16x128\n",
    "# 먼저 위에서 저장했던 flatten전 마지막 3차원을 1차원으로 변환 후 Dense레이어에 적용\n",
    "\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "# 원래 인코더의 마지막 출력 형태인 3차원 텐서로 다시 reshape\n",
    "x = keras.layers.Conv2DTranspose(128, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(64, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "\n",
    "decoder_output = keras.layers.Conv2D(3, (3,3), strides = 1, activation = 'sigmoid', padding='same', name='decoder_output')(x)\n",
    "decoder = keras.models.Model(decoder_input, decoder_output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 학습 루프 만들기\n",
    "def train_step(data):\n",
    "    with tf. GradientTape() as tape:\n",
    "        # with tf. GradientTape() : tensorflow에서 자동 미분을 위해 설저하는 with문\n",
    "        z_mean, z_log_var, z = encoder(data)\n",
    "        recon = decoder(z)\n",
    "        # recon : 재구성된 이미지 / 입력데이터와 비교될 이미지\n",
    "        recon_loss = tf.reduce_mean(500 * tf.losses.binary_crossentropy(data,recon))\n",
    "        # 원본 데이터와 재구성된 이미지 데이터 간의 차이를\n",
    "        # 픽셀의 이진분포롤 계산\n",
    "        # 가중치를 500 곱해서 조정\n",
    "        # reduce_mean : 배치 내 모든 데이터포인트의 평균손실을 계산한다는 의미\n",
    "\n",
    "        # 2. KL-발산 손실\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean)-tf.exp(z_log_var)), axis = 1)) \n",
    "        # KL 발산의 공식 : (1 + z_log_var - tf.square(z_mean)-tf.exp(z_log_var))\n",
    "        # axis = 1옵션을 넣었기 때문에 각 차원에 대한 합산이 이루어 짐\n",
    "        total_loss = recon_loss + kl_loss\n",
    "    grad = tape.gradient(total_loss, encoder.trainable_weights + decoder.trainable_weights) # trainable_weights : 가중치\n",
    "    optimizer.apply_gradient(zip(grad, encoder.trainable_weights + decoder.trainable_weights)) # 각각의 가중치를 업데이트\n",
    "    # 계산된 기울기를 사용하여 Adam최적화 알고리즘을 통해 인코더와 디코더의 가중치를 업데이트\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "    # 총 손실, 재구성 손실, KL-발산 손실을 반환\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(1000).batch(batch_size)\n",
    "# tf.data.Dataset.from_tensor_slices : 주어진 텐서를 받아 이를 개별 슬라이스로 나눠 데이터셋을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'apply_gradient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 현재 스텝과 배치데이터를 반환\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     total_loss, recon_loss, kl_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# 스텝이 100의 배수일 때 마다\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : total loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecon loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecon_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkl_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[51], line 20\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     18\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m kl_loss\n\u001b[0;32m     19\u001b[0m grad \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(total_loss, encoder\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m decoder\u001b[38;5;241m.\u001b[39mtrainable_weights) \u001b[38;5;66;03m# trainable_weights : 가중치\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradient\u001b[49m(\u001b[38;5;28mzip\u001b[39m(grad, encoder\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m decoder\u001b[38;5;241m.\u001b[39mtrainable_weights)) \u001b[38;5;66;03m# 각각의 가중치를 업데이트\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 계산된 기울기를 사용하여 Adam최적화 알고리즘을 통해 인코더와 디코더의 가중치를 업데이트\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, recon_loss, kl_loss\n",
      "File \u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:876\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper:\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hyper(name)\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:866\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOptimizerV2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[0;32m    869\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hyper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'apply_gradient'"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} / {epochs}')\n",
    "    for step, batch_data in enumerate(dataset):\n",
    "        # 현재 스텝과 배치데이터를 반환\n",
    "        total_loss, recon_loss, kl_loss = train_step(batch_data)\n",
    "        if step % 100 == 0:\n",
    "            # 스텝이 100의 배수일 때 마다\n",
    "            print(f'step{step} : total loss = {total_loss.numpy():.4f},'\n",
    "                  f'recon loss : {recon_loss.numpy():.4f}'\n",
    "                  f'KL loss : {kl_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Torch를 활용한 MNIST데이터셋에 VAE 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 🌼마무리 문제\n",
    "\n",
    "다양한 데이터셋을 적용해보세요\n",
    "\n",
    "Q1. Fashion MNIST\n",
    "- 28X28 크기의 패션 아이템 이미지로 구성된 흑백 이미지 데이터셋\n",
    "\n",
    "\n",
    "Q2. CIFAR-10\n",
    "- 32X32 크기의 색상이 있는 자동차, 동물 등 다양한 객체가 포함된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fashion MNIST 데이터셋 로드 (28x28 크기의 패션 아이템 이미지)\n",
    "trans = transforms.ToTensor()\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)\n",
    "data_loader = DataLoader(fashion_mnist_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR-10 데이터셋 로드 (32x32 크기의 컬러 이미지)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 데이터 정규화\n",
    "])\n",
    "cifar10_data = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(cifar10_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
