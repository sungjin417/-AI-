{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 RAG기법의 이해와 적용 - 4차시(24.12.03)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CLASS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFPlumberLoader('data/SPRi AI Brief_11월호_산업동향_F.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs[3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 3, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석\\nKEY Contents\\nn 미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고\\n있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과\\n실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\\n£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식\\n기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간\\n∙ AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로\\n법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용\\n∙ 그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며,\\n현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재\\nn 보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수\\n및 차별적 영향과 같은 민권 문제를 초래할 위험 보유\\n∙ 얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별\\n오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재\\n∙ 정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을\\n지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재\\n∙ 법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아\\n공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재\\n£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시\\nn 민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시\\n∙ 국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성\\n평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요\\n∙ 각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로\\n인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요\\n∙ 얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과\\n지원, 업데이트를 제공 필요\\n☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.\\n1\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 4, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표\\nKEY Contents\\nn 미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을\\n지원하기 위한 지침을 발표\\nn 지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI\\n솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구\\n£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시\\nn 미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일\\n‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표\\n∙ 미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일\\n구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획\\n∙ 이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개\\n전략적 목표에 대하여 권고사항을 제시\\nn (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해\\nAI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시\\n∙ 정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호\\n위험을 식별 및 관리하고 법률과 정책 준수를 보장\\n∙ 정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와\\n안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악\\n∙ 성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할\\n수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상\\nn (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서\\n강력한 경쟁을 보장할 것을 요구\\n∙ 계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항\\n개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한\\n계약업체 성과와 정부 기관의 임무 성과를 보장\\nn (연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘\\n공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원\\n∙ 각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에\\n가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려\\n☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in\\nGovernment, 2024.10.03.\\n2\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 5, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\n대한 투명성과 책임성을 보장 필요\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\n3\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 6, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nOECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표\\nKEY Contents\\nn OECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크,\\n정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표\\nn 보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로\\n구현하는 단계별 접근방식을 권고\\n£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련\\nn OECD가 2024년 10월 15일 안전하고 신뢰할 수 있는 AI의 원칙을 실행 가능한 정책으로 전환할\\n수 있도록 지원하는 ‘공공 부문의 AI를 위한 G7 툴킷’ 보고서를 발간\\n∙ OECD는 G7 회원국이 작성한 설문 응답 및 OECD와 UNESCO의 연구를 토대로 공공 부문에서 AI\\n활용 모범사례와 거버넌스 프레임워크, 정책 옵션과 관련된 종합적 지침 제공을 목표로 보고서를 작성\\nn G7과 EU의 AI 도입 추세를 분석한 결과, G7 회원국과 EU는 공공 부문의 AI 도입과 관련된\\n국가 전략 및 정책의 개발과 구현에서 차이가 존재\\n∙ EU·독일·미국·영국·일본은 국가 AI 전략에 공공 부문을 포함했고 프랑스는 국가 AI 전략에서는\\n공공 부문을 구체적으로 다루지 않으나 공공행정 혁신기금(FTAP)을 조성하여 60개 이상의 AI\\n프로젝트에 투자하는 등 별도의 정책을 수립\\n∙ 캐나다는 2025년 봄까지 공공 서비스를 위한 AI 전략을 개발할 계획이며, 이탈리아는 ‘공공\\n부문 디지털화를 위한 3개년 계획(2024~2026)’에 AI를 포함\\n∙ G7 회원국들은 접근방식의 차이에도 인재와 기술 개발, 조달 정책, 협력관계 구축, 윤리적이고\\n신뢰할 수 있으며 인간 중심적인 AI 관행 조성, 데이터 품질 보장 등에서 공통점을 보유\\nn AI 거버넌스 프레임워크 측면에서 G7 회원국 중 미국·캐나다·프랑스와 EU는 여러 기관이 AI를 관리하는\\n분산형 거버넌스 구조를 채택했으며 이탈리아·독일·영국은 단일 기관이 AI를 관리하는 중앙집중형\\n거버넌스를 채택\\nn G7 회원국들은 공공 부문의 운영 효율성 향상, 정책 결정 강화, 공공 서비스 개선, 정부의 투명성과\\n책임성 강화를 위해 AI를 활용하는 한편, 다양한 정책 옵션으로 AI 도입 시의 과제 해결을 모색\\n∙ AI 도입에 필수적인 인프라를 강화하기 위한 데이터 저장과 공유 솔루션 채택, AI에 적합한\\n혁신적이고 유연한 조달 절차의 수립 및 민간 파트너십 육성, 공공 부문의 AI 역량 강화, 데이터\\n거버넌스 프레임워크 구축 등이 대표적인 정책 옵션\\nn 보고서는 공공 부문의 AI 도입 시 각 단계를 신중히 관리하여 위험을 완화할 수 있도록, 문제를\\n명확히 정의하고 아이디어를 구상한 뒤 프로토타입부터 시작해 통제된 환경에서 AI를 시범 도입한\\n후 이를 개선해 본격적으로 구현하는 단계적 접근방식을 강조\\n☞ 출처: OECD, G7 Toolkit for Artificial Intelligence in the Public Sector, 2024.10.15.\\n4\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 7, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시\\nKEY Contents\\nn 세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적\\n균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표\\nn 백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한\\n이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\\n£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요\\nn 세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스\\n프레임워크를 제시한 백서를 발간\\n∙ 백서는 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거\\n활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안\\nn (과거 활용) 기존 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI\\n규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요\\n∙ 생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를\\n고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완\\n∙ 기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제\\n권한을 집중하는 방안의 장단점을 고려\\nn (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는\\n정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적\\n∙ 정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자\\n집단의 고유한 문제에 대응 필요\\n∙ 다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재\\nn (미래 계획) 생성AI 거버넌스에 대한 민첩한 준비와 함께 국제협력을 촉진하는 것으로, 정부는 빠\\n른 기술 발전과 한정된 자원, 글로벌 불확실성을 고려해 미래를 예견한 국가 전략을 개발하고 다음\\n의 활동을 추진\\n∙ 정부 내 AI 역량 향상과 AI 전문가 채용을 위한 투자를 시행하고 AI 전담 기관의 설립 필요성을 신중히 검토\\n∙ 생성AI와 인간 간 상호작용, 생성AI와 여타 기술의 융합, 생성AI 신기능과 관련된 혁신 및 이로 인한\\n새로운 위험을 탐색\\n∙ 기존 규제의 영향 평가 및 미래 AI 발전에 대비한 영향 평가로 규제 민첩성을 유지하며, 일례로\\n광범위한 도입에 앞서 규제 유예제도(샌드박스)를 시범 운영\\n∙ 지식과 인프라 공유와 AI 안전성 연구, AI 표준의 일관성 확보를 위한 국제협력 추진\\n☞ 출처: World Economic Forum, Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation, 2024.10.08.\\n5\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 8, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중\\nKEY Contents\\nn CB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며,\\nAI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도\\n비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\n£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상\\nn 글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처\\n현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석\\n∙ AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며,\\n3분기에도 역대 두 번째로 높은 비중을 기록\\n∙ 오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe\\nSuperintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록\\n∙ CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국\\n기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록\\nn 기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이\\nAI 기업인 것으로 확인\\n∙ 범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI\\n서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득\\nn AI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은\\n설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해\\n2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성\\n∙ 대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고\\n있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는\\n2024년 9월 AI 스타트업 2곳을 인수\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에\\n부응하지 못하고 실패하게 될 것으로 예상\\n∙ CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을\\n겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망\\n☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.\\n6\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 9, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개\\nKEY Contents\\nn 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는\\n‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁\\n동영상 AI 모델보다 더 높은 점수를 기록\\n£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개\\nn 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타\\n무비 젠(Meta Movie Gen)’을 공개\\n∙ 메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을\\n반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과\\n같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침\\nn 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원\\n∙ (동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대\\n16초 길이 동영상 생성을 지원\\n∙ (개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을\\n반영한 개인화 동영상을 제작 가능\\n∙ (동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과\\n같은 광범위한 수정도 지원\\n∙ (오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로\\n최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성\\n£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를\\n비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록\\n∙ 메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win\\nRate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가\\n* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해\\n승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미\\n<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.\\n7\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 10, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개\\nKEY Contents\\nn 메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량\\n모델을 포함하는 라마 3.2 시리즈를 공개\\nn 비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서\\n앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\n£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능\\nn 메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라마 3.2’를 공개\\n∙ 라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억\\n개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성\\n∙ 2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지\\n추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상\\nn 라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지\\n안의 물체 식별과 같은 이미지 추론을 지원\\n∙ 라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록\\n내용을 전달하는 문장을 생성 가능\\n∙ 이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드\\n3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서\\n57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가\\nn 라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어\\n텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화\\n∙ 모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서\\n구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수\\n∙ 일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점)\\n및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2\\n2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가\\nn 메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록\\n지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개\\n∙ 개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고\\n간소화된 방식으로 라마 모델을 구축 가능\\n* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터\\n☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.\\n8\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 11, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개\\nKEY Contents\\nn 앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를\\n능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성\\nn 몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단\\n폐쇄형 모델을 능가하는 점수를 기록\\n£몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가\\nn 미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈\\n소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개\\n∙ 몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의\\n전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중\\nE-1B 모델은 온디바이스 실행 가능\\n∙ 몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된\\n환경에서도 사용 가능한 것이 장점\\n∙ 몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를\\n구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이\\n필요한 웹 에이전트나 로봇 개발에도 유리\\n∙ AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고\\n연구와 상업적 목적의 활용을 허용\\nn AI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가\\n* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정\\n∙ 몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점),\\n‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로\\nGPT-4o(1079점)에 이어 2위\\n∙ 전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로\\n각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준\\n<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.\\n9\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 12, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개\\nKEY Contents\\nn 미스트랄AI가 네트워크 연결 없이 온디바이스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를\\n미스트랄 3B와 미스트랄 8B 버전으로 공개\\nn 벤치마크 평가에서 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마 및 라마와\\n비교해 대부분 벤치마크에서 더 높은 평가를 획득\\n£미스트랄 AI, 네트워크 연결이 필요 없는 경량 모델 ‘레 미니스트로’ 출시\\nn 프랑스의 대표 AI 스타트업 미스트랄AI(Mistral AI)가 2024년 10월 16일 네트워크 연결 없이\\n작동하는 온디바이스용 AI 모델 ‘레 미니스트로(Les Ministraux)’를 발표\\n∙ ‘미스트랄 3B’와 ‘미스트랄 8B’ 버전으로 공개된 이 모델은 경량 모델이면서도 영어책 50쪽 분량에\\n해당하는 12만 8천 개 토큰의 컨텍스트 창을 지원\\n∙ 미스트랄AI는 레 미니스트로가 번역과 스마트 어시스턴트, 분석, 자율 로봇 같은 중요 애플리케이션에\\n대하여 네트워크 연결 없이 개인정보보호가 가능한 온디바이스 추론을 원하는 고객 수요에 맞게\\n지연시간이 짧고 효율적인 솔루션을 제공한다고 강조\\n∙ 미스트랄AI는 8B 버전만 연구용으로 다운로드를 허용했으며 향후 두 모델을 클라우드 플랫폼을 통해\\n제공할 계획으로, 사용 비용은 100만 입출력 토큰 당 8B 버전은 10센트, 3B 버전은 4센트로 책정\\n£레 미니스트로, 오픈소스 모델 ‘젬마’ 및 ‘라마’ 대비 대부분 벤치마크에서 우수한 평가\\nn 벤치마크 평가 결과, 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마(Gemma)와 라마\\n(Llama)보다 대부분 벤치마크에서 더 높은 평가를 획득\\n∙ MMLU* 평가에서 미스트랄 3B는 60.9점을 얻어 구글의 ‘젬마 2 2B’(52.4점)와 메타의 ‘라마 3.2\\n3B’(56.2점)를 앞섰고, 미스트랄 8B는 65.0점으로 ‘라마 3.1 8B’(64.7점)와 1년 전 출시된 자체\\n모델 ‘미스트랄 7B’(62.5점)를 능가\\n* 다양한 주제에 대한 모델의 광범위한 지식과 추론 능력을 평가하는 벤치마크\\n∙ 미스트랄 8B는 코딩 능력을 평가하는 HumanEval pass@1*에서만 34.8점으로 ‘라마 3.1\\n8B’(37.8점)보다 소폭 낮은 점수를 기록\\n* AI 모델이 한 번의 시도로 정확한 코드를 생성할 수 있는 능력을 평가하는 벤치마크\\n<미스트랄 3B/7B와 경쟁 모델의 벤치마크 평가 비교>\\n☞ 출처: Mistral AI, Un Ministral, des Ministraux-Introducing the world’s best edge models, 2024.10.16.\\n10\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 13, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개\\nKEY Contents\\nn 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI\\n메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정\\nn 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발\\n중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획\\n£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현\\nn 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의\\nAI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표\\n∙ 사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지\\n않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는\\n‘가장 나다운 AI’를 의미\\n∙ 카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,\\nAI 메이트 서비스 ‘카나나’ 출시 계획도 공개\\nn 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를\\n지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현\\n∙ 개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화\\n경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록\\n메시지로 전송\\n∙ 카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서\\n함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공\\n∙ 카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해\\n완성도를 높여갈 계획\\nn 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나\\n에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의\\n주요 서비스에 적용할 계획\\nn 카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조\\n∙ Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서,\\n기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수\\n있는 리스크에 선제적 대응 추구\\n☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.\\n11\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상\\nKEY Contents\\nn 2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는\\n방법을 개발한 존 홉필드와 제프리 힌턴이 수상\\nn 2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI\\n모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상\\n£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상\\nn 스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤\\n교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의\\n토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여\\n∙ 홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을\\n찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발\\n∙ 힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은\\n통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴\\n유형을 활용해 새로운 예제를 생성 가능\\n∙ 힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을\\n이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세\\n£노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상\\nn 데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글\\n딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를\\n활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상\\n∙ 베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며,\\n2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계\\n* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수\\n∙ 허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델\\n‘알파폴드(AlphaFold) 2’를 2020년 발표하고 오픈소스로 공개\\n∙ 2억 개에 달하는 단백질 구조를 예측한 알파폴드 2는 과거에는 몇 년이 걸리거나 불가능하던 단백질\\n구조 예측을 몇 분 만에 완료할 수 있으며, 2024년 10월까지 190개국 200만 명 이상에 의해 사용\\n∙ 노벨위원회에 따르면 단백질의 구조 예측과 새로운 단백질의 설계는 특정 질병이나 항생제 내성의\\n발생원인 이해 및 새로운 의약품이나 나노소재 개발 등으로 인류에게 막대한 이익을 가져올 전망\\n☞ 출처: The Nobel Prize, They used physics to find patterns in information, 2024.10.08.\\nThe Nobel Prize, They have revealed proteins’ secrets through computing and artificial intelligence, 2024.10.09.\\n12\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 15, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표\\nKEY Contents\\nn 미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI\\nR&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표\\nn 국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구\\n우선순위, 주요 이해관계자별 권장 사항을 제시\\n£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시\\nn 미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고\\n신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌\\nAI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표\\n∙ 국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운\\n방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고,\\nAI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시\\nn 국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시\\n∙ (사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의\\n설계와 배포에 관한 연구를 수행 우선\\n∙ (포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에\\n대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화\\n∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI\\n애플리케이션을 우선 개발\\n∙ (AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는\\nAI 시스템 개발을 위해 더 많은 기술 발전 필요\\n∙ (글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고\\n노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립\\nn 국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구\\n의제의 목표 달성을 위한 권장 사항을 제시\\n∙ (연구 기금 제공자) 투명성을 증진하고 국제 AI 연구 협력을 지원하는 기금을 요청하며 다양한 지역에\\n서 연구 인프라 접근성을 증진하고 민관협력을 추진\\n∙ (연구 생태계 허브) 연구 재현성을 장려하고, AI 연구 가이드라인 관련 협력과 조정을 강화하며, 민간\\n분야에서 중시하는 연구 주제 이외의 연구를 지원\\n∙ (연구팀) 다학제적 팀을 우선 편성하고 지역 연구자들과 협력하며, 사회기술적 방법론과 연구 설계를\\n채택하고 위험 평가 절차를 통합\\n☞ 출처: U.S. Department of State, Global AI Research Agenda, 2024.09.23.\\n13\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 16, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간\\nKEY Contents\\nn 일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한\\n평가 관점 가이드’를 발표\\nn 가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해\\n효과적 조치를 취했을 때의 기대 목표를 제시\\n£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시\\nn 일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성\\n평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간\\n∙ 가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을\\n제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립\\n<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점>\\n평가 관점 관련 AI 안전성 요소 기대 목표\\n유해 정보의 출력 통제 인간중심, 안전성, 공정성 Ÿ LLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능\\n허위 정보와 Ÿ LLM 시스템의 출력에 대한 사실 검증 메커니즘 구축\\n인간중심, 안전성, 투명성\\n조작 방지 Ÿ LLM 시스템의 출력에 의한 사용자 결정의 조작 방지\\nŸ LLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한\\n공정성과 포용성 인간중심, 공정성, 투명성 차별 부재\\nŸ LLM 시스템의 출력을 모든 최종 사용자가 이해 가능\\n고위험 사용 및 Ÿ LLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익\\n인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ LLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호\\nŸ LLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한\\n보안 보안\\n기밀정보의 유출 방지\\nŸ LLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적\\n설명 가능성 투명성\\n으로 합리적인 범위에서 확인 가능\\nŸ LLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치\\n견고성 안전성, 투명성\\n않은 입력에 대해 안정적 출력을 제공\\nŸ LLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이\\n데이터 품질 안전성, 공정성, 투명성\\n적절히 관리되는 상태\\nŸ LLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서 시스템 사용\\n검증 가능성 투명성\\n시점까지 제공되는 상태\\nn AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포,\\n사용 단계에서 적절한 간격으로 시행될 필요\\n∙ AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며,\\n평가는 한 차례가 아니라 반복적으로 실시\\n☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.\\n14\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 17, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표\\nKEY Contents\\nn 구글 딥마인드가 강화학습 방식으로 반도체 칩 레이아웃을 설계하여 사람이 몇 주에서 몇 달이\\n걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성하는 AI 모델 ‘알파칩’을 공개\\nn 구글은 2020년 처음 알파칩에 관한 연구 논문을 발표한 뒤, 자체 AI 칩 TPU 개발 시\\n알파칩을 활용해 칩 성능을 개선하고 개발 주기를 단축\\n£알파칩, 구글의 자체 AI 칩 TPU의 레이아웃 설계에도 기여\\nn 구글 딥마인드가 2024년 9월 26일 반도체 칩의 레이아웃을 설계할 수 있는 AI 모델 ‘알파칩\\n(AlphaChip)’을 공개\\n∙ 2020년 연구 프로젝트로 시작된 알파칩은 강화학습 방식을 사용하여 반도체 칩 레이아웃을 설계하며,\\n사람이 완료하는데 몇 주에서 몇 달이 걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성 가능\\nn 구글은 2020년 알파칩에 대한 연구 논문을 처음 발표했으며, 자체 AI 칩 TPU(Tensor Processing\\nUnit) 개발 시 알파칩을 활용해 칩 레이아웃을 설계\\n∙ TPU는 제미나이(Gemini)뿐 아니라 이마젠(Imagen), 비오(Veo) 등의 이미지 및 동영상 생성 모델과\\n같은 구글 AI 시스템의 핵심 요소를 형성\\n∙ 알파칩은 최신 6세대 TPU를 포함한 새로운 세대마다 칩 레이아웃 설계를 개선해 설계주기를\\n단축하고 더 높은 성능의 칩 생산에 기여\\nn 알파칩은 바둑에 특화된 알파고(AlphaGo) 및 바둑, 체스, 쇼기(일본 장기)를 마스터한 알파제로\\n(AlphaZero)와 비슷하게 칩 레이아웃 설계를 게임처럼 접근\\n∙ 알파칩은 모든 부품을 배치할 때까지 한 번에 하나의 회로 부품을 배치하고 최종 레이아웃의 품질에 따라\\n보상을 받게 되며, 상호 연결된 부품 간 관계를 학습하고 칩 전체로 확장해 레이아웃을 개선\\nn 구글은 자체 AI 칩 TPU뿐 아니라 영국 반도체 기업 ARM과 협력해 개발한 데이터센터용 CPU인\\n액시온(Axion) 프로세서도 알파칩으로 레이아웃을 생성했으며, 타사에도 알파칩을 제공\\n∙ 대만의 반도체 기업 미디어텍(MediaTek)은 삼성 스마트폰에 사용되는 ‘다이멘시티 플래그십(Dimensity\\nFlagship) 5G’와 같은 첨단 칩 개발에 알파칩을 활용해 개발을 가속화하고 칩 성능을 개선\\nn 구글 딥마인드는 현재 알파칩의 차기 버전을 개발 중으로, 향후 알파칩이 칩 설계주기의 전 단계를\\n최적화하고 스마트폰, 의료 장비, 농업 센서 등에 사용되는 맞춤형 하드웨어의 칩 설계에 혁신을\\n가져올 것으로 기대\\n☞ 출처: Google Deepmind, How AlphaChip transformed computer chip design, 2024.09.26.\\n15\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 18, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조\\nKEY Contents\\nn 이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머\\n아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적\\nn 고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용\\n절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장\\n£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요\\nn 이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면\\n트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장\\n* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망\\n** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미\\n∙ 트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성\\n측면에서는 한계를 내포\\n∙ 트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI\\n에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아\\n처리 과정에서 지연이 발생\\nn 고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더\\n효율적이고 저렴하게 만들 수 있다고 강조\\n∙ 카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)*\\n메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화\\n* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘\\n∙ 미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월\\n‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세\\n∙ AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를\\n활용해 기반모델을 개발\\nn 고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은\\n이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적\\n∙ AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는\\nLLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요\\n∙ 최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는\\n플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱\\n확산될 것으로 예상\\n☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.\\n16\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 19, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사\\nKEY Contents\\nn MIT 산업성과센터가 설문조사를 통해 근로자 관점의 자동화 기술의 영향을 조사한 결과,\\n근로자들은 직장 내 안전, 임금, 업무 자율성 등에서 자동화를 긍정적으로 평가\\nn 복잡한 문제 해결이 필요한 작업을 수행하는 근로자 및 자신의 직무에 만족하는 근로자일수록\\n자동화의 영향에 긍정적인 것으로 확인\\n£근로자들, 직장 내 안전, 임금, 업무 자율성 등에서 자동화의 영향에 긍정적\\nn MIT 산업성과센터(IPC)는 2024년 9월 30일 9개국* 9천 명 이상의 근로자에 대한 설문조사를\\n바탕으로 근로자 관점에서 자동화 기술을 평가한 연구 결과를 공개\\n* 독일, 미국, 스페인, 영국, 이탈리아, 일본, 폴란드, 프랑스, 호주\\n∙ 연구진은 설문조사를 통해 업무 환경, 직장에서 사용되는 자동화 기술(로봇 및 AI 등), 업무와 기술에\\n대한 태도, 기술이 업무에 미치는 영향을 조사\\nn 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가\\n긍정적 영향을 미칠 것이란 응답이 우세\\n∙ 자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적\\n응답은 12.5%에 불과\\n∙ 자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에\\n미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답\\nn 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며\\n미국 근로자들이 가장 비관적 태도를 보유\\n∙ 9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다\\n우세(임금: –0.6%, 직업 안정성: -4.6%)*\\n* 긍정적 응답에서 부정적 응답 비율을 뺀 수치\\nn 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직 근로자가\\n자동화에 더 긍정적이며, 직장 내 처우도 자동화에 대한 근로자의 인식에 영향을 발휘\\n∙ 고용주가 근로자를 적절히 대우하고 안전에 투자하는 직장에서 일하는 근로자는 직장 내 자동화의\\n영향에 긍정적이며, 직무 만족도와 신뢰도도 자동화에 대한 긍정적 인식에 영향을 미치는 요인으로 확인\\nn 연구진은 조사 결과를 바탕으로 직장 내 원활한 자동화 기술 도입을 위해 직무 설계를 통해 근로자가\\n복잡한 문제를 해결할 수 있는 역할을 만들 것을 권고\\n∙ 근로자들은 신기술 사용과 관련된 보너스가 제공되면 자동화에 더 긍정적인 것으로 나타나, 생산성\\n향상을 위한 자동화 기술 사용에 금전적 보상을 제공하는 방안도 고려 필요\\n☞ 출처: MIT IPC, Automation from the Worker’s Perspective, 2024.09.30.\\n17\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 20, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려\\nKEY Contents\\nn 다이스에 따르면, AI 전문가의 73%는 2025년 이직을 계획 중이며, 58%는 2024년 중 현재보다\\n더 나은 일자리를 찾을 자신이 있다고 응답해 여타 기술 전문가 대비 직업 전망을 낙관\\nn AI 전문가들은 여타 기술 전문가 대비 AI 도구 사용에도 적극적이며, 업무에 생성AI가 상당한\\n영향을 미친다는 응답도 36%로 여타 기술 전문가(22%) 대비 높은 수치를 기록\\n£AI 전문가들, 일반적인 기술 전문가보다 직업 전망에 낙관적\\nn 미국 기술직 채용 플랫폼 다이스(Dice)의 조사에 따르면, AI 기술 전문가는 일반적인 기술 전문가\\n대비 기술 산업의 미래와 자기 경력에 대하여 낙관적\\n∙ 이번 조사는 520명의 미국 정규직 기술 전문가와 390명의 인사 전문가의 응답을 토대로 기술 분야의\\n일자리 시장 환경을 분석\\n∙ 2024년 동안 주요 빅테크가 기술직에 대한 정리해고를 단행하고 기술직 채용도 2021~2022년 대비\\n대폭 감소하는 등 일자리 시장의 침체에도 2024년 기술과 사업의 핵심 요소로 부상한 AI 분야의\\n전문가들은 직업 전망을 낙관\\nn AI 전문가의 73%는 2025년에 이직을 계획 중이며, 58%는 2024년 중 현재보다 더 나은 새로운 일자리를\\n찾을 자신이 있다고 응답\\n∙ 일반적인 기술 전문가의 경우 65%가 2025년 중 이직을 계획 중이며, 2024년 더 나은 신규 일자리를\\n찾을 수 있다고 자신하는 비율은 36%에 불과\\n∙ AI 전문가는 빅테크를 선호하는 비율이 29%로 일반적인 기술 전문가(18%) 대비 더 높게 나타났으며,\\n이는 예산 규모가 더 크고 중요한 AI 프로젝트에 관심이 있거나 빅테크의 채용 가능성에 자신 있기\\n때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가\\n가치 있다고 느끼는 전문가일수록 현재 역할에 만족할 가능성도 증대할 것으로 추론\\n∙ AI 전문가의 51%는 자신의 프로젝트가 기업에 전략적 가치가 있다고 답했으나, 36%는 투자자나\\n이사회, 외부 관계자에게 기업이 AI로 뭔가를 하고 있음을 보여주기 위한 목적이라고 응답\\nn AI 전문가들은 AI 도구 사용에도 적극적이지만, 일반적인 기술 전문가들은 업무에서 AI 도구 사용을\\n주저하는 편으로, AI 전문가들은 일주일에 1회 이상 AI를 사용하는 비율이 49%에 달했으나, 여타\\n기술 전문가들은 25%에 불과\\nn 생성AI가 미치는 영향에 대해서 AI 전문가 사이에서는 상당한 영향을 미친다는 응답이 36%, 약간의 영향을\\n미친다는 응답이 56%, 영향이 없다는 응답은 8%를 기록했으나, 여타 기술 전문가들은 22%가 상당한 영향,\\n53%는 약간의 영향, 26%는 영향이 없다고 응답\\n☞ 출처: Dice, 3 Key Lessons about the AI Tech Talent Market, 2024.09.05.\\n18\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 21, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요\\nKEY Contents\\nn 가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및\\nAI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망\\nn 기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한\\n투자를 강화할 필요\\n£생성AI로 소프트웨어 엔지니어링에서 데이터과학과 AI/ML 역량의 중요성 증대\\nn 시장조사기관 가트너(Gartner)에 따르면 2027년까지 생성AI로 인해 소프트웨어 엔지니어링\\n인력의 80%가 역량 향상이 필요할 전망\\n∙ AI로 인해 인간 엔지니어에 대한 수요가 감소하거나 심지어 AI가 인간을 대체할 것이라는 예상과\\n달리, 가트너는 AI가 향후 소프트웨어 엔지니어의 역할을 변화시키더라도 인간의 전문성과 창의성은\\n여전히 중요하다고 강조\\nn 가트너에 따르면 생성AI는 소프트웨어 엔지니어의 역할에 단기, 중기, 장기적으로 영향을 미칠 전망\\n∙ 단기적으로는 AI가 기존 개발자의 작업 패턴과 업무를 보완하며 소폭의 생산성 향상 효과를 가져오며,\\nAI의 생산성 향상 효과는 성숙한 엔지니어링 관행을 갖춘 기업의 상급 개발자에게 집중될 전망\\n∙ 중기적으로는 AI 에이전트를 통해 더 많은 업무가 자동화되어 개발자의 작업 패턴의 변화가 예상되며,\\n이는 코드 대부분이 인간이 아닌 AI로 생성되는 AI 네이티브 소프트웨어 엔지니어링의 출현을 의미해\\n자연어 프롬프트 엔지니어링과 검색 증강 생성(RAG)* 기술이 엔지니어링의 필수 역량이 될 전망\\n* 외부 데이터를 활용하여 LLM의 출력 정확성을 향상하는 기술\\n∙ 장기적으로는 기업 내 AI 기반 소프트웨어 수요가 증가하면서 이를 충족하기 위해 소프트웨어\\n엔지니어링, 데이터 과학, AI/ML(머신러닝) 분야의 고유한 기술을 갖춘 훨씬 숙련된 AI 엔지니어가\\n부상할 전망\\n£AI 엔지니어를 지원하기 위해 기업의 AI 개발자 플랫폼 투자 필요\\nn 가트너가 2023년 4분기에 미국과 영국 기업 300개를 대상으로 실시한 설문조사에 따르면 소프트웨어\\n엔지니어링 책임자의 56%가 AI/ML 엔지니어를 2024년 가장 수요가 많은 직업으로 평가\\n∙ 기업들은 AI 엔지니어를 지원하기 위해 AI 개발자 플랫폼에 투자해야 하며, AI 개발자 플랫폼은\\n기업이 AI 역량을 더욱 효율적으로 구축하고 AI를 기업 솔루션에 대규모로 통합하는 데 도움이 될 전망\\n∙ 기업들은 AI 개발자 플랫폼 투자를 통해 소프트웨어 엔지니어링팀의 역량을 강화하고 지속적인 AI\\n통합과 개발을 추진하는 도구와 프로세스를 채택 필요\\n☞ 출처: Gartner, Gartner Says Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027,\\n2024.10.03.\\n19\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 22, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2024-11월호\\n인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박\\nKEY Contents\\nn 인디드가 2,800개 이상의 직무 기술에 대한 생성AI의 수행 능력을 분석해 인간을 대체할\\n가능성을 평가한 결과, 생성AI로 대체될 가능성이 “매우 높은” 것으로 평가된 기술은 전무\\nn 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이며, 물리적 작업\\n수행이 필요한 직무 기술에서는 인간 근로자를 대체할 가능성이 희박\\n£생성AI, 문제 해결 역량 및 물리적 작업 수행 역량의 부족으로 인간 근로자 대체에 한계\\nn 미국의 채용 플랫폼 인디드(Indeed) 산하 연구소 하이어링랩(Hiring Lab)이 2024년 9월 25일\\n발표한 연구 결과에 따르면 생성AI가 인간 근로자를 대체할 가능성은 희박\\n∙ 인디드 하이어링랩은 오픈AI의 GPT-4o로 2,800개 이상의 고유한 직무 기술에 대한 생성AI의 수행\\n능력을 분석해 생성AI가 인간을 대체할 가능성을 평가\\n∙ 연구진은 오픈AI의 GPT-4o가 △기술과 관련된 이론적 지식의 제공 역량 △기술을 사용한 문제 해결 역량\\n△기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행\\n∙ 다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은\\n2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로\\n평가됐으며, “매우 높음”으로 평가된 기술은 전무\\nn 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결\\n능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가\\n∙ 생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제\\n해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는\\n“매우 높음”이라고 평가*\\n* 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely, 5점)\\n∙ 생성AI는 물리적 작업을 수행할 몸체가 없어 실제 작업 수행이 필요한 직무 기술에서는 인간 근로자를\\n대체할 가능성이 제한적\\n∙ 일례로 생성AI는 디지털 기술 비중이 큰 소프트웨어 개발 직종의 구인 공고에서 통상 제시되는 직무\\n기술의 71%에 대하여 인간을 대체할 가능성이 “보통” 또는 “높음”으로 평가했으나, 간호사 직종의\\n구인 공고에 제시되는 기술의 약 32.9%만 생성AI로 대체될 가능성이 “보통” 또는 “높음”으로 평가\\nn 인디드는 현재 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이라고 강조\\n∙ 생성AI는 직원 생산성을 극대화하여 노동 시장의 경색을 완화할 수 있으며, 물리적 작업 수행이 필요한\\n직업에서도 근로자가 핵심 업무에 집중할 수 있도록 지원 가능\\n∙ 그러나 생성AI는 논리적 오류나 사실과 다른 내용 또는 편향이나 차별과 같은 비윤리적 응답을 출력할\\n가능성도 있으므로 인간의 신중한 검토 필요\\n☞ 출처: Indeed Hiring Lab, AI at Work: Why GenAI Is More Likely To Support Workers Than Replace Them, 2024.09.25.\\n20\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 23, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4'}, page_content='Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 신경정보처리시스템재단은 인공지능과 머신러닝 분야의 연구 성과\\n교환을 촉진하는 것을 목적으로 하는 비영리 법인으로 매년 학제간\\n학술대회(NeurIPS)를 주최\\n- 이번 제38회 연례학술대회는 AI 연구자를 위한 실험 설계,\\nNeurIPS\\nLLM을 위한 메타 생성 알고리즘, 정렬에 대한 학제 간 통찰력\\n2024\\n등을 다룰 예정\\n기간 장소 홈페이지\\n2024.12.10~15 캐나다 밴쿠버 https://neurips.cc/\\n- GenAI Summit Maroc 2024는 인공지능과 데이터 분석에\\n초점을 맞춘 최고의 이벤트로, 250명 이상의 업계 리더, 정책\\nGenAI\\n입안자, 전문가가 모여 AI 발전을 탐구\\nSummit\\n- 이번 행사에는 오픈소스 AI, AI 주도 사이버 보안, 우수한\\nMaroc\\n의사결정을 위한 생성AI와 예측 AI 결합 등을 다룰 예정\\n2024\\n기간 장소 홈페이지\\n2024.12.10~11 모로코 https://genaimaroc.com/\\n- AI Summit Seoul 행사는 2018년 개최를 시작으로 금년도는\\n7회 행사로 개최\\n- 이번 행사는 AI와 산업의 융합에 초점을 두고 다양한 글로벌\\n기업과 기관, 학계 전문가 등 전문가들이 한자리에 모여 AI\\nAI Summit\\n및 산업 트렌드 등에 대한 주제 발표 및 워크샵 진행\\nSeoul 2024\\n기간 장소 홈페이지\\n2024.12.10~11 서울(코엑스 그랜드볼룸) https://aisummit.co.kr/\\n21\\n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    doc.metadata['filename'] = doc.metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 3, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 민권위원회, 연방정부의 얼굴인식 기술 사용에 따른 민권 영향 분석\\nKEY Contents\\nn 미국 민권위원회에 따르면 연방정부와 법 집행기관에서 얼굴인식 기술이 빠르게 도입되고\\n있으나 이를 관리할 지침과 감독의 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회는 연방정부의 책임 있는 얼굴인식 기술 사용을 위해 운영 프로토콜 개발과\\n실제 사용 상황의 얼굴인식 기술 평가 및 불평등 완화, 지역사회의 의견 수렴 등을 권고\\n£연방정부의 얼굴인식 기술 도입에 대한 지침과 감독 부재로 민권 문제를 초래할 위험 존재\\nn 미국 민권위원회(U.S. Commission on Civil Rights)가 2024년 9월 19일 연방정부의 얼굴인식\\n기술 사용이 민권에 미치는 영향을 분석한 보고서를 발간\\n∙ AI 기술의 일종인 얼굴인식 기술은 연방정부와 법 집행기관에서 빠르게 도입되고 있으며, 일례로\\n법무부 연방수사국(FBI)은 범죄 수사 및 용의자 수색용 단서 확보를 위해 얼굴인식 기술을 가장 빈번히 사용\\n∙ 그러나 얼굴인식 기술의 책임 있는 사용을 위한 연방 지침과 감독은 실제 활용 사례보다 뒤처졌으며,\\n현재 연방정부의 얼굴인식 기술이나 여타 AI 기술 사용을 명시적으로 규제하는 법률도 부재\\nn 보고서에 따르면 얼굴인식 기술의 무분별한 사용은 편향, 개인정보 침해, 적법 절차의 미준수\\n및 차별적 영향과 같은 민권 문제를 초래할 위험 보유\\n∙ 얼굴인식 기술의 정확도는 인종, 성별, 연령 등 인구통계학적 요인에 따라 달라질 수 있으며, 이는 식별\\n오류 및 부정확한 체포로 이어져 유색인종을 비롯한 특정 집단에 차별적 결과를 초래할 위험 존재\\n∙ 정부 기관이 사전 영장이나 정당한 이유 없이 얼굴인식 기술을 광범위하게 사용할 경우 개인을\\n지속적으로 추적하고 감시함으로써 개인정보 보호 권리에 심각한 영향을 미칠 위험 존재\\n∙ 법 집행기관의 얼굴인식 기술 사용 시 부정확한 식별 및 편향으로 인해 개인이 법의 보호를 받아\\n공정하고 올바르게 대우받을 권리를 침해할 가능성도 존재\\n£민권위원회, 연방정부의 책임 있는 얼굴인식 기술 사용을 위한 권고사항 제시\\nn 민권위원회는 연방정부의 얼굴인식 기술 사용과 관련해 다음과 같은 권고사항을 제시\\n∙ 국립표준기술연구소(NIST)는 정부 기관의 얼굴인식 기술 시스템 도입 시의 효과와 공평성, 정확성\\n평가에 사용할 수 있는 운영 테스트 프로토콜의 개발 필요\\n∙ 각 연방정부 기관의 최고AI책임자는 실제 사용 상황에서 얼굴인식 기술을 평가하고 차별이나 편견으로\\n인한 불평등을 완화하며, 얼굴인식 기술의 사용으로 영향을 받는 지역사회의 의견을 수렴 필요\\n∙ 얼굴인식 기술 제공업체는 다양한 인구통계 집단에 대한 높은 정확도를 보장하기 위해 지속적인 교육과\\n지원, 업데이트를 제공 필요\\n☞ 출처: U.S. Commission on Civil Rights, The Civil Rights Implications of the Federal Use of Facial Recognition Technology, 2024.09.19.\\n1\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 4, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미국 백악관 예산관리국, 정부의 책임 있는 AI 조달을 위한 지침 발표\\nKEY Contents\\nn 미국 백악관 예산관리국이 바이든 대통령의 AI 행정명령에 따라 연방정부의 책임 있는 AI 조달을\\n지원하기 위한 지침을 발표\\nn 지침은 정부 기관의 AI 조달 시 AI의 위험과 성과를 관리할 수 있는 모범 관행의 수립 및 최상의 AI\\n솔루션을 사용하기 위한 공급업체 시장의 경쟁 보장, 정부 기관 간 협업을 요구\\n£백악관 예산관리국, 연방정부의 AI 조달 시 책임성을 증진하기 위한 모범 관행 제시\\nn 미국 백악관 예산관리국(OMB)이 바이든 대통령의 AI 행정명령에 따른 후속 조치로 2024년 10월 3일\\n‘정부의 책임 있는 AI 조달 지침(M-24-18)’을 발표\\n∙ 미국 연방정부는 2023년 1,000억 달러 이상의 IT 제품과 서비스를 구매한 미국 경제 최대 규모의 단일\\n구매자로서 구매력을 활용해 책임 있는 AI의 발전을 뒷받침할 계획\\n∙ 이번 지침은 △AI 위험과 성과 관리 △AI 시장의 경쟁 촉진 △연방정부 전반의 협업 보장이라는 3개\\n전략적 목표에 대하여 권고사항을 제시\\nn (AI 위험과 성과 관리) 예산관리국의 지침은 AI 시스템의 구축, 훈련, 배포 방식의 복잡성을 고려해\\nAI의 위험과 성과를 관리하기 위한 모범 관행을 다음과 같이 제시\\n∙ 정부 기관의 개인정보 보호 담당자가 AI 조달 프로세스에 조기에 지속적으로 참여해 개인정보 보호\\n위험을 식별 및 관리하고 법률과 정책 준수를 보장\\n∙ 정부 기관과 공급업체와 간 협력으로 AI 솔루션이 조달되는 시기와 해당 조달로 인해 시민 권리와\\n안전에 영향을 미치는 AI에 대하여 추가로 위험관리가 필요한 시점을 파악\\n∙ 성과 기반의 혁신적 조달 기법을 활용해 정부 기관이 위험을 효과적으로 관리 및 완화하고 성과를 향상할\\n수 있도록 장려하는 한편, 정부 데이터와 지식재산권을 보호하는 방식으로 계약 조건을 협상\\nn (AI 시장의 경쟁 촉진) 지침은 정부 기관이 최상의 AI 솔루션을 사용할 수 있도록 공급업체 시장에서\\n강력한 경쟁을 보장할 것을 요구\\n∙ 계약 요건 수립 시 공급업체 의존성을 최소화할 수 있는 인수 원칙을 적용하고, 시장 조사와 요구사항\\n개발, 공급업체 평가 절차에서 상호운용성과 투명성을 고려하며, 혁신적 조달 관행을 활용해 우수한\\n계약업체 성과와 정부 기관의 임무 성과를 보장\\nn (연방정부 전반의 협업 보장) 빠르게 발전하는 AI 기술환경의 위험관리를 위해 AI 전문지식을 갖춘\\n공무원과 조달, 개인정보보호, 사이버보안 전문가를 포함하는 협업 팀을 구성해 전략적 조달을 지원\\n∙ 각 정부 기관은 기관 간 협의회를 구성해 효과적이고 책임 있는 AI 조달을 지원하고, 협업 시 기관 목표에\\n가장 적합한 AI 투자 식별 및 우선순위 지정, AI 배포 역량 개발, AI 모범 활용 사례 채택 증진 등을 고려\\n☞ 출처: The White House, FACT SHEET: OMB Issues Guidance to Advance the Responsible Acquisition of AI in\\nGovernment, 2024.10.03.\\n2\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 5, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\n대한 투명성과 책임성을 보장 필요\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\n3\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 6, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nOECD, 공공 부문의 AI 도입을 위한 G7 툴킷 발표\\nKEY Contents\\nn OECD는 공공 부문에서 EU 및 G7 국가들의 AI 도입 모범사례와 거버넌스 프레임워크,\\n정책 옵션을 토대로 공공 부문의 AI 도입을 안내하는 보고서를 발표\\nn 보고서는 공공 부문의 AI 도입 시 프로토타입부터 시작해 시범 도입을 거쳐 본격적으로\\n구현하는 단계별 접근방식을 권고\\n£OECD, G7의 사례를 토대로 공공 부문의 AI 도입을 안내하는 지침 마련\\nn OECD가 2024년 10월 15일 안전하고 신뢰할 수 있는 AI의 원칙을 실행 가능한 정책으로 전환할\\n수 있도록 지원하는 ‘공공 부문의 AI를 위한 G7 툴킷’ 보고서를 발간\\n∙ OECD는 G7 회원국이 작성한 설문 응답 및 OECD와 UNESCO의 연구를 토대로 공공 부문에서 AI\\n활용 모범사례와 거버넌스 프레임워크, 정책 옵션과 관련된 종합적 지침 제공을 목표로 보고서를 작성\\nn G7과 EU의 AI 도입 추세를 분석한 결과, G7 회원국과 EU는 공공 부문의 AI 도입과 관련된\\n국가 전략 및 정책의 개발과 구현에서 차이가 존재\\n∙ EU·독일·미국·영국·일본은 국가 AI 전략에 공공 부문을 포함했고 프랑스는 국가 AI 전략에서는\\n공공 부문을 구체적으로 다루지 않으나 공공행정 혁신기금(FTAP)을 조성하여 60개 이상의 AI\\n프로젝트에 투자하는 등 별도의 정책을 수립\\n∙ 캐나다는 2025년 봄까지 공공 서비스를 위한 AI 전략을 개발할 계획이며, 이탈리아는 ‘공공\\n부문 디지털화를 위한 3개년 계획(2024~2026)’에 AI를 포함\\n∙ G7 회원국들은 접근방식의 차이에도 인재와 기술 개발, 조달 정책, 협력관계 구축, 윤리적이고\\n신뢰할 수 있으며 인간 중심적인 AI 관행 조성, 데이터 품질 보장 등에서 공통점을 보유\\nn AI 거버넌스 프레임워크 측면에서 G7 회원국 중 미국·캐나다·프랑스와 EU는 여러 기관이 AI를 관리하는\\n분산형 거버넌스 구조를 채택했으며 이탈리아·독일·영국은 단일 기관이 AI를 관리하는 중앙집중형\\n거버넌스를 채택\\nn G7 회원국들은 공공 부문의 운영 효율성 향상, 정책 결정 강화, 공공 서비스 개선, 정부의 투명성과\\n책임성 강화를 위해 AI를 활용하는 한편, 다양한 정책 옵션으로 AI 도입 시의 과제 해결을 모색\\n∙ AI 도입에 필수적인 인프라를 강화하기 위한 데이터 저장과 공유 솔루션 채택, AI에 적합한\\n혁신적이고 유연한 조달 절차의 수립 및 민간 파트너십 육성, 공공 부문의 AI 역량 강화, 데이터\\n거버넌스 프레임워크 구축 등이 대표적인 정책 옵션\\nn 보고서는 공공 부문의 AI 도입 시 각 단계를 신중히 관리하여 위험을 완화할 수 있도록, 문제를\\n명확히 정의하고 아이디어를 구상한 뒤 프로토타입부터 시작해 통제된 환경에서 AI를 시범 도입한\\n후 이를 개선해 본격적으로 구현하는 단계적 접근방식을 강조\\n☞ 출처: OECD, G7 Toolkit for Artificial Intelligence in the Public Sector, 2024.10.15.\\n4\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 7, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n세계경제포럼, 생성AI 시대의 거버넌스 프레임워크 제시\\nKEY Contents\\nn 세계경제포럼이 글로벌 정책입안자를 대상으로 생성AI의 공익적 활용과 경제·사회적\\n균형 달성, 위험 완화를 위한 거버넌스 프레임워크를 제안하는 백서를 발표\\nn 백서에 따르면 정부는 기존 규제를 평가해 생성AI로 인한 규제 격차를 해소하는 한편, 다양한\\n이해관계자 간 지식 공유를 촉진하고 미래의 AI 발전에 대비한 규제 민첩성을 갖출 필요\\n£생성AI 거버넌스, 과거-현재-미래를 아우르는 프레임워크 수립 필요\\nn 세계경제포럼(WEF)이 2024년 10월 8일 세계 각국의 정책입안자를 대상으로 생성AI 거버넌스\\n프레임워크를 제시한 백서를 발간\\n∙ 백서는 생성AI의 공익적 활용과 경제·사회적 균형 달성, 위험 완화라는 목표 달성을 위해 △과거\\n활용(Harness Past) △현재 구축(Build Present) △미래 계획(Plan Future)의 프레임워크를 제안\\nn (과거 활용) 기존 규제를 활용하고 생성AI로 인한 규제 격차를 해소하는 것으로, 정부는 새로운 AI\\n규제나 관할 당국을 수립하기에 앞서 다음 사항을 추진할 필요\\n∙ 생성AI로 인한 문제나 격차 발생에 관하여 기존 규제를 평가하고 다양한 규제 수단의 정책 목표를\\n고려해 규제를 조정하며, 규제 선례를 참고해 책임 할당을 명확히 하고 격차가 발견된 부분을 보완\\n∙ 기존 규제 당국이 생성AI 문제를 해결할 역량이 있는지 평가하고, AI 전담 기관을 설치하여 규제\\n권한을 집중하는 방안의 장단점을 고려\\nn (현재 구축) 사회 전반의 생성AI 거버넌스와 지식 공유의 증진을 의미하며, 생성AI의 거버넌스에는\\n정책입안자와 규제 당국 외에 산업계, 시민사회, 학계를 포함한 이해관계자 참여가 필수적\\n∙ 정부는 다양한 거버넌스 수단을 활용해 사회 전반의 생성AI 거버넌스에 참여하는 각 이해관계자\\n집단의 고유한 문제에 대응 필요\\n∙ 다양한 이해관계자 간 지식 공유를 촉진하고, 책임 있는 AI 관행으로 사회에 모범을 보일 필요성 존재\\nn (미래 계획) 생성AI 거버넌스에 대한 민첩한 준비와 함께 국제협력을 촉진하는 것으로, 정부는 빠\\n른 기술 발전과 한정된 자원, 글로벌 불확실성을 고려해 미래를 예견한 국가 전략을 개발하고 다음\\n의 활동을 추진\\n∙ 정부 내 AI 역량 향상과 AI 전문가 채용을 위한 투자를 시행하고 AI 전담 기관의 설립 필요성을 신중히 검토\\n∙ 생성AI와 인간 간 상호작용, 생성AI와 여타 기술의 융합, 생성AI 신기능과 관련된 혁신 및 이로 인한\\n새로운 위험을 탐색\\n∙ 기존 규제의 영향 평가 및 미래 AI 발전에 대비한 영향 평가로 규제 민첩성을 유지하며, 일례로\\n광범위한 도입에 앞서 규제 유예제도(샌드박스)를 시범 운영\\n∙ 지식과 인프라 공유와 AI 안전성 연구, AI 표준의 일관성 확보를 위한 국제협력 추진\\n☞ 출처: World Economic Forum, Governance in the Age of Generative AI: A 360° Approach for Resilient Policy and Regulation, 2024.10.08.\\n5\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 8, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nCB인사이츠 분석 결과, 2024년 3분기 벤처 투자 31%가 AI 스타트업에 집중\\nKEY Contents\\nn CB인사이츠에 따르면 2024년 3분기 AI 스타트업은 전체 벤처 투자의 31%를 유치했으며,\\nAI 스타트업의 투자금 회수 시점은 일반 기업보다 6년 빠른 것으로 확인\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 오픈AI와 같은 거대 기업도\\n비용 통제에 어려움을 겪고 있다며 상당수 AI 스타트업이 실패할 것으로 예상\\n£AI 스타트업, 벤처 투자의 최우선 고려 대상으로 부상\\nn 글로벌 리서치 기업 CB인사이츠(CB Insights)가 2024년 10월 3일 발표한 2024년 3분기 벤처\\n현황 보고서에 따르면 2024년 3분기 벤처 자금의 31%가 AI 스타트업에 투자된 것으로 분석\\n∙ AI 스타트업은 2024년 2분기에 전체 벤처 투자의 35%를 유치하며 역대 최고 비중을 차지했으며,\\n3분기에도 역대 두 번째로 높은 비중을 기록\\n∙ 오픈AI의 공동설립자 일리야 수츠케버(Ilya Sutskever)가 2024년 6월 설립한 스타트업 SSI(Safe\\nSuperintelligence Inc.)는 10억 달러를 유치하며 3분기 대표적인 AI 투자로 기록\\n∙ CB인사이츠가 전 세계 1만 5천 개 이상의 AI 스타트업을 추적한 결과, 전 세계 AI 스타트업의 43%가 미국\\n기업이며, 다음 순위는 중국이 9%, 영국이 7%, 인도와 캐나다가 각각 4%로 미국과 상당한 격차를 기록\\nn 기업가치 10억 달러 이상의 유니콘 기업은 2024년 3분기에 24개가 탄생했으며, 이중 절반 이상이\\nAI 기업인 것으로 확인\\n∙ 범용 로봇 개발기업 스킬드AI(Skild AI), 공간지능에 특화된 월드랩스(World Labs), 법률 AI\\n서비스 기업 하비(Harvey) 등이 유니콘 지위를 획득\\nn AI 스타트업은 투자금 회수(Exit) 시점도 일반 스타트업보다 훨씬 빨라 AI 기업이 엑시트하는 시점은\\n설립 후 7년에 불과했으나 여타 스타트업은 13년 소요되었으며, 이러한 경향은 M&A에서 가장 뚜렷해\\n2024년 AI 스타트업 엑시트는 대부분 M&A를 통해 달성\\n∙ 대기업들은 자사 제품군에 AI 도구를 신속히 도입하고자 AI 스타트업 인수에 적극적인 행보를 보이고\\n있으며, 일례로 엔비디아(Nvidia)는 2024년에 AI 스타트업 3곳을 인수했고, 세일즈포스(Salesforce)는\\n2024년 9월 AI 스타트업 2곳을 인수\\nn 그러나 CB인사이츠는 투자자들의 낙관적 기대에도 불구하고 현재의 AI스타트업 중 상당수는 기대에\\n부응하지 못하고 실패하게 될 것으로 예상\\n∙ CB인사이츠는 오픈AI와 같은 거대 AI 기업조차도 수익을 내지 못해 비용을 통제해야 하는 어려움을\\n겪고 있다며, 오픈AI의 2024년 손실 규모가 50억 달러에 달할 것으로 전망\\n☞ 출처 : CB Insights, State of Venture Q3’24 Report, 2024.10.03.\\n6\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 9, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n메타, 동영상 생성AI 도구 ‘메타 무비 젠’ 공개\\nKEY Contents\\nn 메타가 동영상 생성, 개인화 동영상 제작, 동영상 편집, 오디오 생성과 같은 기능을 지원하는\\n‘메타 무비 젠’을 공개하고 2025년 중 인스타그램 등 자사 플랫폼에 통합할 계획\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이의 젠 3, 오픈AI의 소라, 클링 1.5와 같은 경쟁\\n동영상 AI 모델보다 더 높은 점수를 기록\\n£메타, 동영상 제작과 편집, 오디오 생성을 지원하는 메타 무비 젠을 공개\\nn 메타(Meta)가 2024년 10월 4일 텍스트 입력을 통해 고해상도 동영상을 생성하는 AI 도구 ‘메타\\n무비 젠(Meta Movie Gen)’을 공개\\n∙ 메타는 크리에이터와 영화 제작자 등 소수의 외부 파트너에게 메타 무비 젠을 우선 제공 후 피드백을\\n반영해 기능을 개선할 계획으로, 단독 서비스로 출시하는 대신 2025년 중 인스타그램(Instagram)과\\n같은 자사 소셜미디어 플랫폼에 통합하여 제공할 방침\\nn 메타 무비 젠은 △동영상 생성 △개인화 동영상 생성 △동영상 편집 △오디오 생성의 4가지 기능을 지원\\n∙ (동영상 생성) 300억 개 매개변수의 AI 모델을 통해 초당 16프레임의 속도로 1,080p 해상도의 최대\\n16초 길이 동영상 생성을 지원\\n∙ (개인화 동영상 생성) 사용자가 자신이나 타인의 이미지와 텍스트를 입력해 원래 인물의 고유한 특징을\\n반영한 개인화 동영상을 제작 가능\\n∙ (동영상 편집) 특정 요소의 추가나 제거, 변경과 같은 부분적 수정 및 동영상 배경 또는 스타일 변경과\\n같은 광범위한 수정도 지원\\n∙ (오디오 생성) 130억 개 매개변수의 오디오 생성 모델을 통합해 동영상과 텍스트 프롬프트 기반으로\\n최대 45초 길이의 배경음, 음향 효과 등 고품질 오디오를 생성\\n£메타 무비 젠, 인간 선호도 평가에서 오픈AI의 소라 능가\\nn 메타 무비 젠은 인간 선호도 평가에서 런웨이(Runway)의 젠(Gen) 3, 오픈AI의 소라(Sora)를\\n비롯한 경쟁 동영상 생성AI 모델보다 더 높은 점수를 기록\\n∙ 메타 무비 젠과 경쟁 모델에 대하여 세 명의 인간 평가자가 점수를 매겨 비교 후 순승률(Net Win\\nRate)*을 계산한 결과, 메타 무비 젠은 젠 3와 소라, 클링(Kling) 1.5를 모두 능가\\n* 두 모델(A와 B)에 대하여 3명의 인간 평가자가 A 선호 시 +1점, 동점이면 0점, B 선호 시 –1점을 매기는 식으로 계산해\\n승률(-100%~100% 값)을 구하며, 승률이 양수면 A 모델 선호, 음수면 B 모델 선호를 의미\\n<메타 무비 젠과 경쟁 AI 모델의 인간 선호도 평가 승률>\\n☞ 출처: Meta, How Meta Movie Gen could usher in a new AI-enabled era for content creators, 2024.10.04.\\n7\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 10, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n메타, 이미지와 텍스트 처리하는 첫 멀티모달 AI 모델 ‘라마 3.2’ 공개\\nKEY Contents\\nn 메타가 이미지와 텍스트를 모두 처리할 수 있는 모델과 모바일 기기에서 실행 가능한 경량\\n모델을 포함하는 라마 3.2 시리즈를 공개\\nn 비전 기능을 갖춘 라마 3.2 90B 모델은 다양한 이미지 인식과 시각적 이해 작업에서\\n앤스로픽의 ‘클로드3-하이쿠’ 및 오픈AI의 ‘GPT-4o-미니’와 대등한 수준의 성능 보유\\n£라마 3.2 90B 모델, 이미지 인식과 시각적 이해에서 GPT-4o-미니와 대등한 성능\\nn 메타가 2024년 9월 25일 ‘라마(Llama)’ 시리즈 최초로 이미지와 텍스트를 모두 처리하는 ‘라마 3.2’를 공개\\n∙ 라마 3.2 시리즈는 이미지를 처리하는 비전(Vision) 기능을 갖춘 매개변수 110억 개(11B)와 900억\\n개(90B)의 모델 및 모바일 기기에 적합한 매개변수 10억 개(1B)와 30억 개(3B)의 경량 모델로 구성\\n∙ 2024년 7월 공개된 라마 3.1과 비교해 라마 3.2는 전반적 성능 향상 외 비전 기능이 추가되어 이미지\\n추론을 지원하며 모바일 기기에서 실행 가능한 경량 모델이 추가되어 접근성을 향상\\nn 라마 3.2 시리즈 중 11B와 90B 모델은 차트와 그래프를 포함한 문서 이해, 이미지 캡션, 이미지\\n안의 물체 식별과 같은 이미지 추론을 지원\\n∙ 라마 3.2는 이미지에서 세부 정보를 추출하고 장면을 이해하여 이미지 캡션으로 사용할 수 있도록\\n내용을 전달하는 문장을 생성 가능\\n∙ 이미지 인식과 시각적 이해 관련 90B 모델의 벤치마크 평가 결과는 앤스로픽(Anthropic)의 ‘클로드\\n3-하이쿠’나 오픈AI의 ‘GPT-4o-미니’와 대등한 수준으로, 일례로 시각적 수학 추론(MathVista)에서\\n57.3점으로 클로드 3-하이쿠(46.4점)와 GPT-4o-미니(56.7점)를 능가\\nn 라마 3.2 시리즈 중 1B와 3B 경량 모델은 12만 8천 개 토큰의 컨텍스트 창을 지원하고 다국어\\n텍스트 생성과 도구 호출 기능을 제공하며, 데이터를 기기 내에 보관하는 온디바이스 앱 개발에 특화\\n∙ 모델 평가 결과, 3B 모델은 지시 이행, 요약, 신속한 재작성 및 도구 사용과 같은 작업에서\\n구글(Google)의 ‘젬마 2 2.6B’ 및 마이크로소프트(Microsoft)의 ‘파이 3.5-미니’보다 성능이 우수\\n∙ 일례로 텍스트 재작성(Open-rewrite eval) 평가에서 3B 모델은 40.1점으로 젬마 2 2.6B(31.2점)\\n및 파이-3.5-미니(34.5점)를 앞섰으며, 텍스트 요약 능력(TLDR9+)에서는 19.0점으로 젬마 2\\n2.6B(13.9점) 및 파이-3.5-미니(12.8점)를 능가\\nn 메타는 라마 3.2 출시와 함께 개발자들이 라마 모델을 더욱 쉽고 효율적으로 사용할 수 있도록\\n지원하는 표준화 인터페이스인 ‘라마 스택(Llama Stack)’도 공개\\n∙ 개발자들은 라마 스택을 통해 온프레미스*, 클라우드, 온디바이스 등 다양한 환경에서 일관적이고\\n간소화된 방식으로 라마 모델을 구축 가능\\n* 기업이 자체 시설에서 보유하고 직접 유지 관리하는 데이터센터\\n☞ 출처: Meta, Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, 2024.09.25.\\n8\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 11, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n앨런AI연구소, 벤치마크 평가에서 GPT-4o 능가하는 성능의 오픈소스 LLM ‘몰모’ 공개\\nKEY Contents\\nn 앨런AI연구소가 공개한 멀티모달 LLM 제품군 몰모는 벤치마크 평가에서 GPT-4o를\\n능가하는 성능의 72B 모델과 전문가혼합 모델, 온디바이스 모델 등 4개 모델로 구성\\nn 몰모-72B 모델은 시각적 이해 능력이 뛰어나며 벤치마크 평가 및 인간 선호도 평가에서 첨단\\n폐쇄형 모델을 능가하는 점수를 기록\\n£몰모-72B 모델, 벤치마크 평가에서 GPT-4o와 제미나이 1.5 Pro 능가\\nn 미국 비영리 연구기관 앨런AI연구소(Allen Institute for AI, 이하 AI2)가 2024년 9월 25일 오픈\\n소스 멀티모달 LLM 제품군 ‘몰모(Molmo)’를 공개\\n∙ 몰모는 가장 규모가 크고 성능이 뛰어난 72B와 데모 모델 7B-D, 개방성이 가장 높은 7B-O, 70억 개의\\n전체 매개변수 중 10억 개만 활성화하는 전문가혼합(MoE) 모델 E-1B의 4개 모델로 구성되며, 이 중\\nE-1B 모델은 온디바이스 실행 가능\\n∙ 몰모는 데이터 규모보다 품질을 중시하는 학습 방식으로 데이터 효율성이 뛰어나 컴퓨팅 자원이 한정된\\n환경에서도 사용 가능한 것이 장점\\n∙ 몰모는 일상 사물과 표지판, 복잡한 차트, 시계, 메뉴판 등 다양한 시각 자료를 이해하고 이미지를\\n구성하는 요소를 정확히 지목할 수 있어, 화면과 현실 세계 간 복잡한 상호작용(예: 비행기 표 예약)이\\n필요한 웹 에이전트나 로봇 개발에도 유리\\n∙ AI2는 몰모의 언어와 시각 훈련 데이터, 미세조정 데이터, 모델 가중치, 소스코드를 모두 공개하고\\n연구와 상업적 목적의 활용을 허용\\nn AI2에 따르면 몰모-72B 모델은 주요 벤치마크와 인간 선호도 평가*에서 첨단 폐쇄형 모델을 능가\\n* 870명의 인간 평가자에게 다양한 이미지와 텍스트 프롬프트 쌍에 대한 모델 간 응답을 비교해 선호도 평가를 요청해 순위를 산정\\n∙ 몰모-72B는 11개 벤치마크 평균 점수 81.2점으로 ‘GPT-4o’(78.5점), ‘제미나이 1.5 Pro’(78.3점),\\n‘클로드-3.5 소네트’(76.7점)를 넘는 최고 점수를 기록했으며 인간 선호도 평가에서는 1077점으로\\nGPT-4o(1079점)에 이어 2위\\n∙ 전문가혼합 모델인 몰모E-1B는 벤치마크 평균 점수에서 68.6점, 인간 선호도 평가는 1,032점으로\\n각각 71.1점과 1,041점을 받은 GPT-4V과 경쟁할 수 있는 수준\\n<몰모 제품군과 GPT-4o/GPT-4V의 벤치마크 평균(左)과 인간 선호도 평가(右) 점수 비교>\\n☞ 출처: Allen Institute for AI, Introducing Molmo, 2024.09.25.\\n9\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 12, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n미스트랄AI, 온디바이스용 AI 모델 ‘레 미니스트로’ 공개\\nKEY Contents\\nn 미스트랄AI가 네트워크 연결 없이 온디바이스로 사용할 수 있는 경량 모델 ‘레 미니스트로’를\\n미스트랄 3B와 미스트랄 8B 버전으로 공개\\nn 벤치마크 평가에서 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마 및 라마와\\n비교해 대부분 벤치마크에서 더 높은 평가를 획득\\n£미스트랄 AI, 네트워크 연결이 필요 없는 경량 모델 ‘레 미니스트로’ 출시\\nn 프랑스의 대표 AI 스타트업 미스트랄AI(Mistral AI)가 2024년 10월 16일 네트워크 연결 없이\\n작동하는 온디바이스용 AI 모델 ‘레 미니스트로(Les Ministraux)’를 발표\\n∙ ‘미스트랄 3B’와 ‘미스트랄 8B’ 버전으로 공개된 이 모델은 경량 모델이면서도 영어책 50쪽 분량에\\n해당하는 12만 8천 개 토큰의 컨텍스트 창을 지원\\n∙ 미스트랄AI는 레 미니스트로가 번역과 스마트 어시스턴트, 분석, 자율 로봇 같은 중요 애플리케이션에\\n대하여 네트워크 연결 없이 개인정보보호가 가능한 온디바이스 추론을 원하는 고객 수요에 맞게\\n지연시간이 짧고 효율적인 솔루션을 제공한다고 강조\\n∙ 미스트랄AI는 8B 버전만 연구용으로 다운로드를 허용했으며 향후 두 모델을 클라우드 플랫폼을 통해\\n제공할 계획으로, 사용 비용은 100만 입출력 토큰 당 8B 버전은 10센트, 3B 버전은 4센트로 책정\\n£레 미니스트로, 오픈소스 모델 ‘젬마’ 및 ‘라마’ 대비 대부분 벤치마크에서 우수한 평가\\nn 벤치마크 평가 결과, 레 미니스트로는 비슷한 매개변수를 가진 오픈소스 모델 젬마(Gemma)와 라마\\n(Llama)보다 대부분 벤치마크에서 더 높은 평가를 획득\\n∙ MMLU* 평가에서 미스트랄 3B는 60.9점을 얻어 구글의 ‘젬마 2 2B’(52.4점)와 메타의 ‘라마 3.2\\n3B’(56.2점)를 앞섰고, 미스트랄 8B는 65.0점으로 ‘라마 3.1 8B’(64.7점)와 1년 전 출시된 자체\\n모델 ‘미스트랄 7B’(62.5점)를 능가\\n* 다양한 주제에 대한 모델의 광범위한 지식과 추론 능력을 평가하는 벤치마크\\n∙ 미스트랄 8B는 코딩 능력을 평가하는 HumanEval pass@1*에서만 34.8점으로 ‘라마 3.1\\n8B’(37.8점)보다 소폭 낮은 점수를 기록\\n* AI 모델이 한 번의 시도로 정확한 코드를 생성할 수 있는 능력을 평가하는 벤치마크\\n<미스트랄 3B/7B와 경쟁 모델의 벤치마크 평가 비교>\\n☞ 출처: Mistral AI, Un Ministral, des Ministraux-Introducing the world’s best edge models, 2024.10.16.\\n10\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 13, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n카카오, 통합 AI 브랜드 겸 신규 AI 서비스 ‘카나나’ 공개\\nKEY Contents\\nn 카카오가 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제공하는 AI\\n메이트 서비스인 ‘카나나’를 공개 했으며 카카오톡과 별개의 앱으로 출시 예정\\nn 카카오는 자체 언어모델로 용량 별로 카나나 플래그, 카나나 에센스, 카나나 나노도 개발\\n중으로, 에센스와 나노를 중심으로 주요 서비스에 적용할 계획\\n£카카오의 신규 AI 서비스 ‘카나나’, 개인메이트 ‘나나’와 그룹메이트 ‘카나’로 구현\\nn 카카오가 2024년 10월 22~24일 열린 개발자 컨퍼런스 ‘if(kakaoAI)2024’에서 그룹 전체의\\nAI 비전과 방향성을 공개하고 통합 AI 브랜드 ‘카나나(Kanana)’를 발표\\n∙ 사명인 카카오와 함께, ‘나에게 배워 나처럼 생각하고 행동한다’는 의미의 네이티브(Native), ‘배우지\\n않아도 자연스럽게 사용 가능한 기술’이라는 의미의 내츄럴(Natural) 등의 단어를 조합한 카나나는\\n‘가장 나다운 AI’를 의미\\n∙ 카카오는 동 브랜드를 자사가 개발하는 주요 AI 모델과 신규 서비스의 이름에 두루 사용할 계획으로,\\nAI 메이트 서비스 ‘카나나’ 출시 계획도 공개\\nn 카나나는 대화의 맥락 속에서 주요 정보를 기억해 이용자에게 최적화된 답변을 제시하는 ‘AI 메이트’를\\n지향하며, 개인메이트 ‘나나(nana)’와 그룹메이트 ‘카나(kana)’로 구현\\n∙ 개인메이트 나나는 이용자와 일대일 대화 및 이용자가 참여한 그룹 대화도 기억해 최적화된 개인화\\n경험을 제공하며, 일례로 그룹대화에서 나눈 컨퍼런스 참석 일정과 준비물을 기억해 이를 잊지 않도록\\n메시지로 전송\\n∙ 카나는 상주하는 그룹대화 안에서의 대화 내용만 기억해 이용자를 지원하며, 가령 스터디 그룹대화에서\\n함께 읽은 논문 관련 퀴즈를 내주고 채점과 부연 설명을 제공\\n∙ 카카오는 카나나를 카카오톡과 별개의 앱으로 출시할 예정으로, 연내 사내 테스트 버전 출시를 통해\\n완성도를 높여갈 계획\\nn 카카오는 자체 생성AI 모델도 연구개발 중으로, 언어모델은 용량에 따라 △카나나 플래그 △카나나\\n에센스 △카나나 나노로 분류되며, 글로벌 수준의 성능을 갖춘 에센스와 나노를 중심으로 카카오의\\n주요 서비스에 적용할 계획\\nn 카카오는 이번 행사에서 내부의 AI 리스크 관리 체계인 ‘Kakao ASI(AI Safety Initiative)’도 강조\\n∙ Kakao ASI는 안전하고 윤리적인 AI 기술 개발 및 운영 시스템을 구축하기 위한 종합 지침으로서,\\n기술의 설계부터 개발, 테스트, 배포, 모니터링, 업데이트 등 AI 시스템의 전 생애주기에서 발생할 수\\n있는 리스크에 선제적 대응 추구\\n☞ 출처: Kakao, 카카오, ‘if(kakaoAI)2024’에서 그룹 AI 비전 공개…AI 메이트 ‘카나나’도 처음 선보여, 2024.10.22.\\n11\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 14, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n2024년 노벨 물리학상과 화학상, AI 관련 연구자들이 수상\\nKEY Contents\\nn 2024년 노벨 물리학상은 물리학 원리를 바탕으로 인공 신경망을 이용한 머신러닝의 토대가 되는\\n방법을 개발한 존 홉필드와 제프리 힌턴이 수상\\nn 2024년 노벨 화학상은 단백질 설계에 기여한 데이비드 베이커 및 단백질 구조를 예측하는 AI\\n모델을 개발한 딥마인드의 데미스 허사비스와 존 점퍼가 수상\\n£노벨 물리학상, 인공 신경망 연구한 존 홉필드 교수와 제프리 힌턴 교수가 수상\\nn 스웨덴 왕립과학원 노벨위원회는 2024년 10월 8일 존 홉필드(John Hopfield) 미국 프린스턴⼤\\n교수와 제프리 힌턴(Geoffrey Hinton) 캐나다 토론토⼤ 교수에게 인공 신경망을 이용한 머신러닝의\\n토대가 되는 방법을 개발한 공로로 노벨 물리학상을 수여\\n∙ 홉필드는 물리학의 원리를 이용해 왜곡되거나 불완전한 입력 패턴과 가장 유사하게 저장된 패턴을\\n찾아내고 재구성할 수 있는 초기 인공 신경망 모델인 ‘홉필드 네트워크(Hopfield Network)’를 개발\\n∙ 힌턴은 홉필드 네트워크를 토대로 ‘볼츠만 머신(Boltzmann Machine)’을 고안했으며, 이 모델은\\n통계물리학을 활용해 주어진 데이터에서 특징적 요소를 인식하여 인간의 개입 없이 학습된 패턴\\n유형을 활용해 새로운 예제를 생성 가능\\n∙ 힌턴은 인공 신경망이 데이터를 통해 학습할 수 있다는 개념으로 머신러닝의 폭발적 발전을\\n이끌었으며, 인공 신경망은 현재 신소재 발견을 비롯한 광범위한 물리학 연구에 활용되는 추세\\n£노벨 화학상, 단백질 구조 예측 AI 모델 개발한 딥마인드 연구진 등 3인이 수상\\nn 데이비드 베이커(David Baker) 미국 워싱턴⼤ 교수와 데미스 허사비스(Demis Hassabis) 구글\\n딥마인드 CEO, 존 점퍼(John Jumper) 구글 딥마인드 수석 연구원은 새로운 단백질 생성 및 AI를\\n활용한 단백질 구조 예측에 대한 공로로 2024년 10월 9일 노벨 화학상을 수상\\n∙ 베이커 교수는 90년대 말 단백질 구조를 예측하는 컴퓨터 소프트웨어 ‘로제타(Rosetta)’를 개발*했으며,\\n2003년에는 단백질의 기본 요소인 아미노산을 이용해 기존 단백질과 다른 새로운 단백질을 설계\\n* 로제타폴드를 소개한 2021년 Science 논문에는 로제타폴드의 핵심개발자이자 제1저자인 현 백민경 교수\\n∙ 허사비스와 점퍼는 1970년대부터 난제로 남아있던 단백질 구조 예측에 결정적 기여를 한 AI 모델\\n‘알파폴드(AlphaFold) 2’를 2020년 발표하고 오픈소스로 공개\\n∙ 2억 개에 달하는 단백질 구조를 예측한 알파폴드 2는 과거에는 몇 년이 걸리거나 불가능하던 단백질\\n구조 예측을 몇 분 만에 완료할 수 있으며, 2024년 10월까지 190개국 200만 명 이상에 의해 사용\\n∙ 노벨위원회에 따르면 단백질의 구조 예측과 새로운 단백질의 설계는 특정 질병이나 항생제 내성의\\n발생원인 이해 및 새로운 의약품이나 나노소재 개발 등으로 인류에게 막대한 이익을 가져올 전망\\n☞ 출처: The Nobel Prize, They used physics to find patterns in information, 2024.10.08.\\nThe Nobel Prize, They have revealed proteins’ secrets through computing and artificial intelligence, 2024.10.09.\\n12\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 15, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 국무부, AI 연구에서 국제협력을 위한 ‘글로벌 AI 연구 의제’ 발표\\nKEY Contents\\nn 미국 국무부는 바이든 대통령의 AI 행정명령에 따라 국제협력을 통해 포괄적이고 조정된 AI\\nR&D 접근방식을 제시한 ‘글로벌 AI 연구 의제(GAIRA)’를 발표\\nn 국무부는 GAIRA를 통해 AI R&D 원칙과 안전하고 신뢰할 수 있는 AI 발전을 위한 연구\\n우선순위, 주요 이해관계자별 권장 사항을 제시\\n£국무부, AI 연구 우선순위로 포괄적 연구 인프라 조성과 글로벌 도전과제 해결 등 제시\\nn 미국 국무부(United States Department of State)가 2024년 9월 23일 국제협력을 통해 안전하고\\n신뢰할 수 있는 AI 시스템을 개발하기 위한 R&D 원칙과 우선순위, 권장 사항을 제시한 ‘글로벌\\nAI 연구 의제(Global AI Research Agenda, 이하 GAIRA)’를 발표\\n∙ 국무부는 2023년 10월 30일 바이든 대통령이 서명한 AI 행정명령에 따라 모든 사람에게 이로운\\n방식으로 개발·사용되는 AI R&D에 대한 포괄적이고 조정된 접근방식을 마련하고자 GAIRA를 작성하고,\\nAI 연구에서 3가지 권장 원칙으로 △포용성·형평성 △책임 있는 연구 수행 △파트너십과 협업을 제시\\nn 국무부는 GAIRA를 통해 안전하고 신뢰할 수 있는 AI를 발전시키기 위한 연구 우선순위를 제시\\n∙ (사회 기술 연구) 기술과 사회 간 상호작용에 대한 이해를 심화하고 인간 복지를 향상하는 AI 시스템의\\n설계와 배포에 관한 연구를 수행 우선\\n∙ (포용적 연구 인프라 조성) AI 기술과 시스템의 혁신을 지원하는 데이터와 컴퓨팅 성능, 연구 플랫폼에\\n대한 접근성을 향상해 AI 연구와 개발 생태계의 다양성을 촉진하고 편향을 완화\\n∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 과제 해결에 도움이 되는 AI\\n애플리케이션을 우선 개발\\n∙ (AI 안전과 보안, 신뢰성을 포함한 AI 기초연구) AI는 아직 개발 초기 단계로 안전하고 신뢰할 수 있는\\nAI 시스템 개발을 위해 더 많은 기술 발전 필요\\n∙ (글로벌 노동 시장에서 AI의 영향 연구) AI가 노동 시장에 미치는 여러 측면을 다루는 연구를 수행하고\\n노동 시장에 미치는 AI의 부정적 영향을 완화하기 위한 전략을 수립\\nn 국무부는 GAIRA를 통해 연구 기금 제공자, 연구 생태계 허브, 연구팀과 같은 이해관계자별로 연구\\n의제의 목표 달성을 위한 권장 사항을 제시\\n∙ (연구 기금 제공자) 투명성을 증진하고 국제 AI 연구 협력을 지원하는 기금을 요청하며 다양한 지역에\\n서 연구 인프라 접근성을 증진하고 민관협력을 추진\\n∙ (연구 생태계 허브) 연구 재현성을 장려하고, AI 연구 가이드라인 관련 협력과 조정을 강화하며, 민간\\n분야에서 중시하는 연구 주제 이외의 연구를 지원\\n∙ (연구팀) 다학제적 팀을 우선 편성하고 지역 연구자들과 협력하며, 사회기술적 방법론과 연구 설계를\\n채택하고 위험 평가 절차를 통합\\n☞ 출처: U.S. Department of State, Global AI Research Agenda, 2024.09.23.\\n13\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 16, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n일본 AI안전연구소, AI 안전성에 대한 평가 관점 가이드 발간\\nKEY Contents\\nn 일본 AI안전연구소는 AI 개발자나 제공자가 안전성 평가에 참조할 수 있는 ‘AI 안전성에 대한\\n평가 관점 가이드’를 발표\\nn 가이드는 AI 안전성의 핵심 요소를 달성하기 위한 10가지 평가 관점과 함께, 평가를 통해\\n효과적 조치를 취했을 때의 기대 목표를 제시\\n£일본 AI안전연구소, AI 개발자나 제공자의 안전성 평가를 위한 가이드라인 제시\\nn 일본 AI안전연구소(Japan AI Safety Institute)가 2024년 9월 25일 AI 개발자나 제공자가 안전성\\n평가 시에 참조할 수 있는 기본 개념을 제시하는 ‘AI 안전성에 대한 평가 관점 가이드’를 발간\\n∙ 가이드는 AI 안전성의 핵심 요소로 △인간중심 △안전성 △공평성 △프라이버시 보호 △보안 △투명성을\\n제시하고, 이를 달성하기 위한 10가지 평가 관점 및 평가를 통한 효과적 조치 이후의 기대 목표를 수립\\n<AI 안전성의 핵심 요소를 고려한 AI 안전성 평가 관점>\\n평가 관점 관련 AI 안전성 요소 기대 목표\\n유해 정보의 출력 통제 인간중심, 안전성, 공정성 Ÿ LLM 시스템이 테러, 범죄, 불쾌한 표현 등 유해 정보의 출력을 통제 가능\\n허위 정보와 Ÿ LLM 시스템의 출력에 대한 사실 검증 메커니즘 구축\\n인간중심, 안전성, 투명성\\n조작 방지 Ÿ LLM 시스템의 출력에 의한 사용자 결정의 조작 방지\\nŸ LLM 시스템 출력에 유해한 편향이 없으며 개인이나 집단에 대한 불공정한\\n공정성과 포용성 인간중심, 공정성, 투명성 차별 부재\\nŸ LLM 시스템의 출력을 모든 최종 사용자가 이해 가능\\n고위험 사용 및 Ÿ LLM 시스템이 본래 목적과 다르게 부적절하게 사용되어도 피해나 불이익\\n인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ LLM 시스템이 정보의 중요성에 따라 프라이버시를 적절히 보호\\nŸ LLM 시스템의 허가되지 않은 운영 및 비의도적 수정 또는 중단으로 인한\\n보안 보안\\n기밀정보의 유출 방지\\nŸ LLM 시스템 작동에 대한 증거 제시 등을 목적으로 출력의 근거를 기술적\\n설명 가능성 투명성\\n으로 합리적인 범위에서 확인 가능\\nŸ LLM 시스템이 적대적 프롬프트, 왜곡된 데이터 및 잘못된 입력 등 예상치\\n견고성 안전성, 투명성\\n않은 입력에 대해 안정적 출력을 제공\\nŸ LLM 시스템 학습을 위한 데이터가 적절한 상태로 유지되고 데이터 이력이\\n데이터 품질 안전성, 공정성, 투명성\\n적절히 관리되는 상태\\nŸ LLM 시스템에 대한 다양한 유형의 검증이 모델 학습 단계에서 시스템 사용\\n검증 가능성 투명성\\n시점까지 제공되는 상태\\nn AI 안전성 평가는 기본적으로 AI 시스템의 개발자 및 제공자에 의해 실시되며, AI 시스템 개발, 배포,\\n사용 단계에서 적절한 간격으로 시행될 필요\\n∙ AI 안전성 평가 범위는 개발 단계에서는 데이터, 배포와 사용 단계에서는 전체 LLM 시스템 등으로 달라질 수 있으며,\\n평가는 한 차례가 아니라 반복적으로 실시\\n☞ 출처: Japan AI Safety Institute, AIセーフティに関する評価観点ガイドの公開, 2024.09.25.\\n14\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 17, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글 딥마인드, 반도체 칩 레이아웃 설계하는 AI 모델 ‘알파칩’ 발표\\nKEY Contents\\nn 구글 딥마인드가 강화학습 방식으로 반도체 칩 레이아웃을 설계하여 사람이 몇 주에서 몇 달이\\n걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성하는 AI 모델 ‘알파칩’을 공개\\nn 구글은 2020년 처음 알파칩에 관한 연구 논문을 발표한 뒤, 자체 AI 칩 TPU 개발 시\\n알파칩을 활용해 칩 성능을 개선하고 개발 주기를 단축\\n£알파칩, 구글의 자체 AI 칩 TPU의 레이아웃 설계에도 기여\\nn 구글 딥마인드가 2024년 9월 26일 반도체 칩의 레이아웃을 설계할 수 있는 AI 모델 ‘알파칩\\n(AlphaChip)’을 공개\\n∙ 2020년 연구 프로젝트로 시작된 알파칩은 강화학습 방식을 사용하여 반도체 칩 레이아웃을 설계하며,\\n사람이 완료하는데 몇 주에서 몇 달이 걸리는 수준의 칩 레이아웃을 몇 시간 만에 생성 가능\\nn 구글은 2020년 알파칩에 대한 연구 논문을 처음 발표했으며, 자체 AI 칩 TPU(Tensor Processing\\nUnit) 개발 시 알파칩을 활용해 칩 레이아웃을 설계\\n∙ TPU는 제미나이(Gemini)뿐 아니라 이마젠(Imagen), 비오(Veo) 등의 이미지 및 동영상 생성 모델과\\n같은 구글 AI 시스템의 핵심 요소를 형성\\n∙ 알파칩은 최신 6세대 TPU를 포함한 새로운 세대마다 칩 레이아웃 설계를 개선해 설계주기를\\n단축하고 더 높은 성능의 칩 생산에 기여\\nn 알파칩은 바둑에 특화된 알파고(AlphaGo) 및 바둑, 체스, 쇼기(일본 장기)를 마스터한 알파제로\\n(AlphaZero)와 비슷하게 칩 레이아웃 설계를 게임처럼 접근\\n∙ 알파칩은 모든 부품을 배치할 때까지 한 번에 하나의 회로 부품을 배치하고 최종 레이아웃의 품질에 따라\\n보상을 받게 되며, 상호 연결된 부품 간 관계를 학습하고 칩 전체로 확장해 레이아웃을 개선\\nn 구글은 자체 AI 칩 TPU뿐 아니라 영국 반도체 기업 ARM과 협력해 개발한 데이터센터용 CPU인\\n액시온(Axion) 프로세서도 알파칩으로 레이아웃을 생성했으며, 타사에도 알파칩을 제공\\n∙ 대만의 반도체 기업 미디어텍(MediaTek)은 삼성 스마트폰에 사용되는 ‘다이멘시티 플래그십(Dimensity\\nFlagship) 5G’와 같은 첨단 칩 개발에 알파칩을 활용해 개발을 가속화하고 칩 성능을 개선\\nn 구글 딥마인드는 현재 알파칩의 차기 버전을 개발 중으로, 향후 알파칩이 칩 설계주기의 전 단계를\\n최적화하고 스마트폰, 의료 장비, 농업 센서 등에 사용되는 맞춤형 하드웨어의 칩 설계에 혁신을\\n가져올 것으로 기대\\n☞ 출처: Google Deepmind, How AlphaChip transformed computer chip design, 2024.09.26.\\n15\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 18, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트에 트랜스포머 아키텍처의 대안 필요성 강조\\nKEY Contents\\nn 이스라엘 AI 스타트업 AI21의 오리 고센 CEO는 AI 모델 개발에 주로 활용되는 트랜스포머\\n아키텍처가 느린 속도와 과도한 연산 비용으로 인해 AI 에이전트에 부적합하다고 지적\\nn 고센 CEO는 AI 에이전트를 활성화하려면 메모리 사용을 최적화하여 효율적 연산과 비용\\n절감을 지원하는 맘바나 잠바와 같은 대체 아키텍처에 주목해야 한다고 주장\\n£AI 에이전트 활성화를 위해 향상된 메모리 성능을 갖춘 대체 아키텍처 채택 필요\\nn 이스라엘의 AI 스타트업 AI21의 오리 고센(Ori Goshen) CEO가 AI 에이전트를 활성화하려면\\n트랜스포머(Transformer)* 이외의 새로운 아키텍처**가 필요하다고 주장\\n* 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망\\n** AI 시스템이 데이터를 처리하고 학습하기 위한 신경망의 전체적인 구조와 설계 방식을 의미\\n∙ 트랜스포머는 현재 AI 모델 개발에서 가장 많이 사용되는 아키텍처이지만, 다중 에이전트 생태계 조성\\n측면에서는 한계를 내포\\n∙ 트랜스포머 아키텍처는 처리하는 컨텍스트가 길수록 속도가 느리고 연산 비용이 많이 드는데, AI\\n에이전트는 LLM을 여러 차례 호출해야 하고 각 단계에서 광범위한 컨텍스트를 사용하는 경우가 많아\\n처리 과정에서 지연이 발생\\nn 고센 CEO는 ‘맘바(Mamba)’와 ‘잠바(Jamba)’와 같은 대체 아키텍처를 활용하면 AI 에이전트를 더\\n효율적이고 저렴하게 만들 수 있다고 강조\\n∙ 카네기멜론⼤와 프린스턴⼤ 연구진이 개발한 맘바는 트랜스포머 모델의 핵심인 어텐션(Attention)*\\n메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사용을 최적화\\n* 입력된 데이터 간 연관성을 파악해 상호작용을 계산하는 메커니즘\\n∙ 미스트랄이 2024년 7월 ‘코드스트랄(Codestral) 맘바 7B’를, UAE의 AI 기업 팔콘(Falcon)이 8월\\n‘팔콘 맘바 7B’를 출시하는 등, 최근 오픈소스 AI 개발자 사이에서 맘바의 인기가 높아지는 추세\\n∙ AI21 역시 맘바 아키텍처를 토대로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바 아키텍처를\\n활용해 기반모델을 개발\\nn 고센 CEO는 AI 에이전트가 최근 들어서야 부상하고 있으며 대다수 AI 에이전트가 아직 상용화되지 않은\\n이유가 트랜스포머로 구축된 LLM의 한계 때문이라고 지적\\n∙ AI 에이전트가 상용화되려면 데이터 간 연관성을 파악해 확률적으로 가장 그럴듯한 답변을 생성하는\\nLLM의 신뢰성을 높여야 하며, 필요한 수준의 신뢰성 보장을 위해서는 추가적인 요소의 통합이 필요\\n∙ 최근 서비스나우(ServiceNow), 세일즈포스 등 여러 기업이 AI 에이전트나 에이전트 구축을 지원하는\\n플랫폼을 출시하는 추세로, 고센 CEO는 이러한 추세가 적절한 기반모델과 아키텍처를 조합함으로써 더욱\\n확산될 것으로 예상\\n☞ 출처: Venturebeat, AI21 CEO says transformers not right for AI agents due to error perpetuation, 2024.10.11.\\n16\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 19, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과센터, 근로자 관점에서 자동화 기술의 영향 조사\\nKEY Contents\\nn MIT 산업성과센터가 설문조사를 통해 근로자 관점의 자동화 기술의 영향을 조사한 결과,\\n근로자들은 직장 내 안전, 임금, 업무 자율성 등에서 자동화를 긍정적으로 평가\\nn 복잡한 문제 해결이 필요한 작업을 수행하는 근로자 및 자신의 직무에 만족하는 근로자일수록\\n자동화의 영향에 긍정적인 것으로 확인\\n£근로자들, 직장 내 안전, 임금, 업무 자율성 등에서 자동화의 영향에 긍정적\\nn MIT 산업성과센터(IPC)는 2024년 9월 30일 9개국* 9천 명 이상의 근로자에 대한 설문조사를\\n바탕으로 근로자 관점에서 자동화 기술을 평가한 연구 결과를 공개\\n* 독일, 미국, 스페인, 영국, 이탈리아, 일본, 폴란드, 프랑스, 호주\\n∙ 연구진은 설문조사를 통해 업무 환경, 직장에서 사용되는 자동화 기술(로봇 및 AI 등), 업무와 기술에\\n대한 태도, 기술이 업무에 미치는 영향을 조사\\nn 조사 결과, 근로자들 사이에서는 직장 내 안전이나 임금, 업무 자율성 등의 측면에서 자동화가\\n긍정적 영향을 미칠 것이란 응답이 우세\\n∙ 자동화가 직장 내 안전에 미치는 영향에 대하여 응답자 44.9%는 긍정적으로 평가했으며 부정적\\n응답은 12.5%에 불과\\n∙ 자동화가 임금에 미치는 영향은 28.8%가 긍정적, 24.8%는 부정적으로 답했으며, 업무 자율성에\\n미치는 영향은 37.9%는 긍정적, 19.9%가 부정적이라고 응답\\nn 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적으로 나타났으나, 국가 별 차이가 존재하며\\n미국 근로자들이 가장 비관적 태도를 보유\\n∙ 9개국 중 미국에서만 자동화가 임금 및 직업 안정성에 부정적이라는 응답이 긍정적이라는 응답보다\\n우세(임금: –0.6%, 직업 안정성: -4.6%)*\\n* 긍정적 응답에서 부정적 응답 비율을 뺀 수치\\nn 직무 유형에서는 복잡한 문제 해결이나 새로운 아이디어가 필요한 작업을 수행하는 사무직 근로자가\\n자동화에 더 긍정적이며, 직장 내 처우도 자동화에 대한 근로자의 인식에 영향을 발휘\\n∙ 고용주가 근로자를 적절히 대우하고 안전에 투자하는 직장에서 일하는 근로자는 직장 내 자동화의\\n영향에 긍정적이며, 직무 만족도와 신뢰도도 자동화에 대한 긍정적 인식에 영향을 미치는 요인으로 확인\\nn 연구진은 조사 결과를 바탕으로 직장 내 원활한 자동화 기술 도입을 위해 직무 설계를 통해 근로자가\\n복잡한 문제를 해결할 수 있는 역할을 만들 것을 권고\\n∙ 근로자들은 신기술 사용과 관련된 보너스가 제공되면 자동화에 더 긍정적인 것으로 나타나, 생산성\\n향상을 위한 자동화 기술 사용에 금전적 보상을 제공하는 방안도 고려 필요\\n☞ 출처: MIT IPC, Automation from the Worker’s Perspective, 2024.09.30.\\n17\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 20, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n다이스 조사, AI 전문가의 73%는 2025년 중 이직 고려\\nKEY Contents\\nn 다이스에 따르면, AI 전문가의 73%는 2025년 이직을 계획 중이며, 58%는 2024년 중 현재보다\\n더 나은 일자리를 찾을 자신이 있다고 응답해 여타 기술 전문가 대비 직업 전망을 낙관\\nn AI 전문가들은 여타 기술 전문가 대비 AI 도구 사용에도 적극적이며, 업무에 생성AI가 상당한\\n영향을 미친다는 응답도 36%로 여타 기술 전문가(22%) 대비 높은 수치를 기록\\n£AI 전문가들, 일반적인 기술 전문가보다 직업 전망에 낙관적\\nn 미국 기술직 채용 플랫폼 다이스(Dice)의 조사에 따르면, AI 기술 전문가는 일반적인 기술 전문가\\n대비 기술 산업의 미래와 자기 경력에 대하여 낙관적\\n∙ 이번 조사는 520명의 미국 정규직 기술 전문가와 390명의 인사 전문가의 응답을 토대로 기술 분야의\\n일자리 시장 환경을 분석\\n∙ 2024년 동안 주요 빅테크가 기술직에 대한 정리해고를 단행하고 기술직 채용도 2021~2022년 대비\\n대폭 감소하는 등 일자리 시장의 침체에도 2024년 기술과 사업의 핵심 요소로 부상한 AI 분야의\\n전문가들은 직업 전망을 낙관\\nn AI 전문가의 73%는 2025년에 이직을 계획 중이며, 58%는 2024년 중 현재보다 더 나은 새로운 일자리를\\n찾을 자신이 있다고 응답\\n∙ 일반적인 기술 전문가의 경우 65%가 2025년 중 이직을 계획 중이며, 2024년 더 나은 신규 일자리를\\n찾을 수 있다고 자신하는 비율은 36%에 불과\\n∙ AI 전문가는 빅테크를 선호하는 비율이 29%로 일반적인 기술 전문가(18%) 대비 더 높게 나타났으며,\\n이는 예산 규모가 더 크고 중요한 AI 프로젝트에 관심이 있거나 빅테크의 채용 가능성에 자신 있기\\n때문으로 추측\\nn 그러나 AI 전문가들은 기업에서 자신이 맡은 업무에 대하여 엇갈린 감정을 표시했으며, 자신의 업무가\\n가치 있다고 느끼는 전문가일수록 현재 역할에 만족할 가능성도 증대할 것으로 추론\\n∙ AI 전문가의 51%는 자신의 프로젝트가 기업에 전략적 가치가 있다고 답했으나, 36%는 투자자나\\n이사회, 외부 관계자에게 기업이 AI로 뭔가를 하고 있음을 보여주기 위한 목적이라고 응답\\nn AI 전문가들은 AI 도구 사용에도 적극적이지만, 일반적인 기술 전문가들은 업무에서 AI 도구 사용을\\n주저하는 편으로, AI 전문가들은 일주일에 1회 이상 AI를 사용하는 비율이 49%에 달했으나, 여타\\n기술 전문가들은 25%에 불과\\nn 생성AI가 미치는 영향에 대해서 AI 전문가 사이에서는 상당한 영향을 미친다는 응답이 36%, 약간의 영향을\\n미친다는 응답이 56%, 영향이 없다는 응답은 8%를 기록했으나, 여타 기술 전문가들은 22%가 상당한 영향,\\n53%는 약간의 영향, 26%는 영향이 없다고 응답\\n☞ 출처: Dice, 3 Key Lessons about the AI Tech Talent Market, 2024.09.05.\\n18\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 21, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, AI로 인해 엔지니어링 인력의 80%가 역량 향상 필요\\nKEY Contents\\nn 가트너에 따르면 생성AI의 도입으로 중장기적으로 소프트웨어 엔지니어링에서 데이터 과학 및\\nAI/ML 역량의 중요성이 커지면서 AI 엔지니어의 수요가 늘어날 전망\\nn 기업들은 AI 엔지니어를 지원하고 기업 내 AI 통합을 촉진하기 위해 AI 개발자 플랫폼에 대한\\n투자를 강화할 필요\\n£생성AI로 소프트웨어 엔지니어링에서 데이터과학과 AI/ML 역량의 중요성 증대\\nn 시장조사기관 가트너(Gartner)에 따르면 2027년까지 생성AI로 인해 소프트웨어 엔지니어링\\n인력의 80%가 역량 향상이 필요할 전망\\n∙ AI로 인해 인간 엔지니어에 대한 수요가 감소하거나 심지어 AI가 인간을 대체할 것이라는 예상과\\n달리, 가트너는 AI가 향후 소프트웨어 엔지니어의 역할을 변화시키더라도 인간의 전문성과 창의성은\\n여전히 중요하다고 강조\\nn 가트너에 따르면 생성AI는 소프트웨어 엔지니어의 역할에 단기, 중기, 장기적으로 영향을 미칠 전망\\n∙ 단기적으로는 AI가 기존 개발자의 작업 패턴과 업무를 보완하며 소폭의 생산성 향상 효과를 가져오며,\\nAI의 생산성 향상 효과는 성숙한 엔지니어링 관행을 갖춘 기업의 상급 개발자에게 집중될 전망\\n∙ 중기적으로는 AI 에이전트를 통해 더 많은 업무가 자동화되어 개발자의 작업 패턴의 변화가 예상되며,\\n이는 코드 대부분이 인간이 아닌 AI로 생성되는 AI 네이티브 소프트웨어 엔지니어링의 출현을 의미해\\n자연어 프롬프트 엔지니어링과 검색 증강 생성(RAG)* 기술이 엔지니어링의 필수 역량이 될 전망\\n* 외부 데이터를 활용하여 LLM의 출력 정확성을 향상하는 기술\\n∙ 장기적으로는 기업 내 AI 기반 소프트웨어 수요가 증가하면서 이를 충족하기 위해 소프트웨어\\n엔지니어링, 데이터 과학, AI/ML(머신러닝) 분야의 고유한 기술을 갖춘 훨씬 숙련된 AI 엔지니어가\\n부상할 전망\\n£AI 엔지니어를 지원하기 위해 기업의 AI 개발자 플랫폼 투자 필요\\nn 가트너가 2023년 4분기에 미국과 영국 기업 300개를 대상으로 실시한 설문조사에 따르면 소프트웨어\\n엔지니어링 책임자의 56%가 AI/ML 엔지니어를 2024년 가장 수요가 많은 직업으로 평가\\n∙ 기업들은 AI 엔지니어를 지원하기 위해 AI 개발자 플랫폼에 투자해야 하며, AI 개발자 플랫폼은\\n기업이 AI 역량을 더욱 효율적으로 구축하고 AI를 기업 솔루션에 대규모로 통합하는 데 도움이 될 전망\\n∙ 기업들은 AI 개발자 플랫폼 투자를 통해 소프트웨어 엔지니어링팀의 역량을 강화하고 지속적인 AI\\n통합과 개발을 추진하는 도구와 프로세스를 채택 필요\\n☞ 출처: Gartner, Gartner Says Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027,\\n2024.10.03.\\n19\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 22, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='SPRi AI Brief |\\n2024-11월호\\n인디드 조사 결과, 생성AI가 인간 근로자 대체할 가능성은 희박\\nKEY Contents\\nn 인디드가 2,800개 이상의 직무 기술에 대한 생성AI의 수행 능력을 분석해 인간을 대체할\\n가능성을 평가한 결과, 생성AI로 대체될 가능성이 “매우 높은” 것으로 평가된 기술은 전무\\nn 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이며, 물리적 작업\\n수행이 필요한 직무 기술에서는 인간 근로자를 대체할 가능성이 희박\\n£생성AI, 문제 해결 역량 및 물리적 작업 수행 역량의 부족으로 인간 근로자 대체에 한계\\nn 미국의 채용 플랫폼 인디드(Indeed) 산하 연구소 하이어링랩(Hiring Lab)이 2024년 9월 25일\\n발표한 연구 결과에 따르면 생성AI가 인간 근로자를 대체할 가능성은 희박\\n∙ 인디드 하이어링랩은 오픈AI의 GPT-4o로 2,800개 이상의 고유한 직무 기술에 대한 생성AI의 수행\\n능력을 분석해 생성AI가 인간을 대체할 가능성을 평가\\n∙ 연구진은 오픈AI의 GPT-4o가 △기술과 관련된 이론적 지식의 제공 역량 △기술을 사용한 문제 해결 역량\\n△기술 활용 시 물리적 작업의 중요성에 관한 판단 능력의 3개 차원에서 자체 수행 능력을 평가하도록 진행\\n∙ 다섯 가지 선택지(매우 낮음, 낮음, 보통, 높음, 매우 높음)로 평가 결과, 인디드가 평가 대상으로 삼은\\n2,800개 이상의 직무 기술 중 68.7%는 생성AI로 대체될 가능성이 “매우 낮음” 또는 “낮음”으로\\n평가됐으며, “매우 높음”으로 평가된 기술은 전무\\nn 생성AI는 직무 기술의 이론적 지식을 제공하는 자체 능력을 다소 높게 평가했으나, 문제 해결\\n능력 및 물리적 작업의 중요성에 관한 판단 능력은 상대적으로 낮게 평가\\n∙ 생성AI는 직무 기술 중 79.7%에 이론적 지식의 제공 능력을 4점(높음)으로, 기술 중 70.7%에 문제\\n해결 역량을 3점(보통)으로 평가했으며, 기술 중 54%에 대하여 물리적 작업의 필요성이 “높음” 또는\\n“매우 높음”이라고 평가*\\n* 매우 낮음(very unlikely 1점), 낮음(unlikely, 2점), 보통(possible, 3점), 높음(likely, 4점), 매우 높음(very likely, 5점)\\n∙ 생성AI는 물리적 작업을 수행할 몸체가 없어 실제 작업 수행이 필요한 직무 기술에서는 인간 근로자를\\n대체할 가능성이 제한적\\n∙ 일례로 생성AI는 디지털 기술 비중이 큰 소프트웨어 개발 직종의 구인 공고에서 통상 제시되는 직무\\n기술의 71%에 대하여 인간을 대체할 가능성이 “보통” 또는 “높음”으로 평가했으나, 간호사 직종의\\n구인 공고에 제시되는 기술의 약 32.9%만 생성AI로 대체될 가능성이 “보통” 또는 “높음”으로 평가\\nn 인디드는 현재 생성AI의 최대 강점은 직무 기술과 관련된 이론적 지식을 제공하는 능력이라고 강조\\n∙ 생성AI는 직원 생산성을 극대화하여 노동 시장의 경색을 완화할 수 있으며, 물리적 작업 수행이 필요한\\n직업에서도 근로자가 핵심 업무에 집중할 수 있도록 지원 가능\\n∙ 그러나 생성AI는 논리적 오류나 사실과 다른 내용 또는 편향이나 차별과 같은 비윤리적 응답을 출력할\\n가능성도 있으므로 인간의 신중한 검토 필요\\n☞ 출처: Indeed Hiring Lab, AI at Work: Why GenAI Is More Likely To Support Workers Than Replace Them, 2024.09.25.\\n20\\n'),\n",
       " Document(metadata={'source': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'file_path': 'data/SPRi AI Brief_11월호_산업동향_F.pdf', 'page': 23, 'total_pages': 25, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13947', 'Producer': 'Hancom PDF 1.3.0.547', 'CreationDate': \"D:20241105150426+09'00'\", 'ModDate': \"D:20241105150426+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRi AI Brief_11월호_산업동향_F.pdf'}, page_content='Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 신경정보처리시스템재단은 인공지능과 머신러닝 분야의 연구 성과\\n교환을 촉진하는 것을 목적으로 하는 비영리 법인으로 매년 학제간\\n학술대회(NeurIPS)를 주최\\n- 이번 제38회 연례학술대회는 AI 연구자를 위한 실험 설계,\\nNeurIPS\\nLLM을 위한 메타 생성 알고리즘, 정렬에 대한 학제 간 통찰력\\n2024\\n등을 다룰 예정\\n기간 장소 홈페이지\\n2024.12.10~15 캐나다 밴쿠버 https://neurips.cc/\\n- GenAI Summit Maroc 2024는 인공지능과 데이터 분석에\\n초점을 맞춘 최고의 이벤트로, 250명 이상의 업계 리더, 정책\\nGenAI\\n입안자, 전문가가 모여 AI 발전을 탐구\\nSummit\\n- 이번 행사에는 오픈소스 AI, AI 주도 사이버 보안, 우수한\\nMaroc\\n의사결정을 위한 생성AI와 예측 AI 결합 등을 다룰 예정\\n2024\\n기간 장소 홈페이지\\n2024.12.10~11 모로코 https://genaimaroc.com/\\n- AI Summit Seoul 행사는 2018년 개최를 시작으로 금년도는\\n7회 행사로 개최\\n- 이번 행사는 AI와 산업의 융합에 초점을 두고 다양한 글로벌\\n기업과 기관, 학계 전문가 등 전문가들이 한자리에 모여 AI\\nAI Summit\\n및 산업 트렌드 등에 대한 주제 발표 및 워크샵 진행\\nSeoul 2024\\n기간 장소 홈페이지\\n2024.12.10~11 서울(코엑스 그랜드볼룸) https://aisummit.co.kr/\\n21\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q ragas==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor\n",
    "from ragas.testset.docstore import InMemoryDocumentStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기\n",
    "generator_llm = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비평기\n",
    "critic_llm = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할기 설정\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model = 'gpt-4o'))\n",
    "# 구문추출기 생성을 위한 모델 호출(RAGAS와의 호환을 위한 Wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구문추출기 : 문서 핵심 정보 식별 및 추출 역할\n",
    "Keyphrase_extractor = KeyphraseExtractor(llm = langchain_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델도 RAGAS와의 호환을 위해 Wrapper 적용\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docstore 만들기\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter = splitter,\n",
    "    embeddings = ragas_embeddings,\n",
    "    extractor = Keyphrase_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성기 만들기\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm, # 생성기\n",
    "    critic_llm,  # 판별기\n",
    "    ragas_embeddings, # 임베딩모델\n",
    "    docstore=docstore # 문서저장소\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형 분포 결정\n",
    "dirstributions = {simple : 0.4, reasoning : 0.2, multi_context : 0.2, conditional : 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s]              [ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Molmo-72B', 'Benchmark scores', 'Human preference evaluation', 'GPT-4o', 'MolmoE-1B']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How did Molmo-72B perform in human preference evaluation compared to other models like GPT-4o and Jeminae 1.5 Pro?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How does analyzing the correlation between input data help improve the reliability of AI models?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data collection standardization', 'AI model development', 'Data privacy and human rights', 'EU AI law', 'High-risk AI systems']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the requirements for data collection standardization to effectively use AI tools without complexity or relation to data size and utilization scenarios?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data collection standardization', 'AI model development', 'Data privacy and human rights', 'EU AI law', 'High-risk AI systems']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the regulatory measures imposed on high-risk AI systems by the EU AI law?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why is increasing the reliability of LLMs important for their effective application?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the requirements for data collection standardization to effectively use AI tools, specifically excluding considerations related to data size and utilization scenarios. It is clear in its intent to focus on standardization requirements, but it could benefit from further clarification on what aspects of standardization are of interest (e.g., data format, quality control, metadata standards). Additionally, the phrase 'without complexity' is somewhat vague and could be interpreted in various ways, such as ease of implementation or simplicity of the standards themselves. To improve clarity, the question could specify what is meant by 'without complexity' and provide more detail on the aspects of standardization being inquired about.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why is it important to increase the reliability of LLMs for their effective application in AI agents?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the importance of increasing the reliability of Large Language Models (LLMs) for their effective application in AI agents. It is clear in its intent, seeking an explanation of the significance of reliability in this context. The question is specific and does not rely on external references or context, making it understandable and answerable based on the details provided. It effectively communicates its purpose and is self-contained.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"Why is it important to increase the reliability of LLMs for their effective application in AI agents?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking for the regulatory measures imposed on high-risk AI systems by the EU AI law. It specifies the subject of interest (high-risk AI systems) and the context (EU AI law), making the intent clear and allowing for a direct response. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: What are the regulatory measures imposed on high-risk AI systems by the EU AI law?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why are transformers considered a limitation for AI agents according to the context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks what enhances AI agents' answers by analyzing data relationships and boosting LLM reliability. While it is clear that the question seeks a mechanism or method that improves AI agents' responses, it lacks specificity regarding the context or domain in which these improvements are sought. The question could be improved by specifying the type of AI agents, the nature of the data relationships, or the context in which LLM reliability is being evaluated. This would make the question more precise and easier to answer.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why is the popularity of Mamba increasing among AI developers recently?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the reasons behind the increasing popularity of 'Mamba' among AI developers recently. It is clear in its intent, seeking an explanation for a trend in popularity. However, the question assumes that the reader knows what 'Mamba' refers to in the context of AI development, which could be ambiguous without additional context. To improve clarity and answerability, the question could specify what 'Mamba' is (e.g., a software tool, library, framework) and provide a brief description of its relevance to AI development. This would make the question more accessible to those unfamiliar with the term.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks why transformers are considered a limitation for AI agents, referencing 'the context' without providing or describing this context within the question itself. This makes the question unclear and unanswerable for those who do not have access to the unspecified context. To improve clarity and answerability, the question should either include the relevant context directly within the question or be framed in a way that does not rely on external information. Additionally, specifying the particular aspects of transformers or AI agents that are of interest could help clarify the query.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the impact of analyzing the correlation between input data on the reliability of AI models. It is clear in its intent, seeking an explanation of how this analysis contributes to model reliability. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge. However, to enhance clarity, the question could specify the type of AI models or the context in which reliability is being assessed, although this is not strictly necessary for a general answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: How does analyzing the correlation between input data help improve the reliability of AI models?\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What mechanism improves the reliability of AI21's AI agents by analyzing data relationships and enhancing LLM performance?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a mechanism that improves the reliability of AI21's AI agents by analyzing data relationships and enhancing LLM performance. It is clear in its intent, seeking information about a specific mechanism related to AI21's AI agents and their performance. However, it assumes familiarity with AI21's specific technologies or mechanisms without providing additional context or details. To improve clarity and answerability, the question could specify the type of mechanism (e.g., algorithm, framework) or provide more context about AI21's AI agents and their typical performance challenges.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Molmo-72B', 'Benchmark scores', 'Human preference evaluation', 'GPT-4o', 'MolmoE-1B']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How did Molmo-72B perform in human preference evaluation compared to other models like GPT-4o and Jeminae 1.5 Pro?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for a comparison of Molmo-72B's performance in human preference evaluation against other models, specifically GPT-4o and Jeminae 1.5 Pro. It clearly specifies the models of interest and the evaluation criterion (human preference evaluation), making the intent clear. However, the question assumes familiarity with the specific evaluation results or context in which these models were compared, which is not provided within the question itself. To improve clarity and answerability, the question could include a brief description of the evaluation context or criteria used for comparison, or specify the source of the evaluation results.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the importance of increasing the reliability of Large Language Models (LLMs) for their effective application. It is clear in its intent, seeking an explanation or rationale for why reliability is a critical factor in the application of LLMs. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided. It effectively communicates its purpose without ambiguity.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"Why is increasing the reliability of LLMs important for their effective application?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for a comparison of Molmo-72B's performance in human preference evaluation against other models, specifically GPT-4o and Jeminae 1.5 Pro. It clearly specifies the models of interest and the evaluation criterion (human preference evaluation), making the intent clear. However, the question assumes familiarity with the specific evaluation results or context in which these models were compared, which is not provided within the question itself. To improve clarity and answerability, the question could include a brief description of the evaluation context or criteria used for comparison, or specify the source of the evaluation results.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AlphaChip', 'Google Brain', 'AI model', 'TPU development', 'Chip layout design']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What role does Google Brain play in the development and design of AI models like AlphaChip?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of Google Brain in the development and design of AI models, specifically mentioning 'AlphaChip'. It is clear in its intent to understand the contribution or involvement of Google Brain in this context. However, the question assumes knowledge of 'AlphaChip' without providing any context or description of what it is, which may not be familiar to all readers. To improve clarity and answerability, the question could include a brief description of 'AlphaChip' or specify the aspects of development and design it is interested in (e.g., research, engineering, innovation).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"In the context of the evaluation results provided by the Allen Institute for AI, how did Molmo-72B perform in human preference evaluation compared to other models like GPT-4o and Jeminae 1.5 Pro?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for a comparison of Molmo-72B's performance in human preference evaluation against other models such as GPT-4o and Jeminae 1.5 Pro, specifically within the context of evaluation results provided by the Allen Institute for AI. While it clearly specifies the models and the type of evaluation, it assumes access to specific evaluation results from the Allen Institute for AI, which are not provided within the question. This reliance on external context makes the question unclear for those without access to these results. To improve clarity and answerability, the question could include a summary or key points of the evaluation results, or be rephrased to not depend on specific, unpublished documents.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Nobel Prize in Physics and Chemistry 2024', 'Artificial Intelligence research', 'Hopfield Network', 'Boltzmann Machine', 'David Baker and Demis Hassabis']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What contributions have David Baker and Demis Hassabis made to AI and protein structure prediction?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking for the contributions of David Baker and Demis Hassabis to the fields of AI and protein structure prediction. It does not rely on external references or unspecified contexts, making it independent and self-contained. The intent is straightforward, seeking information about the specific contributions of these individuals in the mentioned fields.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What contributions have David Baker and Demis Hassabis made to AI and protein structure prediction?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about advancements in AI for protein structuring, specifically linking David Baker and Demis Hassabis. It is clear in its intent to identify contributions or advancements made by these individuals in the field of AI and protein structuring. However, the phrasing is somewhat ambiguous as it does not specify whether it seeks information on collaborative work between the two or individual contributions that are related. To improve clarity, the question could specify whether it is asking about joint efforts or separate advancements by each individual in the context of AI for protein structuring.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the individual contributions of David Baker and Demis Hassabis to AI advancements in protein structuring?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the individual contributions of David Baker and Demis Hassabis to AI advancements in protein structuring. It is clear in specifying the individuals of interest and the specific field (AI advancements in protein structuring), making the intent clear. The question is independent and does not rely on external references or unspecified contexts, allowing it to be understood and answered based on the details provided. However, to enhance clarity, the question could specify whether it seeks a comparison of their contributions or a separate account of each individual's work.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What are the individual contributions of David Baker and Demis Hassabis to AI advancements in protein structuring?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the contributions of David Baker and Demis Hassabis to AI and protein structure prediction, requiring similar depth and breadth of information.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"In the context of the Allen Institute for AI's evaluation, how did Molmo-72B perform in human preference ratings compared to models like GPT-4o and Jeminae 1.5 Pro?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for a comparison of Molmo-72B's performance in human preference ratings against models like GPT-4o and Jeminae 1.5 Pro, specifically within the context of the Allen Institute for AI's evaluation. While it specifies the models and the evaluation context, it assumes familiarity with the specific evaluation by the Allen Institute for AI without providing details about it. To improve clarity and answerability, the question could include a brief description of the evaluation criteria or context, or specify the aspects of human preference ratings being compared (e.g., accuracy, fluency, relevance).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 전문가', '기술 전문가', '직업 전망', '미국 기술직 채용 플랫폼', 'AI 도구 사용']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"AI 전문가들은 2025년까지 어떤 직업 전망을 계획하고 있나요?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Global AI challenges', 'AI development priorities', 'AI safety and reliability', 'AI impact on labor market', 'International AI research collaboration']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What role does AI play in addressing global challenges such as environmental issues, economic resilience, and social welfare?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about the role of AI in addressing global challenges, specifically mentioning environmental issues, economic resilience, and social welfare. It does not rely on external references or unspecified contexts, making it independent and self-contained. The intent is clear, seeking an explanation or discussion on how AI contributes to these areas. This makes the question understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the career plans of AI experts until the year 2025. It is clear in its intent, seeking information on the professional outlook or plans of AI specialists. However, the question is somewhat broad as it does not specify which aspects of career planning it is interested in (e.g., industry trends, personal career goals, research focus). To improve clarity and answerability, the question could specify the type of career plans or trends it is interested in, such as specific industries, roles, or geographic regions.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"AI 전문가들은 2025년까지 어떤 직업 전망을 계획하고 있나요?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'AI helps in solving global challenges such as environmental issues, economic resilience, and social welfare.', 'verdict': 1}\n",
      "Generating:  10%|█         | 1/10 [02:42<24:25, 162.81s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the percentage of AI experts planning career shifts by 2025 and seeks a comparison with the percentage for 2024. While the intent is clear in terms of seeking statistical data and a comparison, the question assumes the existence of specific data or studies that provide these percentages, which may not be readily available or known to the audience. To improve clarity and answerability, the question could specify the source of this data or context, such as a particular survey or report, or it could be rephrased to ask about general trends or predictions in career shifts among AI experts if specific data is not available.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the predicted percentages of AI experts planning career shifts by 2025 according to the MIT IPC report, and how do these predictions compare to those for 2024?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for specific predictions from the MIT IPC report regarding the percentages of AI experts planning career shifts by 2025 and a comparison to predictions for 2024. It clearly specifies the source (MIT IPC report) and the information sought (predicted percentages for 2024 and 2025), making the intent clear. However, it assumes access to the MIT IPC report without providing any details or context from the report itself, which makes it unclear for those without access to this specific document. To improve clarity and answerability, the question could include a brief summary or key findings from the report, or alternatively, frame the question in a way that does not rely on specific, unpublished documents.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Meta Movie Gen', 'AI-enabled era', 'Content creators', \"Runway's Gen 3\", 'Sora AI model']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is Runway's Gen 3, and how does it compare to Meta Movie Gen in terms of human preference ratings?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for an explanation of 'Runway's Gen 3' and a comparison with 'Meta Movie Gen' based on human preference ratings. It is clear in its intent to understand both what Runway's Gen 3 is and how it performs relative to Meta Movie Gen in a specific metric (human preference ratings). However, the question assumes familiarity with both 'Runway's Gen 3' and 'Meta Movie Gen' without providing any context or description of these terms, which may not be known to all readers. To improve clarity and answerability, the question could include a brief description of what Runway's Gen 3 and Meta Movie Gen are, or specify the context in which these human preference ratings are evaluated (e.g., in terms of user experience, visual quality, etc.).\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['MIT 산업성과센터', '자동화 기술 영향', '근로자 관점', '설문조사 결과', '자동화 기술 평가']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How does the MIT Industrial Performance Center assess the impact of automation technology on workers?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the assessment by the MIT Industrial Performance Center regarding the impact of automation technology on workers. It is clear in specifying the organization (MIT Industrial Performance Center) and the topic of interest (impact of automation technology on workers), making the intent clear. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge about the MIT Industrial Performance Center's work. However, for enhanced clarity, the question could specify whether it seeks qualitative assessments, quantitative data, or specific studies or reports.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The MIT Industrial Performance Center assesses the impact of automation technology on workers through surveys, evaluating aspects such as job safety, wages, and job autonomy. The results indicate that workers generally perceive the impact of automation positively, although there are variations across different countries.', 'verdict': 1}\n",
      "Generating:  20%|██        | 2/10 [03:18<11:45, 88.19s/it] [ragas.testset.evolutions.INFO] rewritten question: \"What is Runway's Gen 3, and how does it compare to Meta Movie Gen in terms of human preference ratings for AI-generated video content?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for an explanation of 'Runway's Gen 3' and a comparison with 'Meta Movie Gen' based on human preference ratings for AI-generated video content. It is clear in specifying the two subjects of interest (Runway's Gen 3 and Meta Movie Gen) and the criteria for comparison (human preference ratings). However, the question assumes familiarity with 'Runway's Gen 3' and 'Meta Movie Gen' without providing any context or description of these terms, which might not be known to all readers. To improve clarity and answerability, the question could include a brief description of what 'Runway's Gen 3' and 'Meta Movie Gen' are, or specify the context in which these human preference ratings were obtained.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 4 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['생성AI', '소프트웨어 엔지니어링', '데이터 과학', 'AI/ML 역량', 'AI 개발자 플랫폼']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How can companies strengthen their investment in AI developer platforms to promote AI integration within their organizations?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking how companies can enhance their investment in AI developer platforms to facilitate AI integration within their organizations. It specifies the focus on investment strategies and the goal of promoting AI integration, making it understandable and answerable without requiring additional context. The question is broad enough to allow for a variety of strategies and approaches, but it remains specific in its focus on AI developer platforms and organizational integration.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: How can companies strengthen their investment in AI developer platforms to promote AI integration within their organizations?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about investment focus areas that aid AI developer platforms within companies to enhance AI integration. It is clear in its intent to identify specific investment strategies or areas that can support AI developer platforms. However, the question could be improved by specifying what aspects of AI integration or developer platforms it refers to, such as infrastructure, tools, training, or innovation. This would help narrow down the focus and provide a more precise answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: To enhance AI integration, what investment focus aids AI developer platforms within companies?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question specifically asks about strengthening investment in AI developer platforms to promote AI integration, indicating a focus on both investment and integration. The second question is broader, asking generally how investment can boost AI platforms, without specifying developer platforms or integration. This results in different depths and breadths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Companies need to strengthen investment in AI developers' platforms to support AI engineering and promote AI integration within the company.\", 'verdict': 1}\n",
      "Generating:  30%|███       | 3/10 [03:48<07:10, 61.54s/it][ragas.testset.evolutions.INFO] rewritten question: \"What role does Google Brain play in the research and engineering of AI models, specifically in the development and design of AlphaChip, an AI model designed for efficient chip layout and performance improvement?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the specific role of Google Brain in the research and engineering of AI models, with a focus on the development and design of AlphaChip. It specifies the area of interest (AI models, AlphaChip) and the aspect of Google Brain's involvement, making it understandable and answerable. The question does not rely on external references or unspecified contexts, thus meeting the criteria for independence. However, to enhance clarity, it could briefly mention what AlphaChip is, assuming the audience might not be familiar with it.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What role does Google Brain play in the research and engineering of AI models, specifically in the development and design of AlphaChip, an AI model designed for efficient chip layout and performance improvement?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the potential impact on Google Brain's role in AI research if AlphaChip's chip layout efficiency is prioritized over performance improvement. It is clear in specifying the entities involved (Google Brain, AlphaChip) and the scenario of interest (prioritizing chip layout efficiency over performance improvement). However, the question assumes knowledge of AlphaChip and its relevance to Google Brain's research, which may not be clear to all readers. To improve clarity and answerability, the question could provide a brief context about AlphaChip's relationship with Google Brain or specify the aspects of AI research that might be affected by such a prioritization.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: How do the limitations of Transformer architectures in AI agents necessitate the optimization of memory usage for enhancing model reliability?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the relationship between the limitations of Transformer architectures in AI agents and the need to optimize memory usage to enhance model reliability. It is clear in its intent to explore the connection between architectural limitations and memory optimization. However, the question could be improved by specifying which limitations of Transformer architectures are being referred to, as well as what aspects of model reliability are of interest (e.g., accuracy, efficiency, scalability). Providing these details would make the question more specific and easier to answer comprehensively.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: How might Google Brain's role in AI research be affected if AlphaChip, a project related to Google's AI initiatives, prioritizes chip layout efficiency over performance improvement?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the potential impact on Google Brain's role in AI research if the AlphaChip project prioritizes chip layout efficiency over performance improvement. It specifies the entities involved (Google Brain, AlphaChip) and the specific focus of interest (chip layout efficiency vs. performance improvement). However, it assumes familiarity with the AlphaChip project and its relation to Google's AI initiatives, which may not be known to all readers. To improve independence and answerability, the question could include a brief description of the AlphaChip project and its current objectives or significance within Google's AI initiatives.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['메커니즘 데이터 정리', '입력 데이터 간 연관성', 'AI 에이전트', 'LLM 신뢰성', 'AI 개발자 사이 인기']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"Why is it important to increase the reliability of LLMs for their effective application in AI agents?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the importance of increasing the reliability of large language models (LLMs) for their effective application in AI agents. It is clear in its intent, seeking an explanation of the significance of reliability in this context. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided. The focus on 'reliability' and 'effective application in AI agents' is specific enough to guide a relevant response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"Why is it important to increase the reliability of LLMs for their effective application in AI agents?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the potential impact of not enhancing the reliability of large language models (LLMs) on their integration into AI agents for effective data interaction. It specifies the subject (LLMs' reliability) and the context (integration into AI agents for data interaction), making it understandable and answerable without requiring additional context or external references. The question is self-contained and does not rely on unspecified documents or prior knowledge, thus meeting the criteria for independence and clear intent.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"If LLMs' reliability isn't enhanced, how might this impact their integration into AI agents for effective data interaction?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the importance of increasing reliability for effective application, while the second question explores the consequences of not improving reliability. They differ in focus and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"If LLMs don't become more reliable, it could affect their use in AI agents for data interaction by limiting their ability to generate the most probable answers reliably. This is because the reliability of LLMs is crucial for ensuring the necessary level of trustworthiness in their responses.\", 'verdict': 1}\n",
      "Generating:  40%|████      | 4/10 [04:48<06:04, 60.82s/it][ragas.testset.evolutions.INFO] rewritten question: \"What factors are contributing to the recent increase in popularity of the Mamba AI framework among developers?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear and specific, asking for the factors contributing to the recent increase in popularity of the Mamba AI framework among developers. It does not rely on external references or unspecified contexts, making it independent and self-contained. The intent is clear, seeking an explanation of the reasons behind the framework's growing popularity.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The recent increase in popularity of the Mamba AI framework among developers is due to its core attention mechanism, which prioritizes data processing and input weighting, optimizing memory usage. Additionally, the framework's efficiency and cost-effectiveness are emphasized by Ori Goshen, CEO of AI21, as key factors.\", 'verdict': 1}\n",
      "Generating:  50%|█████     | 5/10 [05:09<03:52, 46.44s/it][ragas.testset.evolutions.INFO] rewritten question: \"What specific limitations of Transformer architectures in AI agents lead to the need for optimizing memory usage, and how does this optimization enhance aspects of model reliability such as accuracy, efficiency, or scalability?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking for specific limitations of Transformer architectures that necessitate memory optimization and how such optimization improves model reliability in terms of accuracy, efficiency, or scalability. It is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge. The question effectively specifies the aspects of interest (limitations, memory optimization, and reliability improvements), allowing for a focused response.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What limits Transformers in AI that require memory optimization, and how does this boost model reliability?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific aspects of data collection standardization, such as data format, quality control, or metadata standards, are required to effectively use AI tools, while ensuring ease of implementation and simplicity, without considering data size and utilization scenarios?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking for specific aspects of data collection standardization necessary for the effective use of AI tools. It specifies areas of interest such as data format, quality control, and metadata standards, and also emphasizes the need for ease of implementation and simplicity. The exclusion of data size and utilization scenarios is also clearly stated. This makes the question specific, independent, and understandable without requiring additional context.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the role of data correlation analysis in improving AI model reliability, while the second question addresses limitations of Transformers related to memory optimization and its impact on reliability. These questions differ in both scope and depth.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"According to AI21 CEO Ori Goshen, why are transformers not suitable for AI agents?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking for the reasoning provided by AI21 CEO Ori Goshen on why transformers are not suitable for AI agents. It specifies the source of the information (AI21 CEO Ori Goshen) and the topic of interest (suitability of transformers for AI agents), making the intent clear. The question is independent as it does not rely on external references or unspecified contexts beyond the statement attributed to Ori Goshen.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"According to AI21 CEO Ori Goshen, why are transformers not suitable for AI agents?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: What are the implications of the EU AI law on the collection and analysis of high-risk data for effective crime prevention?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the implications of the EU AI law on the collection and analysis of high-risk data for effective crime prevention. It is clear in its intent, seeking information on the impact of a specific law (EU AI law) on a particular area (high-risk data collection and analysis for crime prevention). However, the question assumes familiarity with the 'EU AI law' and what constitutes 'high-risk data' without providing definitions or context. To improve clarity and answerability, the question could benefit from a brief description of the EU AI law's relevant provisions or a definition of 'high-risk data' in this context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Transformers are limited in AI applications that require memory optimization due to the high speed and cost of processing complex contexts, which can lead to error perpetuation. To boost model reliability, it is necessary to analyze the relationships between data points and ensure a high level of reliability by integrating additional elements for comprehensive answers.', 'verdict': 1}\n",
      "Generating:  60%|██████    | 6/10 [06:02<03:15, 48.92s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for an alternative architecture for AI agents if AI21 CEO Ori Goshen's concerns about transformers' inefficiency are valid. It is clear in its intent to explore potential alternatives to transformers based on a specific concern. However, the question assumes familiarity with Ori Goshen's specific concerns without providing details, making it unclear for those not aware of his statements. To improve clarity and answerability, the question could briefly outline the specific inefficiencies mentioned by Ori Goshen or provide context on the nature of these concerns.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the implications of the EU AI law, which includes strict regulations on AI systems, on the collection and analysis of data considered high-risk for effective crime prevention?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking about the implications of the EU AI law on the collection and analysis of high-risk data for crime prevention. It specifies the context (EU AI law) and the focus (high-risk data for crime prevention), making it understandable and answerable for someone with knowledge of the EU AI regulations. However, it could be improved by briefly defining what constitutes 'high-risk' data within the context of the law, as this term might have specific legal or technical definitions. Overall, the question is specific and independent, but adding a definition of 'high-risk' data could enhance clarity.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How might the EU AI law impact data use for crime prevention?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on regulatory measures for high-risk AI systems under the EU AI law, while the second question is about the impact of the EU AI law on data use for crime prevention. These questions have different constraints and requirements, leading to different depths and breadths of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks why LLM (Large Language Model) reliability should be prioritized over Transformer limitations to enhance AI21's agent efficiency. It is clear in its intent, seeking a rationale for prioritizing one aspect over another in the context of improving efficiency. However, the question assumes familiarity with specific terms like 'AI21's agent', 'LLM reliability', and 'Transformer limitations' without providing definitions or context. To improve clarity and answerability, the question could benefit from a brief explanation of these terms or the specific efficiency challenges being addressed. Additionally, specifying what aspects of reliability and limitations are being compared could further clarify the query.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  70%|███████   | 7/10 [06:44<02:19, 46.64s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The EU AI law, effective from August 2024, impacts data use for crime prevention by prohibiting the use of certain AI applications, such as real-time biometric identification in public spaces, and imposing strict oversight on high-risk AI systems. It also considers exceptions for law enforcement activities, requiring re-evaluation and adjustments to existing AI systems to ensure compliance, while maintaining significant accountability and transparency in decision-making processes.', 'verdict': 1}\n",
      "Generating:  80%|████████  | 8/10 [06:53<01:09, 34.52s/it][ragas.testset.evolutions.INFO] rewritten question: \"What alternative architecture should be considered for AI agents, given AI21 CEO Ori Goshen's concerns about transformers' inefficiency in terms of speed and resource consumption?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is clear in its intent, asking for alternative architectures for AI agents in light of concerns about transformers' inefficiency, as expressed by AI21 CEO Ori Goshen. It specifies the context of the concern (speed and resource consumption) and seeks a specific type of information (alternative architectures). However, it assumes familiarity with Ori Goshen's specific concerns without providing details on what those concerns entail. To improve clarity and answerability, the question could briefly summarize the specific inefficiencies mentioned by Ori Goshen or provide more context about the nature of the inefficiencies being addressed.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Mistral AI', 'Les Ministraux model', 'Offline AI model', 'Mistral 3B and 8B versions', 'Benchmarks and performance']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the key features and advantages of Mistral AI's 'Les Ministraux' model compared to other AI models?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the key features and advantages of Mistral AI's 'Les Ministraux' model in comparison to other AI models. It is clear in its intent to understand both the distinctive features and the comparative advantages of the specified model. However, the question could be improved by specifying which aspects of AI models are of interest (e.g., performance, efficiency, scalability) or by identifying the types of AI models it should be compared against (e.g., language models, vision models). This would provide a more focused context for the comparison.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: What are the key features and advantages of Mistral AI's 'Les Ministraux' model compared to other AI models?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the performance of 'Les Ministraux' in comparison to other AI models, specifically when network independence is prioritized. While it specifies the model of interest ('Les Ministraux') and the condition (network independence), it lacks clarity on what 'excel in performance' means. The question could benefit from specifying the performance metrics or criteria being considered (e.g., speed, accuracy, resource efficiency). Additionally, it assumes familiarity with 'Les Ministraux' and its context, which might not be known to all readers. To improve clarity and answerability, the question could define what aspects of performance are being evaluated and provide a brief context about 'Les Ministraux'.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"In what specific performance metrics does 'Les Ministraux' outperform other AI models when prioritizing network independence, and what is the context of its development and use?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the specific performance metrics where 'Les Ministraux' outperforms other AI models, particularly when prioritizing network independence, and also seeks information on the context of its development and use. While the question is clear in its intent to compare performance metrics and understand the development context, it assumes familiarity with 'Les Ministraux' and the specific context of its development and use, which is not provided. To improve clarity and answerability, the question could include a brief description of 'Les Ministraux' and the context in which it was developed and used, or specify the performance metrics of interest.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Facial recognition technology', 'Government agencies', 'Privacy rights', 'Civil Rights Commission', 'Bias and fairness']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How does the use of facial recognition technology by government agencies impact privacy rights?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the impact of government agencies' use of facial recognition technology on privacy rights. It is clear in its intent, seeking an analysis of the relationship between the use of this technology and privacy rights. The question is independent and does not rely on external references or specific documents, making it understandable and answerable with sufficient domain knowledge. It could be improved by specifying the context or jurisdiction (e.g., a particular country or legal framework) if a more focused analysis is desired, but it is sufficiently clear as is.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: How does the use of facial recognition technology by government agencies impact privacy rights?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear in its intent, asking about the potential impact on privacy rights and legal protections if government agencies use facial recognition technology without justification. It is specific in focusing on the use of facial recognition technology by government agencies and the implications for privacy and legal protections. The question is independent and does not rely on external references or context, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"If gov't agencies use facial recognition tech without justification, how might this affect privacy rights and legal protections?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address the impact of facial recognition technology on privacy rights when used by government agencies. They share the same depth and breadth of inquiry regarding potential privacy concerns.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI 안전성 평가', '개인정보 보호', 'LLM 시스템', '데이터 유출 방지', '적절한 관리 상태']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"AI 안전성 평가의 기본적인 역할은 무엇인가요?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the fundamental role of AI safety evaluation, which is clear in its intent to understand the basic purpose or function of evaluating AI safety. It does not rely on external references or context, making it independent and self-contained. The question is specific enough to allow for a direct response regarding the general principles or objectives of AI safety evaluation.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"AI 안전성 평가의 기본적인 역할은 무엇인가요?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the impact on AI safety evaluation when data privacy is prioritized over system performance. It is clear in its intent, seeking to understand the relationship between prioritizing data privacy and changes in AI safety evaluation. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge. However, to enhance clarity, the question could specify what aspects of AI safety evaluation are of interest (e.g., risk assessment, compliance, robustness).', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"How does AI safety evaluation change if data privacy is prioritized over system performance?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the basic role of AI safety evaluation, while the second question focuses on the impact of prioritizing data privacy over performance on AI safety. They differ in both constraints and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context does not provide specific information on how AI safety shifts with data privacy prioritized over performance.', 'verdict': -1}\n",
      "Generating:  90%|█████████ | 9/10 [08:07<00:46, 46.81s/it][ragas.testset.evolutions.INFO] rewritten question: \"In the context of improving the efficiency of AI21's AI agents, why is it important to focus on enhancing the reliability of Large Language Models (LLMs) rather than addressing the limitations of Transformers? Please provide context on the specific efficiency challenges and clarify what aspects of reliability and limitations are being compared.\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question seeks to understand the importance of focusing on enhancing the reliability of Large Language Models (LLMs) over addressing the limitations of Transformers in the context of improving the efficiency of AI21's AI agents. It asks for specific context on efficiency challenges and clarification on the aspects of reliability and limitations being compared. While the intent is clear, the question assumes familiarity with AI21's specific efficiency challenges and does not provide details on what aspects of reliability and limitations are being compared. To improve clarity and answerability, the question could specify the efficiency challenges faced by AI21's AI agents and define the aspects of reliability and limitations under consideration.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI21 CEO Ori Goshen', 'Transformer architecture', 'AI model development', 'Efficient AI systems', 'Mamba and Jamba architectures']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the significance of Transformer architecture in AI model development according to AI21 CEO Ori Goshen?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Transformer architecture in AI model development, specifically according to AI21 CEO Ori Goshen. It is clear in its intent to understand the perspective of a specific individual (Ori Goshen) on a particular topic (Transformer architecture in AI model development). However, it assumes access to Ori Goshen's statements or writings on this topic, which are not provided within the question. To improve clarity and answerability, the question could include a brief summary or quote of Ori Goshen's views if available, or alternatively, it could be reframed to ask more generally about the significance of Transformer architecture in AI model development without relying on a specific individual's perspective.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the significance of Transformer architecture in AI model development?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of Transformer architecture in AI model development. It is clear and specific, as it seeks to understand the impact or importance of a particular architecture (Transformer) within a defined field (AI model development). The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable with sufficient domain knowledge.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the significance of Transformer architecture in AI model development?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how the Transformer architecture improves AI21's model in terms of efficiency and cost-effectiveness. It is clear in its intent, specifying the focus on the Transformer architecture and its impact on AI21's model. However, it assumes familiarity with AI21's specific model and its context, which might not be known to all readers. To improve clarity and answerability, the question could provide a brief description of AI21's model or specify which aspects of efficiency and cost-effectiveness are of interest (e.g., computational resources, speed, scalability).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: How does Transformer architecture enhance AI21's model efficiency and cost-effectiveness?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"The first question asks about the general significance of Transformer architecture in AI model development, while the second question specifically focuses on how Transformers improve AI21's model efficiency and cost. These questions have different constraints and depths of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Transformers are used extensively in AI model development, but they require a lot of processing power and incur high costs. To enhance AI21's model efficiency and reduce costs, alternative architectures like Mamba and Jamba are suggested, which can make AI agents more efficient and cost-effective.\", 'verdict': 1}\n",
      "Generating: 100%|██████████| 10/10 [09:02<00:00, 54.21s/it]\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents = docs,\n",
    "    test_size = 10,\n",
    "    distributions = dirstributions,\n",
    "    with_debugging_logs = True,\n",
    "    # 로그 활성화\n",
    "    raise_exceptions= False\n",
    "    # 예외가 발생해도 계속 진행, 예외 발생 시 문서가 처리 되지 않거나 문서에 기록됨\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific aspects of data collection stand...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What factors are contributing to the recent in...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...</td>\n",
       "      <td>The recent increase in popularity of the Mamba...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the MIT Industrial Performance Center...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과...</td>\n",
       "      <td>The MIT Industrial Performance Center assesses...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does AI play in addressing global ch...</td>\n",
       "      <td>[∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 ...</td>\n",
       "      <td>AI helps in solving global challenges such as ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do Transformers boost AI21's model efficie...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...</td>\n",
       "      <td>Transformers are used extensively in AI model ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can investment boost AI platforms in compa...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...</td>\n",
       "      <td>Companies need to strengthen investment in AI ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How might the EU AI law impact data use for cr...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집...</td>\n",
       "      <td>The EU AI law, effective from August 2024, imp...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What limits Transformers in AI that require me...</td>\n",
       "      <td>[SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...</td>\n",
       "      <td>Transformers are limited in AI applications th...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If LLMs don't become more reliable, how could ...</td>\n",
       "      <td>[메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...</td>\n",
       "      <td>If LLMs don't become more reliable, it could a...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does AI safety shift with data privacy pri...</td>\n",
       "      <td>[인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ...</td>\n",
       "      <td>The context does not provide specific informat...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific aspects of data collection stand...   \n",
       "1  What factors are contributing to the recent in...   \n",
       "2  How does the MIT Industrial Performance Center...   \n",
       "3  What role does AI play in addressing global ch...   \n",
       "4  How do Transformers boost AI21's model efficie...   \n",
       "5  How can investment boost AI platforms in compa...   \n",
       "6  How might the EU AI law impact data use for cr...   \n",
       "7  What limits Transformers in AI that require me...   \n",
       "8  If LLMs don't become more reliable, how could ...   \n",
       "9  How does AI safety shift with data privacy pri...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집...   \n",
       "1  [SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...   \n",
       "2  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성과...   \n",
       "3  [∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전 ...   \n",
       "4  [SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...   \n",
       "5  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n가트너 예측, ...   \n",
       "6  [1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집...   \n",
       "7  [SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전트...   \n",
       "8  [메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여해 메모리 사...   \n",
       "9  [인간중심, 안전성\\n비의도적 사용 대처 미발생\\n개인정보 보호 프라이버시 보호 Ÿ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The answer to given question is not present in...         simple   \n",
       "1  The recent increase in popularity of the Mamba...         simple   \n",
       "2  The MIT Industrial Performance Center assesses...         simple   \n",
       "3  AI helps in solving global challenges such as ...         simple   \n",
       "4  Transformers are used extensively in AI model ...      reasoning   \n",
       "5  Companies need to strengthen investment in AI ...      reasoning   \n",
       "6  The EU AI law, effective from August 2024, imp...  multi_context   \n",
       "7  Transformers are limited in AI applications th...  multi_context   \n",
       "8  If LLMs don't become more reliable, it could a...    conditional   \n",
       "9  The context does not provide specific informat...    conditional   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "1  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "2  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "3  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "4  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "5  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "6  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "7  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "8  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "9  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('data/ragas_dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific aspects of data collection stand...</td>\n",
       "      <td>['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 ...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What factors are contributing to the recent in...</td>\n",
       "      <td>['SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전...</td>\n",
       "      <td>The recent increase in popularity of the Mamba...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the MIT Industrial Performance Center...</td>\n",
       "      <td>['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성...</td>\n",
       "      <td>The MIT Industrial Performance Center assesses...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does AI play in addressing global ch...</td>\n",
       "      <td>['∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전...</td>\n",
       "      <td>AI helps in solving global challenges such as ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do Transformers boost AI21's model efficie...</td>\n",
       "      <td>['SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전...</td>\n",
       "      <td>Transformers are used extensively in AI model ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific aspects of data collection stand...   \n",
       "1  What factors are contributing to the recent in...   \n",
       "2  How does the MIT Industrial Performance Center...   \n",
       "3  What role does AI play in addressing global ch...   \n",
       "4  How do Transformers boost AI21's model efficie...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 ...   \n",
       "1  ['SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전...   \n",
       "2  ['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\nMIT 산업성...   \n",
       "3  ['∙ (글로벌 도전과제 해결) 환경 문제, 경제 회복력, 사회복지 등 글로벌 도전...   \n",
       "4  ['SPRi AI Brief |\\n2024-11월호\\nAI21 CEO, AI 에이전...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The answer to given question is not present in...         simple   \n",
       "1  The recent increase in popularity of the Mamba...         simple   \n",
       "2  The MIT Industrial Performance Center assesses...         simple   \n",
       "3  AI helps in solving global challenges such as ...         simple   \n",
       "4  Transformers are used extensively in AI model ...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "1  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "2  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "3  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  \n",
       "4  [{'source': 'data/SPRi AI Brief_11월호_산업동향_F.pd...          True  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/ragas_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\\\nKEY Contents\\\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\\\n활용 가능성을 탐색한 보고서를 발간\\\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\\\n다양한 윤리적·사회적 우려도 존재\\\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터', '무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\\\n대한 투명성과 책임성을 보장 필요\\\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\\\n3', '1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\\\nKEY Contents\\\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\\\n활용 가능성을 탐색한 보고서를 발간\\\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\\\n다양한 윤리적·사회적 우려도 존재\\\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터']\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contexts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def convert_to_list(example):\n",
    "    contexts = ast.literal_eval(example['contexts'])\n",
    "    return {'contexts':contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 375.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터',\n",
       " '무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터\\n규모와 운영 요구사항에 적응할 수 있는 확장성과 성능을 갖춘 AI 모델도 개발 필요\\n∙ 편향, 개인정보 침해와 인권 침해와 같은 다양한 윤리적·사회적 우려도 존재하며, 이를 해소하기\\n위해 데이터 편향을 제거하고 공공 안전과 개인정보 간 균형을 유지하며 AI 의사 결정 과정에\\n대한 투명성과 책임성을 보장 필요\\nn 보고서는 2024년 8월 발효된 EU AI 법이 법 집행기관에 미칠 영향도 분석\\n∙ EU AI 법은 공공장소에서 실시간 생체인식 식별과 같은 특정 애플리케이션의 사용을 금지하고\\n고위험 AI 시스템에 엄격한 감독을 부과하였으나 법 집행 활동의 특수성을 고려해 일부 예외를 설정\\n∙ 그러나 일부 예외에도 법 집행 역량 강화를 위한 AI 사용을 위해서는 기존에 도입한 AI\\n시스템에 대한 재평가와 수정이 필요한 만큼, 재정과 인력 측면의 상당한 부담 예상\\n☞ 출처: Europol, AI and policing-The benefits and challenges of artificial intelligence for law enforcement, 2024.09.24.\\n3',\n",
       " '1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n유로폴, 법 집행에서 AI의 이점과 과제를 다룬 보고서 발간\\nKEY Contents\\nn 유로폴의 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오\\n분석 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\nn 그러나 AI 도입을 위해서는 기술적 과제 해결 및 다양한 윤리적·사회적 이슈 대응이\\n필요하며, EU AI 법에 부합하도록 기존 AI 시스템에 대한 평가와 수정도 필요\\n£유로폴, 법 집행에서 AI 기술의 윤리적이고 투명한 구현을 위한 고려사항 제시\\nn EU 사법기관 유로폴(Europol)이 2024년 9월 24일 법 집행에서 효과적 범죄 퇴치를 위한 AI의\\n활용 가능성을 탐색한 보고서를 발간\\n∙ 보고서는 법 집행에서 AI 기술을 윤리적이고 투명하게 구현하기 위한 지침 역할을 하며, AI의 이점과\\n과제를 함께 다룸으로써 법 집행에서 AI 사용 시 윤리적 고려 사항에 대한 인식 제고를 추구\\nn 보고서에 따르면 AI는 고급 데이터 분석, 디지털 증거 수집, 이미지와 비디오 분석, 생체인식\\n시스템 등에 활용되어 법 집행 업무를 대폭 개선할 수 있는 잠재력 보유\\n∙ 법 집행기관은 AI 기반 데이터 분석을 활용해 범죄 활동에 대한 탐지와 대응 능력을 강화하고, AI\\n도구로 구조화되지 않은 데이터를 신속히 분석해 비상 상황의 의사결정을 위한 통찰력 확보 가능\\n∙ 기계번역과 같은 AI 기반 도구는 여러 국가가 참여하는 조사에서 원활한 국제협력을 위해서도 필수적\\nn 그러나 법 집행에서 AI 도구의 효과적이고 책임 있는 활용을 위해 해결되어야 할 기술적 과제 및\\n다양한 윤리적·사회적 우려도 존재\\n∙ 일례로 관할권 간 데이터 수집과 보관 관행의 차이에 따른 데이터셋의 편향으로 인해 AI 산출물의\\n무결성(無缺性)이 손상될 수 있어 표준화된 데이터 수집 규약 필요\\n∙ 데이터 규모나 활용 사례의 복잡성과 관계없이 AI 도구를 효과적으로 사용하려면 다양한 데이터']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['contexts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader('data/SPRi AI Brief_11월호_산업동향_F.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "split_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents = split_documents, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"너는 주어진 질문에 대답하는 AI야. 다음 검색된 context를 사용해서 question에 대답해줘.\n",
    "    답을 모르면, '알 수 없습니다'라고 대답해.\n",
    "\n",
    "    # Context: {context}\n",
    "    # Question : {question}\n",
    "    # Answer :\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {'context' : retriever, 'question' : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dataset = []\n",
    "for question in test_dataset['question']:\n",
    "    batch_dataset.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What specific aspects of data collection standardization, such as data format, quality control, or metadata standards, are required to effectively use AI tools, while ensuring ease of implementation and simplicity, without considering data size and utilization scenarios?',\n",
       " 'What factors are contributing to the recent increase in popularity of the Mamba AI framework among developers?',\n",
       " 'How does the MIT Industrial Performance Center assess the impact of automation technology on workers?']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알 수 없습니다.',\n",
       " \"최근 오픈소스 AI 개발자 사이에서 맘바(Mamba) 아키텍처의 인기가 높아지는 이유는 다음과 같습니다:\\n\\n1. **효율적인 메모리 사용**: 맘바는 트랜스포머 모델의 핵심인 어텐션 메커니즘 대신 데이터를 우선순위에 따라 정리하고 입력에 가중치를 부여하여 메모리 사용을 최적화합니다. 이는 AI 에이전트의 효율성을 높이는 데 기여합니다.\\n\\n2. **빠른 추론 시간**: AI21은 맘바 아키텍처를 기반으로 더 빠른 추론 시간과 더 긴 컨텍스트를 지원하는 잠바(Jamba) 아키텍처를 개발하고 있어, 이러한 기술적 발전이 개발자들 사이에서 맘바의 인기를 높이고 있습니다.\\n\\n3. **상용화 가능성**: AI 에이전트가 상용화되기 위해서는 데이터 간 연관성을 파악하고 신뢰성을 높여야 하는데, 맘바 아키텍처가 이러한 요구를 충족할 수 있는 가능성을 보여주고 있습니다.\\n\\n4. **오픈소스 개발**: 최근 미스트랄과 UAE의 AI 기업 팔콘이 각각 '코드스트랄 맘바 7B'와 '팔콘 맘바 7B'를 출시하는 등, 오픈소스 AI 개발자들 사이에서 맘바의 활용이 증가하고 있습니다.\\n\\n이러한 요소들이 결합되어 맘바 아키텍처의 인기가 상승하고 있습니다.\",\n",
       " 'MIT 산업성과센터는 근로자 관점에서 자동화 기술의 영향을 조사한 결과, 근로자들이 직장 내 안전, 임금, 업무 자율성 등에서 자동화를 긍정적으로 평가하고 있다고 밝혔습니다. 설문조사에 따르면, 복잡한 문제 해결이 필요한 작업을 수행하는 근로자 및 자신의 직무에 만족하는 근로자일수록 자동화의 영향에 긍정적인 것으로 나타났습니다. 조사 결과, 자동화가 직장 내 안전에 긍정적 영향을 미친다고 응답한 비율은 44.9%였으며, 임금에 대해서는 28.8%가 긍정적이라고 응답했습니다. 또한, 자동화 기술에 대한 근로자들의 인식은 대체로 긍정적이지만, 국가별로 차이가 있으며, 미국 근로자들은 가장 비관적인 태도를 보였습니다.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'answer' in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns(['answer']).add_column('answer', answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column('answer', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done', 'answer'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy,faithfulness,context_recall,context_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 3742. Please try again in 1.122s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   2%|▎         | 1/40 [01:38<1:03:57, 98.40s/it]Exception raised in Job[23]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198715, Requested 2178. Please try again in 267ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   5%|▌         | 2/40 [02:02<34:32, 54.54s/it]  Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:   8%|▊         | 3/40 [02:06<19:23, 31.44s/it]Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198918, Requested 2177. Please try again in 328ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  10%|█         | 4/40 [02:11<12:40, 21.12s/it]Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1404. Please try again in 421ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  12%|█▎        | 5/40 [02:12<08:09, 13.98s/it]Exception raised in Job[34]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199845, Requested 1612. Please try again in 437ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  15%|█▌        | 6/40 [02:19<06:31, 11.51s/it]Exception raised in Job[17]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199605, Requested 697. Please try again in 90ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  18%|█▊        | 7/40 [02:20<04:25,  8.05s/it]Exception raised in Job[16]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  20%|██        | 8/40 [02:25<03:45,  7.04s/it]Exception raised in Job[15]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199079, Requested 1807. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  22%|██▎       | 9/40 [02:36<04:20,  8.41s/it]Exception raised in Job[33]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  25%|██▌       | 10/40 [02:39<03:16,  6.56s/it]Exception raised in Job[32]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  28%|██▊       | 11/40 [02:45<03:05,  6.39s/it]Exception raised in Job[39]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  30%|███       | 12/40 [02:46<02:18,  4.93s/it]Exception raised in Job[14]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1440. Please try again in 432ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  32%|███▎      | 13/40 [02:51<02:10,  4.85s/it]Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199284, Requested 905. Please try again in 56ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  35%|███▌      | 14/40 [02:59<02:35,  5.97s/it]Exception raised in Job[31]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[4]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2922. Please try again in 876ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  42%|████▎     | 17/40 [03:34<03:27,  9.03s/it]Exception raised in Job[27]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198700, Requested 2269. Please try again in 290ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  45%|████▌     | 18/40 [04:05<05:00, 13.67s/it]Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1869. Please try again in 560ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  48%|████▊     | 19/40 [04:09<04:01, 11.51s/it]Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 1901. Please try again in 570ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  50%|█████     | 20/40 [04:15<03:20, 10.04s/it]Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198472, Requested 2159. Please try again in 189ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  52%|█████▎    | 21/40 [04:30<03:36, 11.37s/it]Exception raised in Job[0]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  55%|█████▌    | 22/40 [04:42<03:29, 11.65s/it]Exception raised in Job[18]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  57%|█████▊    | 23/40 [04:46<02:41,  9.49s/it]Exception raised in Job[5]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  60%|██████    | 24/40 [04:54<02:23,  8.97s/it]Exception raised in Job[28]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 3925. Please try again in 1.177s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  62%|██████▎   | 25/40 [04:55<01:40,  6.69s/it]Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  65%|██████▌   | 26/40 [05:00<01:26,  6.15s/it]Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  68%|██████▊   | 27/40 [05:21<02:16, 10.53s/it]Exception raised in Job[9]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  70%|███████   | 28/40 [05:32<02:10, 10.86s/it]Exception raised in Job[6]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 2962. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  72%|███████▎  | 29/40 [05:39<01:44,  9.48s/it]Exception raised in Job[29]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per min (RPM): Limit 500, Used 500, Requested 1. Please try again in 120ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  75%|███████▌  | 30/40 [05:42<01:16,  7.60s/it]Exception raised in Job[20]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198421, Requested 2231. Please try again in 195ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  78%|███████▊  | 31/40 [05:46<01:00,  6.70s/it]Exception raised in Job[3]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 199629, Requested 2214. Please try again in 552ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  80%|████████  | 32/40 [05:56<01:00,  7.53s/it]Exception raised in Job[12]: TimeoutError()\n",
      "Evaluating:  82%|████████▎ | 33/40 [06:00<00:44,  6.40s/it]Exception raised in Job[38]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  85%|████████▌ | 34/40 [06:36<01:31, 15.27s/it]Exception raised in Job[10]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 198461, Requested 2048. Please try again in 152ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  88%|████████▊ | 35/40 [06:37<00:55, 11.11s/it]Exception raised in Job[21]: TimeoutError()\n",
      "Evaluating:  90%|█████████ | 36/40 [07:09<01:09, 17.40s/it]Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on tokens per min (TPM): Limit 200000, Used 200000, Requested 3390. Please try again in 1.017s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  92%|█████████▎| 37/40 [07:22<00:47, 15.93s/it]Exception raised in Job[22]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-nS8RoafnzeRRZRKTRiJUJQQC on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
      "Evaluating:  95%|█████████▌| 38/40 [07:30<00:27, 13.55s/it]Exception raised in Job[30]: TimeoutError()\n",
      "Evaluating:  98%|█████████▊| 39/40 [07:42<00:13, 13.27s/it]Exception raised in Job[11]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 40/40 [07:46<00:00, 11.66s/it]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    dataset = test_dataset,\n",
    "    metrics = [\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision\n",
    "    ]\n",
    ")\n",
    "# context_recall : 모델이 문맥에서 중요한 정보를 잘 회상, 재현했는가\n",
    "# faithfulness : 모델의 답변이 문맥에 기반해서 사실적인가(factual)\n",
    "# answer_relevancy : 전체 질문에 대해 모델의 답변이 질문과 얼마나 관련성이 있는가\n",
    "# context_precision : 모델이 문맥에서 필요한 정보를 정확히 활용했는가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|context_precision (문맥 정밀도)|faithfulness (신뢰성)|answer_relevancy (답변 적합성)|context_recall (문맥 재현율)|\n",
    "|---|---|---|---|\n",
    "|답변에 사용된 문맥이 정확했는지|답변이 문맥에 기반해 사실적(factual)인지|답변이 질문과 관련성이 있는지|답변이 문맥에서 얼마나 많은 정보를 활용했는지|\n",
    "|1.0: 답변에 사용된 정보가 문맥에서 매우 정확하게 활용됨|1.0: 답변이 문맥과 매우 정확하게 일치|1.0: 답변이 질문과 매우 높은 관련성을 가짐|1.0: 답변이 문맥의 모든 중요한 정보를 잘 회상|\n",
    "|0.0: 답변이 문맥과 무관하거나, 부정확한 정보를 활용|0.0: 답변이 문맥에 기반하지 않고, 사실과 다를 가능성이 큼|0.0: 답변이 질문과 관련이 없거나, 부정확|0.0: 답변이 문맥을 활용하지 못함|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc[:, 'context_recall':'context_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
