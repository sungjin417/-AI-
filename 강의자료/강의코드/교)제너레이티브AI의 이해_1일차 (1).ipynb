{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 제너레이티브AI의 이해 - 1차시(24.11.18)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VAE(Variational Auto Encoder)\n",
    "- 모델이 숫자 이미지를 압축하고, 복원하는 과정(인코더-디코더)\n",
    "- 인코더 : 입력 이미지를 잠재공간으로 매핑\n",
    "- 디코더 : 잠재 공간에서 샘플을 받아 이미지 복원\n",
    "- 가상환경 실행 후 - pip install opencv-python로 설치!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow를 활용한 celeb데이터셋에 VAE 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\RMARKET\\.cache\\kagglehub\\datasets\\yunting0123\\img-align-celeba\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yunting0123/img-align-celeba\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "image_dir = \"C:/Users/RMARKET/.cache/kagglehub/datasets/yunting0123/img-align-celeba/versions/1/t/celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'030000.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filenames = os.listdir(image_dir)[-1]\n",
    "img_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이미지 불러오고 전처리 하는 함수 만들기\n",
    "def load_preprocess_images(image_dir, img_size = (128, 128), num_images = 10000):\n",
    "    # 경로, 이미지 크기, 최대 로드할 이미지 개수\n",
    "    images = []\n",
    "    # 전처리 된 이미지를 추가할 리스트\n",
    "    img_filenames = os.listdir(image_dir)[:num_images]\n",
    "    for filename in img_filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        # 이미지 파일의 전체 경로를 image_dir(폴더 경로) + filename(파일 이름)으로 만들어주기\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None : \n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0\n",
    "            # 이미지 정규화\n",
    "            # [204, 76, 128] -> [0.8, 0.3, 0.5]\n",
    "            images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.78823529, 0.88627451, 0.94901961],\n",
       "         [0.84705882, 0.92156863, 0.96862745],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.79607843, 0.89411765, 0.95294118],\n",
       "         [0.85098039, 0.92156863, 0.97254902],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.81960784, 0.90588235, 0.96078431],\n",
       "         [0.85490196, 0.9254902 , 0.97647059],\n",
       "         [0.8745098 , 0.93333333, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23529412, 0.40392157, 0.6745098 ],\n",
       "         [0.22745098, 0.39215686, 0.6627451 ],\n",
       "         [0.21176471, 0.37254902, 0.63921569],\n",
       "         ...,\n",
       "         [0.0627451 , 0.16078431, 0.40784314],\n",
       "         [0.0627451 , 0.16078431, 0.40392157],\n",
       "         [0.0627451 , 0.16078431, 0.40392157]],\n",
       "\n",
       "        [[0.2       , 0.36078431, 0.63921569],\n",
       "         [0.20784314, 0.37254902, 0.64705882],\n",
       "         [0.22745098, 0.39215686, 0.67058824],\n",
       "         ...,\n",
       "         [0.07843137, 0.18039216, 0.43921569],\n",
       "         [0.0745098 , 0.18039216, 0.43529412],\n",
       "         [0.0745098 , 0.18039216, 0.43529412]],\n",
       "\n",
       "        [[0.18039216, 0.34117647, 0.61960784],\n",
       "         [0.19607843, 0.36078431, 0.63921569],\n",
       "         [0.23137255, 0.4       , 0.68235294],\n",
       "         ...,\n",
       "         [0.08627451, 0.18823529, 0.45490196],\n",
       "         [0.08235294, 0.18823529, 0.45098039],\n",
       "         [0.08235294, 0.18823529, 0.45098039]]],\n",
       "\n",
       "\n",
       "       [[[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30196078, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30588235, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28627451, 0.29803922],\n",
       "         [0.28627451, 0.30588235, 0.31764706],\n",
       "         [0.29411765, 0.31764706, 0.32941176]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784314, 0.78431373, 0.77647059],\n",
       "         [0.81176471, 0.79215686, 0.78431373],\n",
       "         [0.82745098, 0.80392157, 0.8       ],\n",
       "         ...,\n",
       "         [0.4       , 0.41960784, 0.53333333],\n",
       "         [0.45882353, 0.47058824, 0.55686275],\n",
       "         [0.48627451, 0.49803922, 0.57254902]],\n",
       "\n",
       "        [[0.85882353, 0.83529412, 0.83529412],\n",
       "         [0.85490196, 0.83529412, 0.83529412],\n",
       "         [0.85098039, 0.83137255, 0.83137255],\n",
       "         ...,\n",
       "         [0.38039216, 0.40784314, 0.52941176],\n",
       "         [0.43137255, 0.45098039, 0.54901961],\n",
       "         [0.45882353, 0.47058824, 0.56078431]],\n",
       "\n",
       "        [[0.88235294, 0.8627451 , 0.86666667],\n",
       "         [0.8745098 , 0.85490196, 0.85882353],\n",
       "         [0.8627451 , 0.84313725, 0.84705882],\n",
       "         ...,\n",
       "         [0.37254902, 0.4       , 0.5254902 ],\n",
       "         [0.41960784, 0.43921569, 0.54509804],\n",
       "         [0.44313725, 0.45882353, 0.55294118]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22352941, 0.34117647, 0.51764706],\n",
       "         [0.21960784, 0.34509804, 0.5254902 ],\n",
       "         [0.21568627, 0.36078431, 0.54117647],\n",
       "         ...,\n",
       "         [0.25098039, 0.23921569, 0.23921569],\n",
       "         [0.25490196, 0.24313725, 0.24705882],\n",
       "         [0.25882353, 0.24705882, 0.25098039]],\n",
       "\n",
       "        [[0.22745098, 0.32156863, 0.48235294],\n",
       "         [0.22352941, 0.3254902 , 0.49019608],\n",
       "         [0.21568627, 0.34509804, 0.51372549],\n",
       "         ...,\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725],\n",
       "         [0.25098039, 0.24313725, 0.24705882]],\n",
       "\n",
       "        [[0.22745098, 0.30980392, 0.4627451 ],\n",
       "         [0.22352941, 0.31764706, 0.4745098 ],\n",
       "         [0.21960784, 0.3372549 , 0.49803922],\n",
       "         ...,\n",
       "         [0.23921569, 0.23137255, 0.23529412],\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.71372549, 0.69411765, 0.69803922],\n",
       "         [0.71764706, 0.69803922, 0.70196078],\n",
       "         [0.72941176, 0.70980392, 0.71372549],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.70588235, 0.68627451, 0.69019608],\n",
       "         [0.70980392, 0.69019608, 0.69411765],\n",
       "         [0.72156863, 0.70196078, 0.70588235],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.68627451, 0.66666667, 0.67058824],\n",
       "         [0.69019608, 0.67058824, 0.6745098 ],\n",
       "         [0.70588235, 0.68627451, 0.69019608],\n",
       "         ...,\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         ...,\n",
       "         [0.87058824, 0.8627451 , 0.87843137],\n",
       "         [0.8745098 , 0.86666667, 0.87843137],\n",
       "         [0.87843137, 0.86666667, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.87058824, 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.86666667, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.8745098 , 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.87058824, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]]],\n",
       "\n",
       "\n",
       "       [[[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.92156863, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.9372549 , 0.94117647],\n",
       "         [0.90196078, 0.9254902 , 0.92941176],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54117647, 0.49803922, 0.44313725]],\n",
       "\n",
       "        [[0.93333333, 0.94901961, 0.94901961],\n",
       "         [0.9254902 , 0.94117647, 0.94509804],\n",
       "         [0.91372549, 0.92941176, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]],\n",
       "\n",
       "        [[0.9372549 , 0.95294118, 0.95294118],\n",
       "         [0.92941176, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.93333333, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]]],\n",
       "\n",
       "\n",
       "       [[[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.83529412, 0.83921569, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.81568627, 0.81960784, 0.81960784],\n",
       "         ...,\n",
       "         [0.2       , 0.26666667, 0.38039216],\n",
       "         [0.19607843, 0.26666667, 0.38039216],\n",
       "         [0.19215686, 0.26666667, 0.38431373]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         ...,\n",
       "         [0.17647059, 0.23529412, 0.35294118],\n",
       "         [0.17647059, 0.23921569, 0.36078431],\n",
       "         [0.18039216, 0.24313725, 0.36470588]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82745098, 0.82352941],\n",
       "         ...,\n",
       "         [0.16470588, 0.21960784, 0.3372549 ],\n",
       "         [0.16862745, 0.22745098, 0.34901961],\n",
       "         [0.17254902, 0.23137255, 0.35294118]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = load_preprocess_images(image_dir)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 샘플링 함수 정의\n",
    "# 잠재공간에서 새로운 샘플을 생성하기 위해 데이터포인트들을 샘플링하는 과정\n",
    "# 각 데이터포인터들의 평균값과 로그분산을 출력하는 함수\n",
    "def sampling(z_mean, z_log_var):\n",
    "    # 모델이 새로운 데이터포인트(z)를 생성할 수 있음\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    # 딥러닝프레임워크는 데이터 입력 시 자동으로 배치 크기를 감지\n",
    "    # 0번째 자리의 값이 batch사이즈이므로 batch라는 이름의 변수로 저장한 것\n",
    "\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # 잠재공간의 차원값\n",
    "\n",
    "    epsilon = tf.random.normal(shape = (batch, dim))\n",
    "    # 배치사이즈와 차원의 shape을 갖는 표준정규분포의 무작위값 생성\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "# tf.exp(0.5 * z_log_var) -> 로그 분산을 표준편차로 변환하는 과정, 로그분산에 0.5를 곱하고 지수함수를 적용\n",
    "# -> 표준편차를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 인코더 정의\n",
    "latent_dim = 200\n",
    "# 잠재 공간의 차원\n",
    "# 간단한 데이터나 테스트 목적 : 2~10정도\n",
    "# 복잡한 이미지나 고차원 : 100~200 사용\n",
    "\n",
    "encoder_input = keras.layers.Input(shape = (128, 128, 3), name='encoder_input')\n",
    "# 128x128 사이즈의 컬러 이미지를 인풋으로 넣을 것임을 명시적으로 지정한 것\n",
    "x = keras.layers.Conv2D(32, (3, 3), strides = 2, activation='relu', padding = 'same')(encoder_input)\n",
    "# Conv2D : 공간적인 패턴 학습 가능\n",
    "# 32개 필터, (3,3)커널, 슬라이딩간격 2\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding = 'same')(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "# x.shape = (batch_size, height, width, channels)\n",
    "shape_before_flattening = x.shape[1:]\n",
    "# x를 1차원 벡터로 변환하기 전 정보 저장\n",
    "\n",
    "# 1차원 벡터로 변환 : Conv2D는 이미지의 공간적인 구조를 학습할 수 있으나 결정을 내릴 순 없음\n",
    "# 결정을 내릴 수 있는 Dense층을 쌓아주기 위해 1차원 벡터로 변환 (flatten, 평탄화)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "# 인코더의 마지막 단계\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(x)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(x)\n",
    "# 두 레이어는 동일한 입력 x를 받지만, 손실함수와 역전파 과정에 의해 다른 출력을 학습\n",
    "\n",
    "z = sampling(z_mean, z_log_var)\n",
    "# 무작위 벡터값 생성\n",
    "\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "# 모델은 세 개의 출력을 반환한다\n",
    "# z_mean : 인코더가 학습한 잠재 공간의 평균 벡터\n",
    "# z_log_var : 인코더가 학습한 로그 분산 벡터\n",
    "# z : 평균과 분산을 사용해 샘플링된 잠재 공간의 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 디코더 정의\n",
    "decoder_input = keras.layers.Input(shape = (latent_dim,), name = 'decoder_input')\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "# Dense레이어로 잠재공간의 벡터를 디코더 출력에 맞게 변환\n",
    "# prod : 이 형태의 모든 차원을 곱해 1차원 값으로 변환\n",
    "# (16,16,128) -> 16x16x128\n",
    "# 먼저 위에서 저장했던 flatten전 마지막 3차원을 1차원으로 변환 후 Dense레이어에 적용\n",
    "\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "# 원래 인코더의 마지막 출력 형태인 3차원 텐서로 다시 reshape\n",
    "x = keras.layers.Conv2DTranspose(128, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(64, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "\n",
    "decoder_output = keras.layers.Conv2D(3, (3, 3), strides = 1, activation = 'sigmoid', padding='same', name='decoder_output')(x)\n",
    "decoder = keras.models.Model(decoder_input, decoder_output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 학습 루프 만들기\n",
    "def train_step(data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # with tf.GradientTape() as tape : tensorflow에서 자동 미분을 위해 설정하는 with문\n",
    "        z_mean, z_log_var, z = encoder(data)\n",
    "        recon = decoder(z)\n",
    "        # recon : 재구성된 이미지 / 입력데이터와 비교될 이미지\n",
    "\n",
    "        # 1. 재구성 손실\n",
    "        recon_loss = tf.reduce_mean(500 * tf.losses.binary_crossentropy(data, recon))\n",
    "        # 원본 데이터와 재구성된 이미지 데이터 간의 차이를\n",
    "        # 픽셀의 이진분포로 계산\n",
    "        # 가중치를 500곱해서 조정\n",
    "        # reduce_mean : 배치 내 모든 데이터포인트의 평균손실을 계산한다는 의미\n",
    "\n",
    "        # 2. KL-발산 손실\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis = 1))\n",
    "        # axis = 1옵션을 넣었기 떄문에 각 차원에 대한 합산\n",
    "        total_loss = recon_loss + kl_loss\n",
    "    \n",
    "    grad = tape.gradient(total_loss, encoder.trainable_weights + decoder.trainable_weights)\n",
    "    # tape.gradient는 total_loss에 대한 인코더와 디코더의 가중치에 대한 기울기를 계산\n",
    "    optimizer.apply_gradients(zip(grad, encoder.trainable_weights + decoder.trainable_weights))\n",
    "    # 계산된 기울기를 사용하여 Adam최적화 알고리즘을 통해 인코더와 디코더의 가중치를 업데이트\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "    # 총 손실, 재구성 손실, KL-발산 손실을 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(1000).batch(batch_size)\n",
    "# tf.data.Dataset.from_tensor_slices : 주어진 텐서를 받아 이를 개별 슬라이스로 나눠 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "step 0 : total loss = 347.2638,recon loss : 346.6690,KL loss : 0.5948\n",
      "step 100 : total loss = 320.9874,recon loss : 314.6162,KL loss : 6.3712\n",
      "step 200 : total loss = 289.2507,recon loss : 278.3510,KL loss : 10.8997\n",
      "step 300 : total loss = 302.1631,recon loss : 291.7750,KL loss : 10.3881\n",
      "Epoch 2 / 10\n",
      "step 0 : total loss = 307.4444,recon loss : 297.4410,KL loss : 10.0034\n",
      "step 100 : total loss = 286.6945,recon loss : 274.8837,KL loss : 11.8108\n",
      "step 200 : total loss = 290.0837,recon loss : 278.3944,KL loss : 11.6894\n",
      "step 300 : total loss = 295.9551,recon loss : 283.9161,KL loss : 12.0390\n",
      "Epoch 3 / 10\n",
      "step 0 : total loss = 296.9900,recon loss : 283.6467,KL loss : 13.3433\n",
      "step 100 : total loss = 302.9109,recon loss : 290.5237,KL loss : 12.3872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4208\\2027987251.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch + 1} / {epochs}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# 현재 스탭과 배치데이터를 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# 스탭이 100의 배수일 떄마다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             print(f'step {step} : total loss = {total_loss.numpy():.4f},'\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4208\\1656924006.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mkl_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_log_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# axis = 1옵션을 넣었기 떄문에 각 차원에 대한 합산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecon_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;31m# tape.gradient는 total_loss에 대한 인코더와 디코더의 가중치에 대한 기울기를 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# 계산된 기울기를 사용하여 Adam최적화 알고리즘을 통해 인코더와 디코더의 가중치를 업데이트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1096\u001b[0m               output_gradients))\n\u001b[0;32m   1097\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m     47\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m           data_format=op.get_attr(\"data_format\").decode()),\n\u001b[1;32m---> 51\u001b[1;33m       gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m     52\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       return conv2d_eager_fallback(\n\u001b[0;32m    936\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} / {epochs}')\n",
    "    for step, batch_data in enumerate(dataset):\n",
    "        # 현재 스탭과 배치데이터를 반환\n",
    "        total_loss, recon_loss, kl_loss = train_step(batch_data)\n",
    "        if step % 100 == 0:\n",
    "            # 스탭이 100의 배수일 떄마다\n",
    "            print(f'step {step} : total loss = {total_loss.numpy():.4f},'\n",
    "                  f'recon loss : {recon_loss.numpy():.4f},'\n",
    "                  f'KL loss : {kl_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Torch를 활용한 MNIST데이터셋에 VAE 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 🌼마무리 문제\n",
    "\n",
    "다양한 데이터셋을 적용해보세요\n",
    "\n",
    "Q1. Fashion MNIST\n",
    "- 28X28 크기의 패션 아이템 이미지로 구성된 흑백 이미지 데이터셋\n",
    "\n",
    "\n",
    "Q2. CIFAR-10\n",
    "- 32X32 크기의 색상이 있는 자동차, 동물 등 다양한 객체가 포함된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fashion MNIST 데이터셋 로드 (28x28 크기의 패션 아이템 이미지)\n",
    "trans = transforms.ToTensor()\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)\n",
    "data_loader = DataLoader(fashion_mnist_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR-10 데이터셋 로드 (32x32 크기의 컬러 이미지)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 데이터 정규화\n",
    "])\n",
    "cifar10_data = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(cifar10_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
